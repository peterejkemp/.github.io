[
  {
    "objectID": "index.html#seminar-tasks",
    "href": "index.html#seminar-tasks",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n1.1 Seminar tasks",
    "text": "1.1 Seminar tasks\n\n1.1.1 Activity 1: The mismeasure of man?\n\n’The Mismeasure of Man treats one particular form of quantified claim about the ranking of human groups: the argument that intelligence can be meaningfully abstracted as a single number capable of ranking all people on a linear scale of intrinsic and unalterable mental worth.\n… this limited subject embodies the deepest (and most common) philosophical error, with the most fundamental and far-ranging social impact, for the entire troubling subject of nature and nurture, or the genetic contribution to human social organization.’ Gould (1996), p. ii\n\nDiscuss:\n• To what extent do the variables commonly studied in educational research (for example, intelligence, exam scores, attitudes etc.) validly represent some underlying latent variable?\n• What advantages does quantification of such variables bring, and what issues does it raise?\n• Can you think of an example in your own practice where a variable has been created that doesn’t fully reflect the latent concept?\n• What is the researcher’s role in making sure variables are validly represented?\n\n1.1.2 Activity 2: An example of quantification\nIn the seminar we will consider this paper:\nPasha-Zaidi, N., & Afari, E. (2016). Gender in STEM education: An exploratory study of student perceptions of math and science instructors in the United Arab Emirates. International Journal of Science and Mathematics Education, 14(7), 1215-1231.\nPasha-Zaidi and Afari (2016)\nReflect on\n\nWhat potential issues arise from the authors’ construction of quantitative variables of ‘teacher professionalism’ and ‘teacher warmth’?\nTo what extent does the authors’ survey validly probe the variables of ‘teacher professionalism’ and ‘teacher warmth’?\nWhat other critiques of the study can you propose?\n\n\n\n\n\n\n1.1.3 Activity 3: A false dualism?\n\n“‘Quantitative’ and ‘qualitative’ are frequently seen in opposition…. The contrast is drawn between the objective world (out there independently of our thinking about it) and the subjective worlds (in our heads, as it were, and individually constructed); between the public discourse and private meanings; between reality unconstructed by anyone and the ‘multiple realities’ constructed by each individual. The tendency to dichotomise in this way is understandable but misleading.” (Pring 2000, 248)\n\nDiscussion Questions\n\nWhat are the differing assumptions of qualitative and quantitative educational research?\nAre the two ‘paradigms’ completely distinct? Is the distinction helpful?\nHow should a researcher choose what approach to use?\n\n1.1.4 Task 4: Another critique of quantification\nThe second task considers this paper: Gibson and Dembo (1984)\nFor the purpose of discussion, teacher efficacy has been defined as “the extent to which the teacher believes he or she has the capacity to affect student performance” (Berman et al. 1977, 137)\nTool\n\n\n\n\n(Gibson and Dembo 1984, 573)\nFindings\n\n(Gibson and Dembo 1984, 577)\nTo discuss\n\nDoes teacher efficacy measure a discrete aspect of teachers’ beliefs? Does that matter?\nDoes the construct have validity? I.e., does the questionnaire measure what it claims to?\nWhat issues arises from quantifying teacher efficacy?\nWhat alternatives are there to quantitative measures of teacher efficacy? What are their advantages and limitations?"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.1 Introduction",
    "text": "2.1 Introduction\nThis short course aims to take you through the process of writing your first programs in the R statistical programming language to analyse national and international educational datasets. To do this we will be using the R Studio integrated development environment (IDE), a desktop application to support you in writing R scripts. R Studio supports your programming by flagging up errors in your code as you write it, and helping you manage your analysis environment by giving you quick access to tables, objects and graphs as you develop them. In addition, we will be looking at data analysis using the tidyverse code packages. The tidyverse is a standardised collection of supporting code that helps you read data, tidy it into a usable format, analyse it and present your findings.\nThe R programming language offers similar functionality to an application based statistical tool such as SPSS, with more of a focus on you writing code to solve your problems, rather than using prebuilt tools. R is open source, meaning that it is free to use and that lots of people have written code in R that they have shared with others. R statistical libraries are some of the most comprehensive in existence. R is popular1 in academia and industry, being used for everything from sales modelling to cancer detection.\n\n# This example shows how R can pull data directly from the internet\n# tidy it and start making graphs. All within 9 lines of code\nlibrary(tidyverse)\n\neducation <- read_csv(\n  \"https://barrolee.github.io/BarroLeeDataSet/BLData/BL_v3_MF.csv\")\n\neducation %>%\n  filter(agefrom == 15, ageto == 24,\n         country %in% c(\"Germany\",\"France\",\"Italy\",\"United Kingdom\")) %>%\n  ggplot(aes(x=year, y=yr_sch, colour=country)) +\n  geom_point() +\n  geom_line()\n\n\n\n\nWhilst it is possible to use R through menu systems and drop down tools, the focus of this course is for you to write your own R scripts. These are text files that will tell the computer how to go through the process of loading, cleaning, analysing and presenting data. The sequential and modular nature of these files makes it very easy to develop and test each stage separately, reuse code in the future, and share with others.\nThis booklet is written with the following sections to support you:\n\n# Code examples and questions appear like this\na <- 1 + 3\n\n[1] Code output appears like this\nCourier font indicates keyboard presses, column names, column values and function names.\n<folder> Courier font within brackets describe values that can be passed to functions and that you need to define yourself. I.e. copying and pasting these code chunks verbatim won’t work!\n\n\n\n\n\n\nNote\n\n\n\nspecifies things to note\n\n\n\n\n\n\n\n\nWarning\n\n\n\ngives warning messages\n\n\n\n\n\n\n\n\nImportant\n\n\n\nhighlights issues that might break your code\n\n\n\n\n\n\n\n\nTip\n\n\n\ngives suggestions on how to do things in a better way\n\n\n\nActivities and coding tasks look like this\n\nwhat <- \"does this\"\ncode == \"do\""
  },
  {
    "objectID": "index.html#getting-set-up",
    "href": "index.html#getting-set-up",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.2 Getting set up",
    "text": "2.2 Getting set up\n\n2.2.1 Installation (on your own machine)\n\n\nInstall R (default settings should be fine)\n\n\nWindows users visit: here\n\n\nMac users visit: here and make sure you get the correct version of R for M1/2 Macs (~November 2020 onwards), or Intel Macs (~up to November 2020)\n\n\nInstall RStudio, visit here and it should present you with the version suitable for your operating system.\n\n(If the above doesn’t work follow the instructions here)\n\n2.2.2 Setting up RStudio and the tidyverse\n\nOpen RStudio\n\nOn the bottom right-hand side, select Packages, then select Install, then type “tidyverse” into the Packages field of the new window:\n\n\nClick Install and you should see things happening in the console (bottom left). Wait for the console activity to finish (it’ll be downloading and checking packages). If it asks any questions, type N for no and press enter.\n\nAdd a new R Script using the  button\n\n\n\nIn the new R script, write the following:\n\n\n\nSelect all the lines and press Control or Command ⌘ and Enter on your keyboard at the same time. Alternatively, press the  button\n\n\n\nCheck that you have the following in the console window (depending on your screen size you might have fewer columns):\n\n\nInstall the arrow package, repeat step 2, above.\nDownload the PISA_2018_student_subset.parquet dataset from here and download it on your computer, make a note of the full folder location where you have saved this!\n\nIf you need help with finding the full folder location of your file, often a hurdle for Mac users, go to Section 2.8.3\n\nCopy the following code and replace <folder> with the full folder location of where your dataset was saved, make sure that you have .parquet on the end. And keep the (r\"[  ]\")!\n\n\nexamples of what this should look like for PC and Mac# For Pete (PC) the address format was:\nPISA_2018 <- read_parquet(r\"[C:\\Users\\Peter\\KCL\\MASTEMR\\PISA_2018_student_subset.parquet]\")\n\n# For Richard (Mac) the address format was:\nPISA_2018 <- read_parquet(r\"[/Users/k1765032/Documents/Teaching/STEM MA/Quantitative module/Data sets/PISA_2018_student_subset.parquet]\")\n\n\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2018 <- read_parquet(r\"[<folder>PISA_2018_student_subset.parquet]\")\n\n\nUnderneath the code you have already written, copy the code below (you don’t have to write it yourself), and run it. Try and figure out what each line does and what it’s telling you.\n\n\nlibrary(tidyverse)\n\nPISA_2018 %>%\n  mutate(maths_better = PV1MATH > PV1READ) %>%\n  select(CNT, ST004D01T, maths_better, PV1MATH, PV1READ) %>% \n  filter(!is.na(ST004D01T), !is.na(maths_better)) %>%\n  group_by(ST004D01T) %>%\n  mutate(students_n = n()) %>%\n  group_by(ST004D01T, maths_better) %>%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n\nThat’s it, you should be set up!\nAny issues, please drop a message on the Teams group, or mail peter.kemp@kcl.ac.uk and richard.brock@kcl.ac.uk"
  },
  {
    "objectID": "index.html#starting-to-code",
    "href": "index.html#starting-to-code",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.3 Starting to code",
    "text": "2.3 Starting to code\nAfter adding a new R Script using the button , there are four parts to R Studio’s interface. For the moment we are most interested in the Script file section, top left."
  },
  {
    "objectID": "index.html#your-first-program",
    "href": "index.html#your-first-program",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.4 Your first program",
    "text": "2.4 Your first program\n\n2.4.1 Objects and instructions\nIn programming languages we can attach data to a name, this is called assigning a value to an object (you might also call them variables). To do this in R we use the <- arrow command. For example, I want to put the word \"Pete\" into an object called myname (note that words and sentences such as \"Pete\" need speech marks):\n\nmyname <- \"Pete\"\nprint(myname)\n\n[1] \"Pete\"\n\n\nWe can also perform quick calculations and assign them to objects:\n\nHoursInYear <- 365 * 24\nprint(HoursInYear) \n\n[1] 8760\n\n\n\nType the two examples above into your RStudio script file and check that they work. Adapt them to say your full name and give the number of MinutesInADay\n\n\n\n\n\n\n\nTip\n\n\n\nRemember to select code and press control or command and Enter to run it\n\n\nObjects can form part of calculations, for example, the code below shows how we can use the number HoursInYear to (roughly!) calculate the number of HoursInWeek:\n\nHoursInYear <- 365 * 24\n\nHoursInWeek <- HoursInYear / 52\nprint(HoursInWeek)\n\n[1] 168.4615\n\n\nNotice from the above we can perform the main arithmetic commands using keyboard symbols: + (add); - (minus); * (multiply); / (divide); ^ (power)\nObjects can change values when you run code. For example in the code below:\n\na <- 2000\nb <- 5\n\na <- b\n\na <- a * b\nprint(a)\n\n[1] 25\n\n\nWhat’s going on here?\n\nline 1 sets a to equal 2000 (note: don’t use commas in writing numbers a <- 2,000 would bring up an error),\nline 2 sets b to equal 5,\nline 4 overwrites the value of a with the value stored in b, making object a now equal to 5\nline six is now 5 * 5\n\n\n\n2.4.1.1 Questions\n\nwhat are the outputs of the following code snippets/what do they do? One of the examples might not output anything, why is that? Type the code into your script file to check your answers:\ncode example 1\n\nrabbits <- 50\nfeet <- 4\n\ntotalfeet <- rabbits * feet\nprint(totalfeet)\n\n\nanswer200\n\n\ncode example 2\n\np <- 3.14 - 0.14\nr <- 5\n\nprint(p * r^2)\n\n\nanswer75\n\n\ncode example 3\n\ntax <- 17.5\nprice <- 4.50\nsales <- 128\ntax <- 20\n\nincome <- (sales * price) * (1 + (tax/100))\n\n\nanswer# prints nothing! there isn't a print statement\n\n\n\n\n2.4.2 Naming objects\nCorrectly naming objects is very important. You can give an object almost any name, but there are a few rules to follow:\n\nName them something sensible\nR is case sensitive, myName is not equal to (!=) myname\n\nDon’t use spaces in names\nDon’t start a name with a number\nKeep punctuation in object names to underscore (_ and full stop .) e.g. my_name, my.name.\nStick to a convention for all your objects, it’ll make your code easier to read, e.g.\n\n\nmyName, yourName, ourName (this is camelCase 2)\n\nmy_name, your_name, our_name\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe actual name of an object has no effect on what it does (other than invalid names breaking your program!). For example age <- \"Barry\" is perfectly valid to R, it’s just a real pain for a human to read.\n\n\n\n2.4.2.1 Questions\n\nWhich of these are valid R object names:\n\nmy_Number\nmy-Number\nmyNumber!\nfirst name\nFIRSTname\ni\n3names\nnames3\n\n\nanswers# my_Number  (VALID)\n# my-Number  (VALID)\n# myNumber!  (INVALID due to !)\n# first name (INVALID due to space)\n# FIRSTname  (VALID but don't recommend so many caps)\n# i          (VALID)\n# 3names     (INVALID starts with a 3)\n# names3     (VALID)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor more information on the R programming style guide, see this\n\n\n\n2.4.3 Comments\nCode can often look confusing and it’s a good idea to add # comments to your code to make it more understandable for you and others. The computer ignores comments when running your code:\n\n# this calculates the average sales per shop\n\nincome1 <- 132\nincome2 <- 665\nincome3 <- 233\nincome4 <- 1200\n\nshops <- 4 # everything after the hash is a comment\n\navgSales <- sum(income1, income2, income3, income4) / shops  \n\n# sometimes you might want to comment out code that\n# is no longer needed, but might be useful later\n# standard_deviation <- sd(c(income1, income2, income3, income4) )\n# the above code isn't run\n\nprint(avgSales) # but this code is\n\n[1] 557.5"
  },
  {
    "objectID": "index.html#sec-datatypes",
    "href": "index.html#sec-datatypes",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.5 Datatypes",
    "text": "2.5 Datatypes\nWe have already met two different datatypes, the character datatype for words and letters (e.g. \"Peter\") and the numeric datatype for numbers (e.g. 12). Datatypes tell R how to handle data in certain circumstances. Sometimes data will be of the wrong datatype and you will need to convert between datatypes.\n\nweeks <- 4\ndays_in_week <- \"7\"\n\n# we now attempt to multiply a number by a string\n# but it doesn't work!\ntotal_days <- weeks * days_in_week \n\nError in weeks * days_in_week: non-numeric argument to binary operator\n\n\nWhilst R will understand what to do when we multiply numbers with numbers, it gets very confused and raises an error when we try to perform an arithmetic operation using words and numbers.\nTo perform the calculation we will need to convert the days_in_week from a string to a number, using the as.numeric(<text>) command:\n\nweeks <- 4\ndays_in_week <- \"7\"\n\n# we now attempt to multiply a number by a string\ntotal_days <- weeks * as.numeric(days_in_week)\n\nThere is a logical datatype for boolean values of TRUE and FALSE. This will become a lot more useful later.\n\nlegs_snake <- TRUE # you can specify logical values directly\ndogs_legs <- 4\nlegs_dog <- dogs_legs > 0 # or as part of a calculation\n\n# Do dog's have legs?\nprint(legs_dog)\n\n[1] TRUE\n\n\nThere are actually three datatypes for numbers in R, numeric for most of your work, the rarer integer specifically for whole numbers and the even rarer complex for complex numbers. When you are looking at categorical data, factors are used on top of the underlying datatype to store the different values, for example you might have a field of character to store countries, factors would then list the different countries stored in this character field.\nTo change from one datatype to another we use the as.____ command: as.numeric(<text>), as.logical(<data>), as.character(<numeric>).\n\n2.5.0.1 Questions\n\n\nCan you spot the error(s) in this code and fix them so it outputs: “July is month 7”?\n\n\nmonth <- \"July\"\norder <- 7\n  \nprint(month)\nPrint(\"is\")\nprint(month)\nprint(\"order\")\n\n\nanswermonth <- \"July\"\norder <- 7\n  \nprint(month)    \nprint(\"is\")     #1 print needs a lowercase p\nprint(\"month\")  #2 month is a character not an object, use speech marks\nprint(order)    #3 order is an object, not a character, so drop the speech marks\n\n\n\nCan you spot the error(s) in this code and fix it?\n\n\na <- 7\nb <- \"8\"\nc < - 3\n  \nprint(a + b + c)\n\n\nanswera <- 7\nb <- 8 #1 b is numeric so drop the speech marks\nc <- 3 #2 the arrow needs to be together, remove the space\n  \nprint(a + b + c)\n\n\n\nCan you spot the error(s) in this code and fix it?\n\n\npass mark <- 50 \nexam_grade <- 50\n\n# did the student pass?\nprint(exam_grade > pass_mark)\n\n\nanswerpass_mark <- 50 #1 the variable name can't have any spaces\nexam_grade <- 50\n\n# did the student pass?\nprint(exam_grade >= pass_mark) # this needs to be >= as they had a passing grade\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to find out the datatype of an object you can use the structure str command to give you more information about the object. In this instance chr means that month is of character datatype and num means it is of the numeric datatype.\n\nmonth <- \"July\"\nstr(month)\n\n chr \"July\"\n\nmonth <- 7\nstr(month)\n\n num 7\n\n\n\n\n\n2.5.1 Vectors\nSo far we have seen how R does simple calculations and prints out the results. Underlying all of this are vectors. Vectors are data structures that bring together one or data elements of the same datatype. E.g. we might have a numeric vector recording the grades of a class, or a character vector storing the gender of a set of students. To define a vector we use c(<item>, <item>, ...), where c stands for combine. Vectors are very important to R3, even declaring a single object, x <- 6, is creating a vector of size one. Larger vectors look like this:\n\nmaths_grade <-   c(5,    4,    4,    1,     7,     5,     8)\nenglish_grade <- c(8,    5,    3,    2,     3,     6,     9)\ngenders <-      c(\"F\",  \"M\",  \"M\",  \"F\",   \"M\",   \"F\",   \"M\")\nstudents <-     c(\"Joe\", \"Al\", \"Mo\", \"Flo\", \"Olu\", \"Sam\", \"Jimmy\")\n\nYou can quickly perform calculations across whole vectors:\n\n# convert all genders to the lower case form\ntolower(genders) \n\n[1] \"f\" \"m\" \"m\" \"f\" \"m\" \"f\" \"m\"\n\n# raise everyone's maths grade by one(!?)\nmaths_grade + 1\n\n[1] 6 5 5 2 8 6 9\n\n\nWe can also perform calculations across vectors, in the example below we can find out which students got a better grade in Maths than in English.\n\n# this compares each pair of values\n# e.g. the first item in maths_grade (5) with\n# the first item in english_grade (8)\n# and so on\n# This returns a logical vector of TRUE and FALSE\nmaths_grade > english_grade\n\n[1] FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE\n\n# To work out how many students got a better grade \n# in maths than in English we can apply sum()\n# to the logical vector. \n# We know that TRUE == 1, FALSE == 0,\n# so sum() will count all the TRUEs\nsum(maths_grade > english_grade)\n\n[1] 2\n\n# if you want to find out the average grade for\n# each student in maths and english\n# add both vectors together and divide by 2\n(maths_grade + english_grade) / 2\n\n[1] 6.5 4.5 3.5 1.5 5.0 5.5 8.5\n\n# we can use square brackets to pick a value from a vector\n# vectors start couting from 1, so students[1] would pick Jo\nstudents[1]\n\n[1] \"Joe\"\n\n# we can pass a numeric vector to a another vector to create a\n# subset, in the example below we find the 3rd and 5th item\n\nstudents[c(3,5)]\n\n[1] \"Mo\"  \"Olu\"\n\n# we can also use a vector of TRUE and FALSE to pick items\n# TRUE will pick an item, FALSE will ignore it\n# for each maths_grade > english_grade that is TRUE\n# the name in that position in the student vector will be shown\nstudents[maths_grade > english_grade]\n\n[1] \"Mo\"  \"Olu\"\n\n\nYou should be careful when trying to compare vectors of different lengths. When combining vectors of different lengths, the shorter vector will match the length of the longer vector by wrapping its values around. For example if we try to combine a vector of the numbers 1 ot 10 with a two item logical vector TRUE FALSE, the logical vector will repeat 5 times: c(TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE). We can use this vector as a mask to return the odd numbers, TRUE means keep, FALSE means ignore:\n\nnums <- c(1,2,3,4,5,6,7,8,9,10)\nmask <- c(TRUE, FALSE) \n\n# you can see the repeat of mask by pasting them together\npaste(nums, mask)\n\n [1] \"1 TRUE\"   \"2 FALSE\"  \"3 TRUE\"   \"4 FALSE\"  \"5 TRUE\"   \"6 FALSE\" \n [7] \"7 TRUE\"   \"8 FALSE\"  \"9 TRUE\"   \"10 FALSE\"\n\n# now to filter out the numbers we don't want\nnums[mask]\n\n[1] 1 3 5 7 9\n\n\nThis might not seem very useful, but it comes in very handy when we want to perform a single calculation across a whole vector. For example, we want to find all the students who achieved grade 5 in English, the below code creates a vector of 5s the same size as english_grade:\n\n# this can also be rewritten english_grade >= c(5)\n# note, when we are doing a comparison, we need to use double ==\nstudents[english_grade == 5]\n\n[1] \"Al\"\n\n#which is the same as\nstudents[english_grade == c(5,5,5,5,5,5,5)]\n\n[1] \"Al\"\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen we are doing a comparison, we need to use double == equals sign. Using a single equals sign is the equivalent of an assignment = is the same as <-\n\n\n\n\n\n\n\n\nTip\n\n\n\nThere are several shortcuts that you can take when creating vectors. Instead of writing a whole sequence of numbers by hand, you can use the seq(<start>, <finish>, <step>) command. For example:\n\n# the step default is 1, so you can miss it from seq(1,10,1)\nseq(1,10)   == c(1,2,3,4,5,6,7,8,9,10)\nseq(1,10,2) == c(1,3,5,7,9)\n\nThis allows for some pretty short ways of solving quite complex problems, for example if you wanted to know the sum of all the multiples of 3 and 5 below 1000, you could write it like this:\n\n# the unique() command gives you the unique items in a vector\nsum(unique(c(seq(3, 999, 3), seq(5, 999, 5))))\n\nAnother shortcut is writing T, F, or 1, 0 instead of the whole words TRUE, FALSE:\n\nc(T, F) == c(1, 0) == c(TRUE, FALSE)\n\n\n\n\n2.5.2 Questions\n\n\nCan you spot the four problems with this code:\n\n\nnums <- v(1,2,\"3\",4,7,2,2)\nsum(nums)\nmean(nums)\n# return a vector of all numbers greater than 2\nnums(nums >= 2)\n\n\nanswernums <- c(1,2,3,4,7,2,2) \n#1 a vector is declared using c(), not v()\n#2 3 should be numeric, so no need for speech marks\n# (though technically R would do this conversion for you!)\n\nsum(nums)\nmean(nums)\n# return a vector of all numbers greater than 2\nnums[nums >= 2] #3 to pick items from another vector, use square brackets\n\n\n\nCreate a vector to store the number of glasses of water you have drunk for each day in the last 7 days. Work out:\n\nthe average number of glasses for the week,\nthe total number of glasses,\nthe number of days where you drank less than 2 glasses (feel free to replace water with your own tipple: wine, coffee, tea, coke, etc.)\n\n\n\n\nanswerglasses <- c(6,1,3,2,3,0)\nmean(glasses)\nsum(glasses)\nsum(glasses < 2)\n\n\n\nUsing the vectors below, create a program that will find out the average grade for females taking English:\n\n\nenglish_grade <- c(8,5,3,2,3,6,9)\ngenders <- c(\"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\")\n\n\nanswerenglish_grade <- c(8,5,3,2,3,6,9)\ngenders <- c(\"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\")\nmean(english_grade[genders == \"F\"])\n\n\n\n\n2.5.3 Summary questions\nNow you have covered the basics of R, it’s time for some questions to check your understanding. These questions will cover all the material you have read so far and don’t be worried if you need to go back and check something. Exemplar answers are provided, but don’t worry if your solution looks a little different, there are often multiple ways to achieve the same outcome.\n\n\nDescribe three datatypes that you can use in your program?\n\n\nanswerprint(\"numeric for numbers\")\nprint(\"character for words/strings\")\nprint(\"logical for boolean values\")\n\n\n\nWhat are two reasons that you might use comments?\n\n\nanswer# to make your code more understandable\n# to disable bits of code that you might want to reenable later\n\n\n\n\nWhich object names are valid?\n\nmy_name\nyour name\nour-name\nTHYname\n\n\n\n\nanswer# my_name - VALID\n# your name - INVALID use of space\n# our-name - INVALID use of hyphen\n# THYname - VALID\n\n\n\nCan you spot the four errors in this code:\n\n\nstu1 <- 12\n2stu <- 13\nstu3 <- \"15\"\n\n# now work out the average of the ages\navg < - (Stu1 + stu2 + stu3) / 3\nprint(avg)\n\n\nanswerstu1 <- 12\nstu2 <- 13 #1 2stu to stu2, cannot start name with a number\nstu3 <- 15 #2 no need for speech marks on \"15\"\n\n# now work out the average of the ages\navg <- (stu1 + stu2 + stu3) / 3 #3 broken arrow < - #4 capital letter on Stu1\nprint(avg)\n\n\n\n[Extension] Calculate the number of seconds since 1970.\n\n\nanswerthis_year <- 2022\nfocus_year <- 1970\n\n(this_year - focus_year) * 365 * 24 * 60 * 60"
  },
  {
    "objectID": "index.html#packages-and-libraries",
    "href": "index.html#packages-and-libraries",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.6 Packages and libraries",
    "text": "2.6 Packages and libraries\nR comes with some excellent statistical tools, but often you will need to supplement them with packages4 . Packages contain functionality that isn’t built into R by default, but you can choose to load or install them to meet the needs of your tasks. For example you have code packages to deal with SPSS data, and other packages to run machine learning algorithms. Nearly all R packages are free to use!\n\n2.6.1 Installing and loading packages\nTo install a package you can use the package tab in the bottom right-hand panel of RStudio and follow the steps from Section 2.2.2. Alternatively you can install things by typing:\n\ninstall.packages(\"tidyverse\")\n\nNote that the instruction is to install packages, you can pass a vector of package names to install multiple packages at the same time:\n\ninstall.packages(c(\"tidyverse\",\"readxl\",\"haven\"))\n\nOnce a package is installed it doesn’t mean that you can use it, yet. You will need to load the package. To do this you need to use the library(<package_name>) command, for example:\n\nlibrary(tidyverse)\n\n\n\n\n\n\n\nImportant\n\n\n\nSome packages might use the same function names as other packages, for example select might do different things depending on which package you loaded last. As a rule of thumb, when you start RStudio afresh, make sure that you load the tidyverse package after you have loaded all your other packages. To read more about this problem see Section 11.1"
  },
  {
    "objectID": "index.html#the-tidyverse",
    "href": "index.html#the-tidyverse",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.7 The tidyverse",
    "text": "2.7 The tidyverse\nThis course focuses on using the tidyverse; a free collection of programming packages that will allow you to write code that imports data, tidys it, transforms it into useful datasets, visualises findings, creates statistical models and communicates findings to others data using a standardised set of commands.\n\n\nData science workflow - RStudio\n\n\nFor many people the tidyverse is the main reason that they use R. The tidyverse is used widely in government, academia, NGOs and industry, notable examples include the Financial Times and the BBC. Code in the tidyverse can be (relatively) easily understood by others and you, when you come back to a project after several months.\n\n\n\n\n# load the tidyverse packages\nlibrary(tidyverse)\n\n# download Covid data from website\ndeaths <- read.csv(\"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/excess_mortality/excess_mortality.csv\")\n\ndeaths <- deaths %>% \n     filter(location %in% \n              c(\"United States\", \"United Kingdom\", \n                \"Sweden\", \"Germany\")) %>%\n  mutate(date = as.Date(date))\n\nggplot(data=deaths) +\n  geom_line(aes(x = date, \n                y = excess_per_million_proj_all_ages, \n                colour=location)) +\n  theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTry this out\nThe code above transforms data and converts it into a graph. It doesn’t have any comments, but you should hopefully be able to understand what a lot of the code does by just reading it. Can you guess what each line does? Try running the code by selecting parts of it and pressing control | command ⌘ and Enter"
  },
  {
    "objectID": "index.html#sec-loading",
    "href": "index.html#sec-loading",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.8 Loading data",
    "text": "2.8 Loading data\nWe can’t do much with R without loading data from elsewhere. Data will come in many formats and R should be able to deal with all of them. Some of the datasets you access will be a few rows and columns; others, like the ones we are going to use on this course, might run into hundreds of thousands or even millions of rows and hundreds or thousands of columns. Depending on the format you are using, you might need to use specific packages. A few of the data file types you might meet are described below:\n\n\n\n\n\n\nFile type\nDescription\n\n\n\nComma separated values [.csv]\nAs it says in the name, .csv files store data by separating data items with commas. They are a common way of transferring data and can be easily created and read by Excel, Google spreadsheets and text editors (in addition to R). CSVs aren’t compressed so will generally be larger than other file types. They don’t store information on the types of data stored in the file so you might find yourself having to specify that a date column is a date, rather than a string of text. You can read and write csv files without the need to load any packages, but if you do use readr you might find things go much faster.\n\n\nExcel [.xls | .xlsx | .xlsxm]\nExcel files store data in a compressed custom format. This means files will generally be smaller than CSVs and will also contain information on the types of data stored in different columns. R can read and write these files using the openxlsx package, but you can also use the tidyverse’s readxl for reading, and writexl for writing for excel formats.\n\n\nR Data [.rds]\nR has it’s own data format, .rds. Saving to this format means that you will make perfect copies of your R data, including data types and factors. When you load .rds files they will look exactly the same as when you saved them. Data can be highly compressed and it’s one of the fastest formats for getting data into R. You can read and write .rds files without the need to load any packages, but using the functions in readr might speed things up a bit. You won’t be able to look at .rds files in other programs such as Excel\n\n\nArrow [.parquet]\nApache Arrow .parquet is a relatively new format that allows for the transfer of files between different systems. Files are small and incredibly fast to load, whilst looking exactly the same as when you save them. The PISA dataset used here, that takes ~20 seconds to load in .rds format, will load in less than 2 seconds in .parquet format. Because of the way that data is stored you won’t be able to open these files in programs such as Excel. You will need the arrow package to read and write .parquet files.\n\n\nSPSS [.sav]\nSPSS is a common analysis tool in the world of social science. The native format for SPSS data is .sav. These files are compressed and include information on column labels and column datatypes. You will need either the haven or foreign packages to read data into R. Once you have loaded the .sav you will probably want to convert the data into a format that is more suitable for R, normally this will involve converting columns into factors. We cover factors in more detail below.\n\n\nStata [.dta]\n\nhaven or foreign packages to read data into R\n\n\nSAS [.sas]\n\nhaven or foreign packages to read data into R\n\n\nStructured Query Language [.sql]\na common format for data stored in large databases. Normally SQL code would be used to query these, you can use the tidyverse to help construct SQL this through the package dbplyr which will convert your tidyverse pipe code into SQL. R can be set up to communicate directly with databases using the DBI package.\n\n\nJavaScript Object Notation [.json]\n\n.json is a popular format for sharing data on the web. You can use jsonlite and rjson to access this type of data\n\n\n\nFor this course we will be looking at .csv, excel, .rds and parquet files.\n\n2.8.1 Dataframes\nLoading datasets into R will normally store them as dataframes (also known as tibbles when using the tidyverse). Dataframes are the equivalent of tables in a spreadsheet, with rows, columns and datatypes.\n\n\n\nThe table above has 4 columns, each column has a datatype, CNT is a character vector, PV1MATH is a double (numeric) vector, ESCS is a double (numeric) vector and ST211Q01HA is a factor. For more about datatypes, see Section 2.5\n\n\n\n\n\n\nTip\n\n\n\nCore to the tidyverse is the idea of tidy data, a rule of thumb for creating datasets that can be easily manipulated, modeled and presented. Tidy data are datasets where each variable is a column and each observation a row.\nThis data isn’t tidy data as each row has contains multiple exam results (observations):\n\n\nID\nExam 1\nGrade 1\nExam 2\nGrade 2\n\n\n\nR2341\nEnglish\n4\nMaths\n5\n\n\nR8842\nEnglish\n5\n\n\n\n\n\nThis dataframe is tidy data as each student has one entry for each exam:\n\n\nID\nExam\nGrade\n\n\n\nR2341\nEnglish\n4\n\n\nR2341\nMaths\n5\n\n\nR8842\nEnglish\n5\n\n\n\n\n\n\n\n\nFirst we need to get some data into R so we can start analysing them. We can load large datatables into R by either providing the online web address, or by loading it from a local file directory on your hard drive. Both methods are covered below:\n\n2.8.2 Loading data from the web\nTo download files from the web you’ll need to find the exact location of the file you are using. For example below we will need another package, openxlsx, which you need to install before you load it (see: Section 2.2.2, or use line 1 below). The code shown will download the files from an online Google drive directly into objects in R using read.xlsx(<file_web_address>, <sheet_name>):\n\n\n\n\n\n\nTip\n\n\n\nTo convert data on your google drive into a link that works in R, you can use the following website: https://sites.google.com/site/gdocs2direct/. Note that not all read/load commands in R will work with web addresses and some will require you have to copies of the datasets on your disk drive. Additionally, downloading large datasets from the web directly into R can be very slow, loading the dataset from your harddrive will nearly always be much faster.\n\n\n\ninstall.packages(\"openxlsx\")\nlibrary(openxlsx)\n\nresults <- read.xlsx(\"https://drive.google.com/uc?export=download&id=1tp9xe3dS__eg7RrXf0T_oMxcrz_TbMdM\",\n                      sheet=\"Results\")\nschools <- read.xlsx(\"https://drive.google.com/uc?export=download&id=1tp9xe3dS__eg7RrXf0T_oMxcrz_TbMdM\",\n                      sheet=\"Schools\")\n\n\n2.8.3 Loading data from your computer\nDownloading files directly from web addresses can be slow and you might want to prefer to use files saved to your computer’s hard drive. You can do this by following the steps below:\nDownload the PISA_2018_student_subset.parquet file from here and save it to your computer where your R code file is.\nCopy the location of the file (see next step for help)\n\n\nTo find the location of a file in Windows do the following:\n\n\nNavigate to the location of the file in Windows Explorer:\n\n\n\nClick on the address bar\n\n\nCopy the location\n\n\n\nTo find the location of a file in Mac OSX do the following:\n\nOpen Finder\nNavigate to the folder where you saved the file\n\nRight click on the name of the file, then press the option ⌥ (or Alt) button and select Copy <name of file> as Pathname\n\n\nAlternatively, follow this\n\n\n\nTo load this particular data into R we need to use the read_parquet command from the arrow package, specifying the location and name of the file we are loading. See the following code:\n\ninstall.packages(\"arrow\")\nlibrary(arrow)\n\nPISA_2018 <- read_parquet(r\"[C:/Users/Peter/code/PISA_2018_student_subset.parquet]\")\n\n\n2.8.4 Setting working directories\nUsing the setwd(<location>) you can specify where R will look by default for any datasets. In the example below, the dfe_data.xlsx will have been downloaded and stored in C:/Users/Peter/code. By running setwd(\"C:/Users/Peter/code\") R will always look in that location when trying to load files, meaning that read_parquet(r\"[C:/Users/Peter/code/PISA_2018_student_subset.parquet]\") will be treated the same as read_parquet(r\"[PISA_2018_student_subset.parquet]\")\n\n# context: setup\nsetwd(r\"[C:/Users/Peter/code/]\")\nPISA_2018 <- read_parquet(r\"[PISA_2018_student_subset.parquet]\")\n\nTo work out what your current working directory is, you can use getwd().\n\n2.8.5 Proper addresses\nYou might have found that you get an error if you don’t convert your backslashes \\ into forwardslashes /. It’s common mistake and very annoying. In most programming languages a backslash signifies the start of a special command, for example \\n signifies a newline.\nWith R there are three ways to get around the problem of backslashes in file locations, for the location:\"C:\\myfolder\\\" we could:\n\nreplace them with forwardslashes (as shown above):\"C:/myfolder/\"\n\nreplace them with double backslashes (the special character specified by two backslashes is one backslash!):\"C:\\\\myfolder\\\\\"\n\nuse the inbuilt R command to deal with filenames: r\"[C:\\myfolder\\]\"\n\n\n2.8.6 .parquet files\nFor the majority of this workbook you will be using a cutdown version of the PISA_2018 student table. This dataset is huge and we have loaded it into R, selected fields we think are useful, converted column types to work with R and saved in the .parquet format. .parquet files are quick to load and small in size. To load an .parquet file you can use the read_parquet(<location>) command from the arrow package.\n\nlibrary(arrow)\nPISA_2018 <- read_parquet(\"<yourfolder>/PISA_2018_student_subset.parquet\")\n\nIf you want to save out any of your findings, you can use write_parquet(<object>, <location>), where object is the table you are working on and location is where you want to save it.\n\nlibrary(tidyverse)\nwrite_rds(PISA_2018 %>% filter(CNT==\"France\"),\n                      \"<yourfolder>/pisa_france_2018.parquet\")\n\n\n2.8.7 .csv files\nA very common way of distributing data is through .csv files. These files can be easily compressed and opened in common office spreadsheet tools such as Excel. To load a .csv we can use read_csv(\"<file_location>\")\n\nlibrary(tidyverse)\n# loading from a website\ndata <- read_csv(\"https://barrolee.github.io/BarroLeeDataSet/BLData/BL_v3_MF.csv\")\n\n# loading from your hard drive\ndata <- read_csv(\"<your_folder>/BL_v3_MF.csv\")\n\nYou might want to save your own work as a .csv for use later or for manipulation in another tool e.g. Excel. To do this we can use write_csv(<your_data>, \"<your_folder><name>.csv\"). NOTE: don’t forget to add .csv to the end of your “.csv”, otherwise you might struggle to open the file in another program.\n\nlibrary(tidyverse)\n# loading from a website\nwrite_csv(data, \"summary_stats.csv\")"
  },
  {
    "objectID": "index.html#exploring-data",
    "href": "index.html#exploring-data",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.9 Exploring data",
    "text": "2.9 Exploring data\nNow that we have loaded the PISA_2018 dataset we can start to explore it.\nYou can check that the tables have loaded correctly by typing the object name and ‘running’ the line (control|command ⌘ and Enter)\n\nPISA_2018\n\n# A tibble: 612,004 × 205\n   CNT     OECD  ISCEDL   ISCEDD ISCEDO PROGN WVARS…¹ COBN_F COBN_M COBN_S GRADE\n * <fct>   <fct> <fct>    <fct>  <fct>  <fct>   <dbl> <fct>  <fct>  <fct>  <fct>\n 1 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 2 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 3 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 4 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 5 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 6 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 7 Albania No    ISCED l… C      Vocat… Alba…       3 Missi… Missi… Missi… 0    \n 8 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 9 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n10 Albania No    ISCED l… C      Vocat… Alba…       3 Missi… Missi… Missi… 0    \n# … with 611,994 more rows, 194 more variables: SUBNATIO <fct>, STRATUM <fct>,\n#   ESCS <dbl>, LANGN <fct>, LMINS <dbl>, OCOD1 <fct>, OCOD2 <fct>,\n#   REPEAT <fct>, CNTRYID <fct>, CNTSCHID <dbl>, CNTSTUID <dbl>, NatCen <fct>,\n#   ADMINMODE <fct>, LANGTEST_QQQ <fct>, LANGTEST_COG <fct>, BOOKID <fct>,\n#   ST001D01T <fct>, ST003D02T <fct>, ST003D03T <fct>, ST004D01T <fct>,\n#   ST005Q01TA <fct>, ST007Q01TA <fct>, ST011Q01TA <fct>, ST011Q02TA <fct>,\n#   ST011Q03TA <fct>, ST011Q04TA <fct>, ST011Q05TA <fct>, ST011Q06TA <fct>, …\n\n\nWe can see from this that the tibble (another word for dataframe, basically a spreadsheet table) is 612004 rows, with 205 columns 5. This is data for all the students from around the world that took part in PISA 2018. The actual PISA dataset has many more columns than this, but for the examples here we have selected 205 of the more interesting data variables. The column names might seem rather confusing and you might want to refer to the PISA 2018 code book to find out what everything means.\nThe data shown in the console window is only the top few rows and first few columns. To see the whole table click on the Environment panel and the table icon  to explore the table:\n\nAlternatively, you can also hold down command ⌘|control and click on the table name in your R Script to view the table. You can also type View(<table_name>). Note: this has a capital “V”\nIn the table view mode you can read the label attached to each column, this will give you more detail about what the column stores. If you hover over columns it will display the label:\n\nAlternatively, to read the full label of a column, the following code can be used:\n\n# You might also want to read the label of a field\nattr(PISA_2018$ST013Q01TA, \"label\")\n\n[1] \"How many books are there in your home?\"\n\n\nEach view only shows you 50 columns, to see more use the navigation panel:\n\n\n\n\n\n\n\nNote\n\n\n\nTo learn more about loading data from in other formats, e.g. SPSS and STATA, look at the tidyverse documentation for haven.\n\n\nThe PISA_2018 dataframe is made up of multiple columns, with each column acting like a vector, which means each column stores values of only one datatype. If we look at the first four columns of the schools table, you can see the CNTSTUID, ESCS and PV1MATH columns are <dbl> (numeric) and the other three columns are of <fctr> (factor), a special datatype in R that helps store categorical and ordinal variables, see Section 2.11.2 for more information on how factors work.\n\n\n# A tibble: 5 × 5\n  CNTSTUID ST004D01T CNT       ESCS PV1MATH\n     <dbl> <fct>     <fct>    <dbl>   <dbl>\n1   800251 Male      Albania  0.675    490.\n2   800402 Male      Albania -0.757    462.\n3   801902 Female    Albania -2.51     407.\n4   803546 Male      Albania -3.18     483.\n5   804776 Male      Albania -1.76     460.\n\n\n\n\n\n\n\n\nNote\n\n\n\nVectors are data structures that bring together one or more data elements of the same datatype. E.g. we might have a numeric vector recording the grades of a class, or a character vector storing the gender of a set of students. To define a vector we use c(item, item, ...), where c stands for combine. Vectors are very important to R, even declaring a single object, x <- 6, is creating a vector of size one. To find out more about vectors see: Section 2.5.1\n\n\nWe can find out some general information about the table we have loaded. nrow and ncol tell you about the dimensions of the table\n\nnrow(PISA_2018)  # how many rows are in the results table\n\n[1] 612004\n\nncol(PISA_2018)  # how many columns are in the results table\n\n[1] 205\n\n\nIf we want to know the names of the columns we can use the names() command that returns a vector. This can be a little confusing as it’ll return the names used in the dataframe, which can be hard to interpret, e.g. ST004D01T is PISA’s way of encoding gender. You might find the labels in the view of the table available through view(PISA_2018) and the Environment panel easier to navigate:\n\nnames(PISA_2018) # the column names of a table\n\n [1] \"CNT\"          \"OECD\"         \"ISCEDL\"       \"ISCEDD\"       \"ISCEDO\"      \n [6] \"PROGN\"        \"WVARSTRR\"     \"COBN_F\"       \"COBN_M\"       \"COBN_S\"      \n[11] \"GRADE\"        \"SUBNATIO\"     \"STRATUM\"      \"ESCS\"         \"LANGN\"       \n[16] \"LMINS\"        \"OCOD1\"        \"OCOD2\"        \"REPEAT\"       \"CNTRYID\"     \n[21] \"CNTSCHID\"     \"CNTSTUID\"     \"NatCen\"       \"ADMINMODE\"    \"LANGTEST_QQQ\"\n[26] \"LANGTEST_COG\" \"BOOKID\"       \"ST001D01T\"    \"ST003D02T\"    \"ST003D03T\"   \n[31] \"ST004D01T\"    \"ST005Q01TA\"   \"ST007Q01TA\"   \"ST011Q01TA\"   \"ST011Q02TA\"  \n[36] \"ST011Q03TA\"   \"ST011Q04TA\"   \"ST011Q05TA\"   \"ST011Q06TA\"   \"ST011Q07TA\"  \n [ reached getOption(\"max.print\") -- omitted 165 entries ]\n\n\nAs mentioned, the columns in the tables are very much like a collection of vectors, to access these columns we can put a $ [dollar sign] after the name of a table. This allows us to see all the columns that table has, using the up and down arrows to select, press the Tab key to complete:\n\n\nPISA_2018$ST004D01T\n\n [1] Male   Male   Female Male   Male   Female Female Male   Female Female\n[11] Female Female Female Female Male   Female Male   Male   Male   Male  \n[21] Male   Male   Female Male   Male   Female Male   Female Male   Male  \n[31] Female Female Female Female Female Male   Male   Male   Male   Female\n [ reached getOption(\"max.print\") -- omitted 611964 entries ]\nattr(,\"label\")\n[1] Student (Standardized) Gender\nLevels: Female Male Valid Skip Not Applicable Invalid No Response\n\n\n\n\n\nWe can apply functions to the returned column/vector, for example: sum, mean, median, max, min, sd, round, unique, summary, length. To find all the different/unique values contained in a column we can write:\n\nunique(PISA_2018$CNT) # the unique values in this column\n\n [1] Albania                United Arab Emirates   Argentina             \n [4] Australia              Austria                Belgium               \n [7] Bulgaria               Bosnia and Herzegovina Belarus               \n[10] Brazil                 Brunei Darussalam      Canada                \n[13] Switzerland            Chile                  Colombia              \n[16] Costa Rica             Czech Republic         Germany               \n[19] Denmark                Dominican Republic     Spain                 \n[22] Estonia                Finland                France                \n[25] United Kingdom         Georgia                Greece                \n[28] Hong Kong              Croatia                Hungary               \n[31] Indonesia              Ireland                Iceland               \n[34] Israel                 Italy                  Jordan                \n[37] Japan                  Kazakhstan             Korea                 \n[40] Kosovo                \n [ reached getOption(\"max.print\") -- omitted 40 entries ]\n82 Levels: Albania United Arab Emirates Argentina Australia Austria ... Vietnam\n\n\nWe can also combine commands, with length(<vector>) telling you how many items are in the unique(PISA_2018$CNT) command\n\n# tells you the number of countries in PISA 2018\nlength(unique(PISA_2018$CNT))\n\n[1] 80\n\n\nYou might meet errors when you try and run some of the commands because a field has missing data, recorded as NA. In the case below it doesn’t know what to do with the NA values in PV1MATH, so it gives up and returns NA:\n\nmax(PISA_2018$ESCS) # max cultural capital value for all students\n\n[1] NA\n\n\nYou can see the NAs by just loking at this column:\n\nPISA_2018$ESCS # NAs present in data\n\n [1]  0.6747 -0.7566 -2.5112 -3.1843 -1.7557 -1.4855      NA -3.2481 -1.7174\n[10]      NA -1.5617 -1.9952 -1.6790 -1.1337      NA      NA -1.0919 -1.2391\n[19] -0.1641 -0.4510 -0.9622 -0.8303 -1.8772 -1.2963 -1.4784 -2.3759 -0.8440\n[28] -1.2251      NA -2.4655 -1.2018 -0.4426 -1.4634 -2.1813 -1.9087 -1.7194\n[37] -2.7486 -2.0457 -1.8321 -1.8647\n [ reached getOption(\"max.print\") -- omitted 611964 entries ]\nattr(,\"label\")\n[1] \"Index of economic, social and cultural status\"\n\n\nTo get around this you can tell R to remove/ignore the NA values when performing maths calculations:\n\n# max cultural capital score for all students\nmax(PISA_2018$ESCS, na.rm = TRUE) \n\n[1] 4.2051\n\n\n\n\n\n\n\n\nTip\n\n\n\nR’s inbuilt mode function doesn’t calculate the mathematical mode, instead it tells you what type of data you are dealing with. You can work out the mode of data by using the modeest package:\n\nlibrary(modeest)\nmlv(PISA_2018$PV1MATH, method = \"mfv\", na.rm = TRUE)\n\n[1] 455.767\n\n\nThere is more discussion on how to use modes in R here\n\n\nCalculations might also be upset when you try to perform maths on a column that is stored as another datatype. For example if you wanted to work out the mean common number of minutes spent learning the language that the PISA test was sat in, e.g. number of hours of weekly English lessons in England:\n\nmean(PISA_2018$LMINS)\n\n[1] NA\n\n\nLooking at the structure of this column, we can see it is stored as a factor, not as a numeric\n\nstr(PISA_2018$LMINS)\n\n num [1:612004] 90 180 90 90 400 150 NA NA 180 NA ...\n - attr(*, \"label\")= chr \"Learning time (minutes per week) - <test language>\"\n\n\nSo we need to change the type of the column to make it work with the mean command, changing it to as.numeric(<column>) for the calculation, for more details on datatypes, see Section 2.5.\n\n# this isn't ideal for proper analysis as you will need to remove all the \"No Response\" data\nmean(as.numeric(PISA_2018$LMINS), na.rm = TRUE)\n\n[1] 223.747\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo get a good overview of what a table contains, you can use the str(<table_name>) and summary(<table_name>) commands.\n\n\n\n2.9.1 Questions\n\nUsing the PISA_2018 dataset:\n\nuse the Environment window to view the dataset, what is the name and the label of the 100th column?\n\n\nanswer# the 100th column is ST102Q02TA\n# the label is: \"How often during <test language lessons>: The teacher asks questions to check whether we have understood what was taught\"\n\n# you could use View() instead of the environment window, note the capital V\nView(PISA_2018)\n# use could use the vector subset to fetch the 100th name\nnames(PISA_2018)[100]\n\n# you could use the attr function to find the label\nattr(PISA_2018$ST102Q02TA, \"label\")\n# or using the dollar sign to load this field will also give the label\nPISA_2018$ST102Q02TA\n\n\n\nUse the dollar sign $ to return the column ST004D01T. What is stored in this column?\n\n\nanswer# Student (Standardized) Gender\nPISA_2018$ST004D01T\n\n#  [1] Male   Male   Female Male   Male   Female Female Male   Female Female\n# [11] Female Female Female Female Male   Female Male   Male   Male   Male  \n# [21] Male   Male   Female Male   Male   Female Male   Female Male   Male  \n# [31] Female Female Female Female Female Male   Male   Male   Male   Female\n#  [ reached getOption(\"max.print\") -- omitted 611964 entries ]\n# attr(,\"label\")\n# [1] Student (Standardized) Gender\n# Levels: Female Male Valid Skip Not Applicable Invalid No Response\n\n\n\nHow many students results are in the whole table?\n\n\nanswernrow(PISA_2018)\n# [1] 612004\n\n\n\nWhat unique values does the dataset hold for Mother’s occupation OCOD1 and Father’s occupation OCOD2? Which is larger?\n\n\nanswerunique(PISA_2018$OCOD1)\nunique(PISA_2018$OCOD2)\n\n# you can read the length from the above, or you could use the\n# length command to tell you the length of the vector\n\nlength(unique(PISA_2018$OCOD1))\n# [1] 588\nlength(unique(PISA_2018$OCOD2))\n# [1] 589\n\n\n\nWhat are the maximum, mean, median and minumum science grades PV1SCIE achieved by any student\n\n\nanswer# remember to set the na.rm = TRUE\nmax(PISA_2018$PV1SCIE, na.rm=TRUE)\n# [1] 886.081\nmean(PISA_2018$PV1SCIE, na.rm=TRUE)\n# [1] 460.6944\nmedian(PISA_2018$PV1SCIE, na.rm=TRUE)\n# [1] 458.2\nmin(PISA_2018$PV1SCIE, na.rm=TRUE)\n# [1] 58.736\n\n\n\nExplore the dataset and makes notes about the range of values of 2 other columns"
  },
  {
    "objectID": "index.html#piping-and-dplyr",
    "href": "index.html#piping-and-dplyr",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.10 Piping and dplyr",
    "text": "2.10 Piping and dplyr\nPiping allows us to break down complex tasks into manageable chunks that can be written and tested one after another. There are several powerful commands in the tidyverse as part of the dplyr package that can help us group, filter, select, mutate and summarise datasets. With this small set of commands we can use piping to convert massive datasets into simple and useful results.\nUsing the pipe %>% command, we can feed the results from one command into the next command making for reusable and easy to read code.\n\n\nhow piping works\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe pipe command we are using %>% is from the magrittr package which is installed alongside the tidyverse. Recently R introduced another pipe |> which offers very similar functionality and tutorials online might use either. The examples below use the %>% pipe.\n\n\nLet’s look at an example of using the pipe on the PISA_2018 table to calculate the best performing OECD countries for maths PV1MATH by gender ST004D01T:\n\nPISA_2018 %>% \n  filter(OECD == \"Yes\") %>%\n  group_by(CNT, ST004D01T) %>% \n  summarise(mean_maths = mean(PV1MATH, na.rm=TRUE),\n            sd_maths = sd(PV1MATH, na.rm=TRUE),\n            students = n()) %>%\n  filter(!is.na(ST004D01T)) %>%\n  arrange(desc(mean_maths))\n\n# A tibble: 74 × 5\n# Groups:   CNT [37]\n   CNT            ST004D01T mean_maths sd_maths students\n   <fct>          <fct>          <dbl>    <dbl>    <int>\n 1 Japan          Male            533.     90.5     2989\n 2 Korea          Male            530.    102.      3459\n 3 Estonia        Male            528.     85.0     2665\n 4 Japan          Female          523.     82.2     3120\n 5 Korea          Female          523.     96.0     3191\n 6 Switzerland    Male            520.     92.7     3033\n 7 Estonia        Female          519.     76.0     2651\n 8 Czech Republic Male            518.     98.0     3501\n 9 Belgium        Male            518.     95.9     4204\n10 Poland         Male            517.     91.8     2768\n# … with 64 more rows\n\n\n\nline 1 passes the whole PISA_2018 dataset and pipes it into the next line %>%\n\nline 2 filters out any results that are from non-OECD countries by finding all the rows where OECD equals == “Yes”, this is then piped to the next line\nline 3 groups the data by country CNT and by student gender ST004D01T, this is then piped to the next line\nline 4-6 the summarise command performs a calculation on the country and gender groupings returning three new columns, each command on a new line and separated by a comma: the mean value for maths mean_maths, the standard deviation sd_maths and a column telling us how many students were in each grouping using the n() which returns the number of rows in a group. These new columns and the grouping columns are then piped to the next line\nline 7 filters out any gender ST004D01T that is NA. First is finds all the students that have NA as their gender by using is.na(ST004D01T), then is NOTs/flips the result using the exclamation mark !, giving those students who don’t have their gender set to NA. The filtered data is then piped to the next line\nline 8, finally we arrange / sort the results in descending order by the mean_maths column. The default for arrange is ascending order, leave out the desc(  ) for the numbers to be ordered in the opposite way.\n\nMales get a slightly better maths score than Females for this PV1MATH score, other scores are available, please read Section 10.1.4.1 to find out more about the limitations of using this value.\n\n\n\n\n\n\nNote\n\n\n\nwe met the assignment command earlier <-. Within the tidyverse commands we use the equals sign instead =.\n\n\nThe commands we have just used come from a package within the tidyverse called dplyr, let’s take a look at what they do:\n\n\n\n\n\n\n\ncommand\npurpose\nexample\n\n\n\nselect\nreduce the dataframe to the fields that you specify\nselect(<field>, <field>, <field>)\n\n\nfilter\nget rid of rows that don’t meet one or more criteria\nfilter(<field> <comparison>)\n\n\ngroup\ngroup fields together to perform calculations\ngroup_by(<field>, <field>))\n\n\nmutate\nadd new fields or change values in current fields\nmutate(<new_field> = <field> / 2)\n\n\nsummarise\ncreate summary data optionally using a grouping command\nsummarise(<new_field> = max(<field>))\n\n\narrange\norder the results by one or more fields\narrange(desc(<field>))\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want to explore more of the functions of dplyr, take a look at the helpsheet\n\n\n\nAdjust the code above to find out the lowest performing countries for reading PV1READ by gender that are not in the OECD\n\nanswerPISA_2018 %>% \n  filter(OECD == \"No\") %>%\n  group_by(CNT, ST004D01T) %>% \n  summarise(mean_read = mean(PV1READ, na.rm=TRUE),\n            sd_read = sd(PV1READ, na.rm=TRUE),\n            students = n()) %>%\n  filter(!is.na(ST004D01T)) %>%\n  arrange(mean_read)\n\n\n\n\n2.10.1 select\nThe PISA_2018 dataset has far too many fields, to reduce the number of fields to focus on just a few of them we can use select\n\nPISA_2018 %>% select(CNT,ESCS, ST004D01T, ST003D02T)\n\n# A tibble: 612,004 × 4\n   CNT       ESCS ST004D01T ST003D02T\n   <fct>    <dbl> <fct>     <fct>    \n 1 Albania  0.675 Male      February \n 2 Albania -0.757 Male      July     \n 3 Albania -2.51  Female    April    \n 4 Albania -3.18  Male      April    \n 5 Albania -1.76  Male      March    \n 6 Albania -1.49  Female    February \n 7 Albania NA     Female    July     \n 8 Albania -3.25  Male      August   \n 9 Albania -1.72  Female    March    \n10 Albania NA     Female    July     \n# … with 611,994 more rows\n\n\nYou might also be in the situation where you want to select everything but one or two fields, you can do this with the negative signal -:\n\nPISA_2018 %>% select(-CNT, -OECD)\n\n# A tibble: 612,004 × 203\n   ISCEDL ISCEDD ISCEDO PROGN WVARS…¹ COBN_F COBN_M COBN_S GRADE SUBNA…² STRATUM\n   <fct>  <fct>  <fct>  <fct>   <dbl> <fct>  <fct>  <fct>  <fct> <fct>   <fct>  \n 1 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 2 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 3 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 4 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 5 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 6 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 7 ISCED… C      Vocat… Alba…       3 Missi… Missi… Missi… 0     Albania ALB - …\n 8 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 9 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n10 ISCED… C      Vocat… Alba…       3 Missi… Missi… Missi… 0     Albania ALB - …\n# … with 611,994 more rows, 192 more variables: ESCS <dbl>, LANGN <fct>,\n#   LMINS <dbl>, OCOD1 <fct>, OCOD2 <fct>, REPEAT <fct>, CNTRYID <fct>,\n#   CNTSCHID <dbl>, CNTSTUID <dbl>, NatCen <fct>, ADMINMODE <fct>,\n#   LANGTEST_QQQ <fct>, LANGTEST_COG <fct>, BOOKID <fct>, ST001D01T <fct>,\n#   ST003D02T <fct>, ST003D03T <fct>, ST004D01T <fct>, ST005Q01TA <fct>,\n#   ST007Q01TA <fct>, ST011Q01TA <fct>, ST011Q02TA <fct>, ST011Q03TA <fct>,\n#   ST011Q04TA <fct>, ST011Q05TA <fct>, ST011Q06TA <fct>, ST011Q07TA <fct>, …\n\n\nYou might find that you have a vector of column names that you want to select, to do this, we can use the any_of command:\n\nmy_fields <- c(\"CNTSTUID\", \"CNTSCHID\", \"ST004D01T\")\nPISA_2018 %>% select(any_of(my_fields))\n\n# A tibble: 612,004 × 3\n   CNTSTUID CNTSCHID ST004D01T\n      <dbl>    <dbl> <fct>    \n 1   800251   800002 Male     \n 2   800402   800002 Male     \n 3   801902   800002 Female   \n 4   803546   800002 Male     \n 5   804776   800002 Male     \n 6   804825   800002 Female   \n 7   804983   800002 Female   \n 8   805287   800002 Male     \n 9   805601   800002 Female   \n10   806295   800002 Female   \n# … with 611,994 more rows\n\n\nWith hundreds of fields, you might want to focus on fields whose names match a certain pattern, to do this you can use starts_with, ends_with, contains:\n\nPISA_2018 %>% select(ends_with(\"NA\"))\n\n# A tibble: 612,004 × 19\n   ST011Q16NA ST012Q05NA ST012…¹ ST012…² ST125…³ ST060…⁴ ST061…⁵ IC009…⁶ IC009…⁷\n   <fct>      <fct>      <fct>   <fct>   <fct>     <dbl> <fct>   <fct>   <fct>  \n 1 Yes        <NA>       One     One     6 year…      31 45      Yes, a… No     \n 2 Yes        Three or … One     None    4 years      37 45      No      Yes, b…\n 3 No         One        None    None    4 years      NA 45      Yes, a… Yes, a…\n 4 No         <NA>       None    One     1 year…      31 45      Yes, a… No     \n 5 No         One        One     None    3 years      80 100     Yes, a… Yes, a…\n 6 No         Three or … One     None    6 year…      24 25      Yes, a… Yes, a…\n 7 <NA>       <NA>       <NA>    <NA>    <NA>         NA <NA>    <NA>    <NA>   \n 8 No         None       None    None    1 year…      NA 45      <NA>    <NA>   \n 9 Yes        Three or … One     One     4 years      36 45      Yes, a… Yes, a…\n10 <NA>       <NA>       <NA>    <NA>    <NA>         NA <NA>    <NA>    <NA>   \n# … with 611,994 more rows, 10 more variables: IC009Q07NA <fct>,\n#   IC009Q10NA <fct>, IC009Q11NA <fct>, IC008Q07NA <fct>, IC008Q13NA <fct>,\n#   IC010Q02NA <fct>, IC010Q05NA <fct>, IC010Q06NA <fct>, IC010Q09NA <fct>,\n#   IC010Q10NA <fct>, and abbreviated variable names ¹​ST012Q06NA, ²​ST012Q09NA,\n#   ³​ST125Q01NA, ⁴​ST060Q01NA, ⁵​ST061Q01NA, ⁶​IC009Q05NA, ⁷​IC009Q06NA\n\n\nWhen you come to building your statistical models you often need to use numeric data, you can find the columns that have only numbers in them by the following. Be warned though, sometimes there are numeric fields which have a few words in them, so R treats them as characters. Use the PISA codebook to help work out where those numbers are.\n\nPISA_2018 %>% select(where(is.numeric)) %>% names()\n\n [1] \"WVARSTRR\"   \"ESCS\"       \"LMINS\"      \"CNTSCHID\"   \"CNTSTUID\"  \n [6] \"ST060Q01NA\" \"MMINS\"      \"SMINS\"      \"TMINS\"      \"CULTPOSS\"  \n[11] \"WEALTH\"     \"PV1MATH\"    \"PV1READ\"    \"PV1SCIE\"    \"ATTLNACT\"  \n[16] \"BELONG\"     \"DISCLIMA\"  \n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you do want to change the type of a column to numeric you are going to neeed to:\n\n\nfilter out the offending rows, and\n\nmutate the column to be numeric: col = as.numeric(col)\n\n\n\n\n\n2.10.1.1 Questions\n\n\nSpot the three errors with the following select statement\n\n\nPISA_2018 \n  select(CNT BELONG) %>%\n\n\nanswerPISA_2018 %>%  #1 missing pipe\n  select(CNT, BELONG) #2 no comma between column names, #3 stray pipe on end\n\n\n\nWrite a select statement to display the month ST003D02T and year of birth ST003D03T and the gender ST004D01T of each student.\n\n\nanswerPISA_2018 %>% \n  select(ST003D02T, ST003D03T, ST004D01T)\n\n\n\nWrite a select statement to show all the fields that are to do with digital skills, e.g. IC150Q01HA\n\n\n\nanswerPISA_2018 %>% \n  select(starts_with(\"IC15\"))\n\n\n\n[EXTENSION] Adjust the answer to Q3 so that you select the gender ST004D01T and the ID CNTSTUID of each student in addition to the IC15____ fields\n\n\nanswerPISA_2018 %>% \n  select(CNTSTUID, ST004D01T, starts_with(\"IC15\"))\n\n\n\n\n2.10.2 filter\nNot only does the PISA_2018 dataset have a huge number of columns, it has hundred of thousands of rows. We want to filter this down to the students that we are interested in, i.e. filter out data that isn’t useful for our analysis. If we only wanted the results that were Male, we could do the following:\n\nPISA_2018 %>% \n  select(CNT, ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\")\n\n# A tibble: 307,044 × 5\n   CNT       ESCS ST004D01T ST003D02T PV1MATH\n   <fct>    <dbl> <fct>     <fct>       <dbl>\n 1 Albania  0.675 Male      February     490.\n 2 Albania -0.757 Male      July         462.\n 3 Albania -3.18  Male      April        483.\n 4 Albania -1.76  Male      March        460.\n 5 Albania -3.25  Male      August       441.\n 6 Albania NA     Male      March        280.\n 7 Albania -1.09  Male      March        523.\n 8 Albania -1.24  Male      June         314.\n 9 Albania -0.164 Male      August       428.\n10 Albania -0.451 Male      December     369.\n# … with 307,034 more rows\n\n\nWe can combine filter commands to look for Males born in September and where the PV1MATH figure is greater than 750. We can list multiple criteria in the filter by separating the criteria with commas, using commas mean that all of these criteria need to be TRUE for a row to be returned. A comma in a filter is the equivalent of an AND, :\n\nPISA_2018 %>% \n  select(CNT, ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\",\n         ST003D02T == \"September\",\n         PV1MATH > 750)\n\n# A tibble: 56 × 5\n   CNT                    ESCS ST004D01T ST003D02T PV1MATH\n   <fct>                 <dbl> <fct>     <fct>       <dbl>\n 1 United Arab Emirates  0.861 Male      September    760.\n 2 Belgium               0.887 Male      September    751.\n 3 Bulgaria             -0.160 Male      September    752.\n 4 Canada                1.38  Male      September    751.\n 5 Canada                1.16  Male      September    760.\n 6 Canada                0.760 Male      September    770.\n 7 Switzerland           0.814 Male      September    783.\n 8 Germany               0.740 Male      September    762.\n 9 Spain                 1.46  Male      September    787.\n10 Estonia               0.897 Male      September    752.\n# … with 46 more rows\n\n\nYou can also write it as an ampersand &\n\nPISA_2018 %>% \n  select(CNT, ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\" &\n         ST003D02T == \"September\" &\n         PV1MATH > 750)\n\n\n\n\n\n\n\nImportant\n\n\n\nRemember to include the == sign when looking to filter on equality; additionally, you can use != (not equals), >=, <=, >, <.\nRemember matching is case sensitive, “june” != “June”\n\n\nRather than just looking at September born students, we want to find all the students born in the Autumn term. But if we add a couple more criteria on ST003D02T nothing is returned!\n\nPISA_2018 %>% \n  select(CNT, ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\",\n         ST003D02T == \"September\",\n         ST003D02T == \"October\",\n         ST003D02T == \"November\",\n         ST003D02T == \"December\",\n         PV1MATH > 750)\n\n# A tibble: 0 × 5\n# … with 5 variables: CNT <fct>, ESCS <dbl>, ST004D01T <fct>, ST003D02T <fct>,\n#   PV1MATH <dbl>\n\n\nThe reason is R is looking for inidividual students born in September AND October AND November AND December. As a student can only have one birth month there are no students that meet this criteria. We need to use OR :\nTo create an OR in a filter we use the bar | character, the below looks for all students who are “Male” AND were born in “September” OR “October” OR “November” OR “December”, AND have a PV1MATH > 750.\n\nPISA_2018 %>% \n  select(CNT, ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\",\n         (ST003D02T == \"September\" | ST003D02T == \"October\" | ST003D02T == \"November\" | ST003D02T == \"December\"),\n         PV1MATH > 750)\n\n# A tibble: 175 × 5\n   CNT                     ESCS ST004D01T ST003D02T PV1MATH\n   <fct>                  <dbl> <fct>     <fct>       <dbl>\n 1 Albania               0.539  Male      October      789.\n 2 United Arab Emirates  0.861  Male      September    760.\n 3 United Arab Emirates  0.813  Male      October      753.\n 4 United Arab Emirates  0.953  Male      November     766.\n 5 United Arab Emirates  0.930  Male      November     773.\n 6 United Arab Emirates  1.44   Male      October      752.\n 7 Australia             1.73   Male      December     756.\n 8 Australia            -0.0537 Male      October      827.\n 9 Australia             1.18   Male      November     758.\n10 Australia             1.13   Male      October      757.\n# … with 165 more rows\n\n\nIt’s neater, maybe, to use the %in% command, which checks to see if the value in a column is present in a vector, this can mimic the OR/| command:\n\nPISA_2018 %>% \n  select(CNT, ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\",\n         ST003D02T %in% c(\"September\", \"October\", \"November\", \"December\"),\n         PV1MATH > 750)\n\n\n\n\n\n\n\nTip\n\n\n\nWhen building filters you need to know the range of values that a column can take, we can do this in several ways:\n\n# show the possible levels\nlevels(PISA_2018$ST013Q01TA)\n\n [1] \"0-10 books\"          \"11-25 books\"         \"26-100 books\"       \n [4] \"101-200 books\"       \"201-500 books\"       \"More than 500 books\"\n [7] \"Valid Skip\"          \"Not Applicable\"      \"Invalid\"            \n[10] \"No Response\"        \n\n# show the actual unique values in a field\n# this might be a slightly smaller set of values\nunique(PISA_2018$ST013Q01TA)\n\n[1] 0-10 books          11-25 books         <NA>               \n[4] 26-100 books        101-200 books       More than 500 books\n[7] 201-500 books      \n10 Levels: 0-10 books 11-25 books 26-100 books 101-200 books ... No Response\n\n# You might also want to read the label of a field\nattr(PISA_2018$ST013Q01TA, \"label\")\n\n[1] \"How many books are there in your home?\"\n\n\n\n\n\n2.10.2.1 Questions\n\n\nSpot the three errors with the following select statement\n\n\nPISA_2018 %>% \n  select(CNT) %>%\n  filter(CNT in c(\"France\", \"belgium\")\n         ESCS < 0)\n\n\nanswerPISA_2018 %>% \n  select(CNT, ESCS) %>% #1 you have ESCS in the filter, it needs to be in the select as well\n  filter(CNT %in% c(\"France\", \"Belgium\"), #2 Belgium needs a capital letter\n                                          #3 the %in% command needs percentages\n                                          #4 you need a comma (or &) at the end of the line\n         ESCS < 0)\n\n\n\nUse filter to find all the students with Three or more cars in their home ST012Q02TA. How does this compare to those with no None cars?\n\n\nanswercars_3 <- PISA_2018 %>%\n  select(CNT, ST012Q02TA) %>%\n  filter(ST012Q02TA == \"Three or more\")\n\ncars_0 <- PISA_2018 %>%\n  select(CNT, ST012Q02TA) %>%\n  filter(ST012Q02TA == \"None\")\n\n\n\nAdjust your code in Q2. to find the number of students with Three or more cars in their home ST012Q02TA in Italy, how does this compare with Spain?\n\n\nanswerPISA_2018 %>%\n  select(CNT, ST012Q02TA) %>%\n  filter(ST012Q02TA == \"Three or more\",\n         CNT == \"Italy\")\n\nPISA_2018 %>%\n  select(CNT, ST012Q02TA) %>%\n  filter(ST012Q02TA == \"Three or more\",\n         CNT == \"Spain\")\n\n\n\nWrite a filter to create a table for the number of Female students with reading PV1READ scores lower than 400 in the United Kingdom, store the result as read_low_female, repeat but for Male students and store as read_low_male. Use nrow() to work out if there are more males or females with a low reading score in the UK\n\n\nanswerread_low_female <- PISA_2018 %>% \n  filter(CNT == \"United Kingdom\",\n         PV1READ < 400,\n         ST004D01T == \"Female\")\n\nread_low_male <- PISA_2018 %>% \n  filter(CNT == \"United Kingdom\",\n         PV1READ < 400,\n         ST004D01T == \"Male\")\n\nnrow(read_low_female)\nnrow(read_low_male)\n\n# You could also pipe the whole dataframe into nrow()\nPISA_2018 %>% \n  filter(CNT == \"United Kingdom\",\n         PV1READ < 400,\n         ST004D01T == \"Female\") %>% \n  nrow()\n\n\n\nHow many students in the United Kingdom had no television ST012Q01TA OR no connection to the internet ST011Q06TA. HINT: use levels(PISA_2018$ST012Q01TA) to look at the levels available for each column.\n\n\nanswerPISA_2018 %>% filter(CNT == \"United Kingdom\", \n                     ST011Q06TA == \"No\" |\n                     ST012Q01TA == \"None\")\n\n\n\nWhich countr[y|ies] had students with NA for Gender?\n\n\nanswerPISA_2018 %>% \n  filter(is.na(ST004D01T)) %>%\n  select(CNT)\n\n\n\n\n2.10.3 renaming columns\nVery often when dealing with datasets such as PISA or TIMSS, the column names can be very confusing without a reference key, e.g. ST004D01T, BCBG10B and BCBG11. To rename columns in the tidyverse we use the rename(<new_name> = <old_name>) command. For example, if you wanted to rename the rather confusing student column for gender, also known as ST004D01T, and the column for having a dictionary at home, also known as ST011Q12TA, you could use:\n\nPISA_2018 %>%\n  rename(gender = ST004D01T,\n         dictionary = ST011Q12TA) %>%\n  select(CNT, gender, dictionary) %>% \n  summary()\n\n                   CNT                    gender                dictionary    \n Spain               : 35943   Female        :304958   Yes           :524311  \n Canada              : 22653   Male          :307044   No            : 66730  \n Kazakhstan          : 19507   Valid Skip    :     0   Valid Skip    :     0  \n United Arab Emirates: 19277   Not Applicable:     0   Not Applicable:     0  \n Australia           : 14273   Invalid       :     0   Invalid       :     0  \n Qatar               : 13828   No Response   :     0   No Response   :     0  \n (Other)             :486523   NA's          :     2   NA's          : 20963  \n\n\nIf you want to change the name of the column so that it stays when you need to perform another calculation, remember to assign the renamed dataframe back to the original dataframe. But be warned, you’ll need to reload the full dataset to restore the original names:\n\nPISA_2018 <- PISA_2018 %>%\n    rename(gender = ST004D01T,\n           dictionary = ST011Q12TA)\n\n\n2.10.4 group_by and summarise\nSo far we have looked at ways to return rows that meet certain criteria. Using group_by and summarise we can start to analyse data for different groups of students. For example, let’s look at the number of students who don’t have internet connections at home ST011Q06TA:\n\nPISA_2018 %>% \n  group_by(ST011Q06TA) %>%\n  summarise(student_n = n())\n\n# A tibble: 3 × 2\n  ST011Q06TA student_n\n  <fct>          <int>\n1 Yes           543010\n2 No             49703\n3 <NA>           19291\n\n\n\nLine 1 passes the full PISA_2018 to the pipe\nLine 2 makes groups within PISA_2018 using the unique values of ST011Q06TA\n\nLine 3, these groups are then passed to summarise, which creates a new column called student_n and stores the number of rows in each ST011Q06TA group using the n() command. summarise only returns the columns it creates, or are in the group_by, everything else is discarded.\n\nWhat we might want to do is look at this data from a country by country perspective, by adding another field to the group_by() command, we then group by the unique combination of countries CNT and internet access ST011Q06TA, e.g. Albania+Yes; Albania+No; Albania+NA; Brazil+Yes; etc\n\nint_by_cnt <- PISA_2018 %>% \n  group_by(CNT, ST011Q06TA) %>%\n  summarise(student_n = n())\n\nprint(int_by_cnt)\n\n# A tibble: 240 × 3\n# Groups:   CNT [80]\n   CNT                  ST011Q06TA student_n\n   <fct>                <fct>          <int>\n 1 Albania              Yes             5059\n 2 Albania              No              1084\n 3 Albania              <NA>             216\n 4 United Arab Emirates Yes            17616\n 5 United Arab Emirates No               949\n 6 United Arab Emirates <NA>             712\n 7 Argentina            Yes             9871\n 8 Argentina            No              1781\n 9 Argentina            <NA>             323\n10 Australia            Yes            12547\n# … with 230 more rows\n\n\nsummarise can also be used to work out statistics by grouping. For example, if you wanted to find out the max, mean and min science grade PV1SCIE by country CNT, you could do the following:\n\nPISA_2018 %>% \n  group_by(CNT) %>%\n  summarise(sci_max  = max(PV1SCIE,  na.rm = TRUE),\n            sci_mean = mean(PV1SCIE, na.rm = TRUE),\n            sci_min  = min(PV1SCIE,  na.rm = TRUE))\n\n# A tibble: 80 × 4\n   CNT                    sci_max sci_mean sci_min\n   <fct>                    <dbl>    <dbl>   <dbl>\n 1 Albania                   674.     417.   166. \n 2 United Arab Emirates      778.     425.    86.3\n 3 Argentina                 790.     418.   138. \n 4 Australia                 879.     502.   153. \n 5 Austria                   779.     493.   175. \n 6 Belgium                   764.     502.   196. \n 7 Bulgaria                  741.     426.   145. \n 8 Bosnia and Herzegovina    664.     398.   152. \n 9 Belarus                   799.     474.   192. \n10 Brazil                    747.     407.    95.6\n# … with 70 more rows\n\n\n\n\n\n\n\n\nImportant\n\n\n\ngroup_by() can have unintended consequences in your code if you are saving your pipes to new dataframes. To be safe your can clear any grouping by adding: my_data %>% ungroup()\n\n\n\n2.10.4.1 Questions\n\n\nSpot the three errors with the following summarise statement\n\n\nPISA_2018 %>% \n  group(CNT)\n  summarise(num_stus = n)\n\n\nanswerPISA_2018 %>% \n  group_by(CNT) %>% #1 group_by NOT group #2 missing pipe %>%\n  summarise(num_stus = n()) #3 = n() not = n\n\n\n\nWrite a group_by and summarise statement to work out the mean and median cultural capital value ESCS for each student by country CNT\n\n\n\nanswerPISA_2018 %>%\n  group_by(CNT) %>%\n  summarise(escs_mean = mean(ESCS, na.rm=TRUE),\n            escs_median = median(ESCS, na.rm=TRUE))\n\n\n\nUsing summarise work out, Yes or No, by country CNT and gender ST004D01T, whether students “reduce the energy I use at home […] to protect the environment.” ST222Q01HA. Filter out any NA values on ST222Q01HA:\n\n\nanswerPISA_2018 %>% \n  filter(!is.na(ST222Q01HA)) %>%\n  group_by(CNT, ST004D01T, ST222Q01HA) %>% \n  summarise(n=n())\n\n\n\n\n2.10.5 mutate\nSometimes you will want to adjust the values stored in a field, e.g. converting a distance in miles into kilometres; or compute a new fields based on other fields, e.g. working out a total grade given the parts of a test. To do this we can use mutate. Unlike summarise, mutate retains all the other columns either adding a new column or changing an existing one\n\nmutate(<field> = <field_calculation>)\n\nThe PISA_2018 dataset has results for maths PV1MATH, science PV1SCIE and reading PV1READ. We could combine these to create an overall PISA_grade, and PISA_mean:\n\nPISA_2018 %>%\n  mutate(PV1_total = PV1MATH + PV1SCIE + PV1READ,\n         PV1_mean = PV1_total/3) %>%\n  select(CNT, ESCS, PV1_total, PV1_mean)\n\n# A tibble: 612,004 × 4\n   CNT       ESCS PV1_total PV1_mean\n   <fct>    <dbl>     <dbl>    <dbl>\n 1 Albania  0.675     1311.     437.\n 2 Albania -0.757     1319.     440.\n 3 Albania -2.51      1158.     386.\n 4 Albania -3.18      1424.     475.\n 5 Albania -1.76      1094.     365.\n 6 Albania -1.49      1004.     335.\n 7 Albania NA         1311.     437.\n 8 Albania -3.25      1104.     368.\n 9 Albania -1.72      1268.     423.\n10 Albania NA         1213.     404.\n# … with 611,994 more rows\n\n\n\nline 2 mutate creates a new field called PV1_total made up by adding together the columns for maths, science and reading. Each column acts like a vector and adding them together is the equivalent of adding each students individual grades together, row by row. See Section 2.5.1 for more details on vector addition.\nline 3 inside the same mutate statement, we take the PV1_total calculated on line 2 and divide it by 3, to give us a mean value, this is then assigned to a new column, PV1_mean.\nline 4 this line selects only the fields that we are interested in, dropping the others\n\nWe can use mutate to create subsets of data in fields. For example, if we wanted to see how many students in each country were high performing readers, specified by getting a reading grade of greater than 550, we could do the following:\n\nPISA_2018 %>%\n  mutate(PV1READ_high = PV1READ > 550) %>%\n  group_by(CNT, PV1READ_high) %>%\n  summarise(n = n())\n\n# A tibble: 159 × 3\n# Groups:   CNT [80]\n   CNT                  PV1READ_high     n\n   <fct>                <lgl>        <int>\n 1 Albania              FALSE         6083\n 2 Albania              TRUE           276\n 3 United Arab Emirates FALSE        16567\n 4 United Arab Emirates TRUE          2710\n 5 Argentina            FALSE        11003\n 6 Argentina            TRUE           972\n 7 Australia            FALSE         9311\n 8 Australia            TRUE          4962\n 9 Austria              FALSE         4900\n10 Austria              TRUE          1902\n# … with 149 more rows\n\n\nComparisons can also be made between different columns, if we wanted to find out the percentage of Males and Females that got a better grade in their maths test PV1MATH than in their reading test PV1READ:\n\nPISA_2018 %>%\n  mutate(maths_better = PV1MATH > PV1READ) %>%\n  select(CNT, ST004D01T, maths_better, PV1MATH, PV1READ) %>% \n  filter(!is.na(ST004D01T), !is.na(maths_better)) %>%\n  group_by(ST004D01T) %>%\n  mutate(students_n = n()) %>%\n  group_by(ST004D01T, maths_better) %>%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n# A tibble: 4 × 4\n# Groups:   ST004D01T [2]\n  ST004D01T maths_better      n   per\n  <fct>     <lgl>         <int> <dbl>\n1 Female    FALSE        176021 0.583\n2 Female    TRUE         126157 0.417\n3 Male      FALSE        110269 0.362\n4 Male      TRUE         194178 0.638\n\n\n\nline 2 mutate creates a new field called maths_better made up by comparing the PV1MATH grade with PV1READ and creating a boolean/logical vector for the column.\nline 3 selects a subset of the columns\nline 4 filters out any students that don’t have gender data ST004D01T, or where the calculation on line 2 failed, i.e. PV1MATH or PV1READ was NA\n\nline 5 group on the gender of the student\nline 6 using the group on line 5, use mutate to calculate the total number of Males and Females by looking for the number of rows in each group n(), store this as students_n\n\nline 7 re-group the data on gender ST004D01T and whether the student is better at maths than reading maths_better\n\nline 8 count the number of students, n in each group, as specified by line 7.\nline 9 create a percentage figure for the number of students in each grouping given by line 7. Use the n value from line 8 and the students_n value from line 6. NOTE: we need to use unique(students_n) to return just one value for each grouping rather than a value for every row of the line 7 grouping\n\nFor more information on how to mutate fields using ifelse, see Section 2.11.1\n\n2.10.6 arrange\nThe results returned by pipes can be huge, so it’s a good idea to store them in objects and explore them in the Environment window where you can sort and search within the output. There might also be times when you want to order/arrange the outputs in a particular way. We can do this quite easily in the tidyverse by using the arrange(<column_name>, <column_name>) function.\n\nPISA_2018 %>%\n  select(CNT, ST004D01T, PV1MATH) %>%\n  arrange(PV1MATH)\n\n# A tibble: 612,004 × 3\n   CNT             ST004D01T PV1MATH\n   <fct>           <fct>       <dbl>\n 1 Philippines     Female       24.7\n 2 Jordan          Male         51.0\n 3 Jordan          Female       61.6\n 4 Mexico          Female       64.3\n 5 Kazakhstan      Male         70.4\n 6 Jordan          Male         70.7\n 7 Bulgaria        Male         73.4\n 8 Kosovo          Male         76.0\n 9 North Macedonia Female       78.3\n10 North Macedonia Male         81.2\n# … with 611,994 more rows\n\n\nIf we’re interested in the highest achieving students we can add the desc() function to arrange:\n\nPISA_2018 %>%\n  select(CNT, LANGN, ST004D01T, PV1MATH) %>%\n  arrange(desc(PV1MATH))\n\n# A tibble: 612,004 × 4\n   CNT                  LANGN                  ST004D01T PV1MATH\n   <fct>                <fct>                  <fct>       <dbl>\n 1 Canada               Another language (CAN) Male         888.\n 2 Canada               Another language (CAN) Male         874.\n 3 United Arab Emirates English                Male         865.\n 4 B-S-J-Z (China)      Mandarin               Female       864.\n 5 Australia            English                Male         863.\n 6 B-S-J-Z (China)      Mandarin               Male         861.\n 7 Serbia               Serbian                Male         860.\n 8 Singapore            Invalid                Female       849.\n 9 Australia            Cantonese              Male         845.\n10 Canada               French                 Female       842.\n# … with 611,994 more rows\n\n\n\n2.10.7 Bring everyting together\nWe know that the evidence strongly indicates that repeating a year is not good for student progress, but how do countries around the world differ in terms of the percentage of their students who repeat a year?\n\ndata_repeat <- PISA_2018 %>%\n  filter(!is.na(REPEAT)) %>%\n  group_by(CNT) %>%\n  mutate(total = n()) %>%\n  select(CNT, REPEAT, total) %>%\n  group_by(CNT, REPEAT) %>%\n  summarise(student_n = n(),\n            total = unique(total),\n            per = student_n / unique(total)) %>%\n  filter(REPEAT == \"Repeated a  grade\") %>%\n  arrange(desc(per))\n\nprint(data_repeat)\n\nwrite_csv(data_repeat, \"<folder_location>/repeat_a_year.csv\")\n\n\n\n# A tibble: 77 × 5\n# Groups:   CNT [77]\n   CNT                REPEAT            student_n total   per\n   <fct>              <fct>                 <int> <int> <dbl>\n 1 Morocco            Repeated a  grade      3333  6666 0.5  \n 2 Colombia           Repeated a  grade      2746  7185 0.382\n 3 Lebanon            Repeated a  grade      1580  4756 0.332\n 4 Uruguay            Repeated a  grade      1657  5049 0.328\n 5 Luxembourg         Repeated a  grade      1655  5168 0.320\n 6 Dominican Republic Repeated a  grade      1694  5474 0.309\n 7 Brazil             Repeated a  grade      3227 10438 0.309\n 8 Macao              Repeated a  grade      1135  3773 0.301\n 9 Belgium            Repeated a  grade      2351  8089 0.291\n10 Costa Rica         Repeated a  grade      1904  6571 0.290\n# … with 67 more rows\n\n\n\nLine 2, filter out any NA values in the REPEAT field\nLine 3, group on the country of student CNT\n\nLine 4, create a new column total for total number of rows n() in each country CNT grouping\nLine 5, select on the CNT, REPEAT and total columns\nLine 6, regroup the data on country CNT and whether a student has repeated a year REPEAT, i.e. Albania+Did not repeat a grade; Albania+Repeated a grade; etc.\nLine 7, using the above grouping, count the number of rows in each group n() and assign this to student_n\n\nLine 8, for each grouping keep the total number of students in each country, as calculated on line 4. Note: unique(total) is needed here to return a single value of total, rather than a value for each student in each country\nLine 9, using student_n from line 7 and the number of students per country total, from line 4, create a percentage per for each grouping\nLine 10, as we have percentages for both Repeated a  grade and Did not repeat a  grade, we only need to display one of these. Note: that there is an extra space in this\nLine 11, finally, we sort the data on the per/percentage column, to show the countries with the highest level of repeating a grade. This data is self-recorded by students, so might not be totally reliable!\nLine 15, save the data to your own folder as a csv"
  },
  {
    "objectID": "index.html#advanced-topics",
    "href": "index.html#advanced-topics",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.11 Advanced topics",
    "text": "2.11 Advanced topics\n\n2.11.1 Recoding data (ifelse)\nOften we want to plot values in groupings that don’t yet exist, for example might want to give all schools over a certain size a different colour from others schools, or flag up students who have a different home language to the language that is being taught in school. To do this we need to look at how we can recode values. A common way to recode values is through an ifelse statement:\n\nifelse(<statement(s)>, <value_if_true>, <value_if_false>)\n\nifelse allows us to recode the data. In the example below, we are going to add a new column to the PISA_2018 dataset (using mutate) noting whether a student got a higher grade in their Maths PV1MATH or Reading PV1READ tests. if PV1MATH is bigger then PV1READ, the maths_better is TRUE, else maths_better is FALSE, or in dplyr format:\n\nmaths_data <- PISA_2018 %>%\n  mutate(maths_better = \n           ifelse(PV1MATH > PV1READ,\n                  TRUE, \n                  FALSE)) %>%\n  select(CNT, ST004D01T, maths_better, PV1MATH, PV1READ)\n\nprint(maths_data)\n\n# A tibble: 612,004 × 5\n   CNT     ST004D01T maths_better PV1MATH PV1READ\n   <fct>   <fct>     <lgl>          <dbl>   <dbl>\n 1 Albania Male      TRUE            490.    376.\n 2 Albania Male      TRUE            462.    434.\n 3 Albania Female    TRUE            407.    359.\n 4 Albania Male      TRUE            483.    425.\n 5 Albania Male      TRUE            460.    306.\n 6 Albania Female    TRUE            367.    352.\n 7 Albania Female    FALSE           411.    413.\n 8 Albania Male      TRUE            441.    271.\n 9 Albania Female    TRUE            506.    373.\n10 Albania Female    FALSE           412.    412.\n# … with 611,994 more rows\n\n\nWe now take this new dataset maths_data and look at whether the difference between relative performance in maths and reading is the same for girls and boys:\n\nmaths_data %>% \n  filter(!is.na(ST004D01T), !is.na(maths_better)) %>%\n  group_by(ST004D01T, maths_better) %>%\n  summarise(n = n()) \n\n# A tibble: 4 × 3\n# Groups:   ST004D01T [2]\n  ST004D01T maths_better      n\n  <fct>     <lgl>         <int>\n1 Female    FALSE        176021\n2 Female    TRUE         126157\n3 Male      FALSE        110269\n4 Male      TRUE         194178\n\n\n\nAdjust the code above to work out the percentages of Males and Females ST004D01T in each group. Check to see if the pattern also exists between science PV1SCIE and reading PV1READ:\n\nadding percentage columnPISA_2018 %>%\n  mutate(maths_better = \n           ifelse(PV1MATH > PV1READ,\n                  TRUE, \n                  FALSE)) %>%\n  select(CNT, ST004D01T, maths_better, PV1MATH, PV1READ) %>% \n  filter(!is.na(ST004D01T), !is.na(maths_better)) %>%\n  group_by(ST004D01T) %>%\n  mutate(students_n = n()) %>%\n  group_by(ST004D01T, maths_better) %>%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n\n\ncomparing science and readingPISA_2018 %>%\n  mutate(sci_better = \n           ifelse(PV1SCIE > PV1READ,\n                  TRUE, \n                  FALSE)) %>%\n  select(CNT, ST004D01T, sci_better, PV1SCIE, PV1READ) %>% \n  filter(!is.na(ST004D01T), !is.na(sci_better)) %>%\n  group_by(ST004D01T) %>%\n  mutate(students_n = n()) %>%\n  group_by(ST004D01T, sci_better) %>%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n\n\ncomparing science and mathsPISA_2018 %>%\n  mutate(sci_better = \n           ifelse(PV1SCIE > PV1MATH,\n                  TRUE, \n                  FALSE)) %>%\n  select(CNT, ST004D01T, sci_better, PV1SCIE, PV1MATH) %>% \n  filter(!is.na(ST004D01T), !is.na(sci_better)) %>%\n  group_by(ST004D01T) %>%\n  mutate(students_n = n()) %>%\n  group_by(ST004D01T, sci_better) %>%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n\n\nifelse statements can get a little complicated when using factors (see: Section 2.11.2). Take this example. Let’s flag students who have a different home language LANGN to the language that is being used in the PISA assessment tool LANGTEST_QQQ. We make an assumption here that the assessment tool will be the language used at school, so these students will be learning in a different language to their mother tongue. if LANGN equals LANGTEST_QQQ, the lang_diff is FALSE, else lang_diff is TRUE, this raises an error:\n\nlang_data <- PISA_2018 %>%\n  mutate(lang_diff = \n           ifelse(LANGN == LANGTEST_QQQ,\n                  FALSE, \n                  TRUE)) %>%\n  select(CNT, lang_diff, LANGTEST_QQQ, LANGN)\n\nError in `mutate()`:\n! Problem while computing `lang_diff = ifelse(LANGN == LANGTEST_QQQ,\n  FALSE, TRUE)`.\nCaused by error in `Ops.factor()`:\n! level sets of factors are different\n\n\nThe levels in each field are different, i.e. the range of home languages is larger than the range of test languages. To fix this, all we need to do is cast the factors LANGN and LANGTEST_QQQ as characters using as.character(<field>). This will then allow the comparison of the text stored in each row:\n\nlang_data <- PISA_2018 %>%\n  mutate(lang_diff = \n           ifelse(as.character(LANGN) == as.character(LANGTEST_QQQ),\n                  FALSE, \n                  TRUE)) %>%\n  select(CNT, lang_diff, LANGTEST_QQQ, LANGN)\n\nprint(lang_data)\n\n# A tibble: 612,004 × 4\n   CNT     lang_diff LANGTEST_QQQ LANGN                 \n   <fct>   <lgl>     <fct>        <fct>                 \n 1 Albania TRUE      Albanian     Another language (ALB)\n 2 Albania FALSE     Albanian     Albanian              \n 3 Albania FALSE     Albanian     Albanian              \n 4 Albania FALSE     Albanian     Albanian              \n 5 Albania FALSE     Albanian     Albanian              \n 6 Albania FALSE     Albanian     Albanian              \n 7 Albania NA        <NA>         Missing               \n 8 Albania FALSE     Albanian     Albanian              \n 9 Albania FALSE     Albanian     Albanian              \n10 Albania NA        <NA>         Missing               \n# … with 611,994 more rows\n\n\nWe can now look at this dataset to get an idea of which countries have the largest percentage of students learning in a language other than their mother tongue:\n\nlang_data_diff <- lang_data %>% \n  group_by(CNT) %>%\n  mutate(student_n = n()) %>%\n  group_by(CNT, lang_diff) %>%\n  summarise(n = n(),\n            percentage = 100*(n / max(student_n))) %>%\n    filter(!is.na(lang_diff),\n         lang_diff == TRUE)\n\nprint(lang_data_diff)\n\n# A tibble: 80 × 4\n# Groups:   CNT [80]\n   CNT                    lang_diff     n percentage\n   <fct>                  <lgl>     <int>      <dbl>\n 1 Albania                TRUE        284       4.47\n 2 United Arab Emirates   TRUE       8195      42.5 \n 3 Argentina              TRUE        651       5.44\n 4 Australia              TRUE       2238      15.7 \n 5 Austria                TRUE       1329      19.5 \n 6 Belgium                TRUE       2458      29.0 \n 7 Bulgaria               TRUE        747      14.1 \n 8 Bosnia and Herzegovina TRUE        526       8.12\n 9 Belarus                TRUE        248       4.27\n10 Brazil                 TRUE        297       2.78\n# … with 70 more rows\n\n\nThis looks like a promising dataset, but there are some strange results:\n\nlang_data_diff %>% filter(percentage > 92)\n\n# A tibble: 9 × 4\n# Groups:   CNT [9]\n  CNT             lang_diff     n percentage\n  <fct>           <lgl>     <int>      <dbl>\n1 Hong Kong       TRUE       5880       97.4\n2 Lebanon         TRUE       5339       95.1\n3 Macao           TRUE       3683       97.6\n4 Montenegro      TRUE       6411       96.2\n5 Norway          TRUE       5813      100  \n6 Philippines     TRUE       6823       94.3\n7 B-S-J-Z (China) TRUE      12049       99.9\n8 Singapore       TRUE       6666       99.9\n9 Ukraine         TRUE       5597       93.3\n\n\nExploring data for Ukraine, we can see that a different spelling has been used in each field, Ukrainian and Ukranain.\n\nlang_data %>% filter(CNT == \"Ukraine\")\n\n# A tibble: 5,998 × 4\n   CNT     lang_diff LANGTEST_QQQ LANGN    \n   <fct>   <lgl>     <fct>        <fct>    \n 1 Ukraine TRUE      Ukranian     Ukrainian\n 2 Ukraine TRUE      Ukranian     Ukrainian\n 3 Ukraine TRUE      Ukranian     Ukrainian\n 4 Ukraine TRUE      Ukranian     Russian  \n 5 Ukraine TRUE      Ukranian     Ukrainian\n 6 Ukraine TRUE      Ukranian     Russian  \n 7 Ukraine TRUE      Ukranian     Ukrainian\n 8 Ukraine TRUE      Ukranian     Ukrainian\n 9 Ukraine TRUE      Ukranian     Russian  \n10 Ukraine TRUE      Ukranian     Ukrainian\n# … with 5,988 more rows\n\n\nifelse can help here too. If we pick the spelling we want to stick to, we can recode fields to match:\n\nlang_data %>% \n  mutate(LANGTEST_QQQ = \n           ifelse(as.character(LANGTEST_QQQ) == \"Ukranian\",\n                 \"Ukrainian\",\n                 as.character(LANGTEST_QQQ))) %>%\n  filter(CNT == \"Ukraine\")\n\n# A tibble: 5,998 × 4\n   CNT     lang_diff LANGTEST_QQQ LANGN    \n   <fct>   <lgl>     <chr>        <fct>    \n 1 Ukraine TRUE      Ukrainian    Ukrainian\n 2 Ukraine TRUE      Ukrainian    Ukrainian\n 3 Ukraine TRUE      Ukrainian    Ukrainian\n 4 Ukraine TRUE      Ukrainian    Russian  \n 5 Ukraine TRUE      Ukrainian    Ukrainian\n 6 Ukraine TRUE      Ukrainian    Russian  \n 7 Ukraine TRUE      Ukrainian    Ukrainian\n 8 Ukraine TRUE      Ukrainian    Ukrainian\n 9 Ukraine TRUE      Ukrainian    Russian  \n10 Ukraine TRUE      Ukrainian    Ukrainian\n# … with 5,988 more rows\n\n\nUnfortunately, if you explore this dataset a little further, the language fields are don’t conform well with each other and a lot more work with ifelse will be needed before you could put together any full analysis around students who speak different langages at home and at school.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIt’s possible to nest our ifelse statements, by writing another ifelse where you would have the <value_if_false>, for example we might want to give describe the type of school in England:\n\nplot_data <- schools %>% \n  mutate(sch_type = \n           ifelse(EstablishmentGroup == \"Special schools\", \"Special\",\n                  ifelse(EstablishmentGroup == \"Independent schools\", \"Independent\",\n                         ifelse(AdmissionsPolicy==\"Selective\", \n                                \"Grammar\", \"Comprehensive\"))))\n\n\n\n\n2.11.2 Factors and statistical data types\nThe types of variable will heavily influence what statistical analysis you can perform. R is there to help by assigning datatypes to each field. We have different sorts of data that can be stored:\n\n\n\nCategorical - data that can be divided into groups or categories\n\n\nNominal - categorical data where the order isn’t important, e.g. gender, or colours\n\nOrdinal - categorical data that may have order or ranking, e.g. exam grades (A, B, C, D) or lickert scales (strongly agree, agree, disgaree, strongly disagree)\n\n\n\nNumeric - data that consists of numbers\n\n\nContinuous - numeric data that can take any value within a given range, e.g. height (178cm, 134.54cm)\n\nDiscrete - numeric data that can take only certain values within a range, e.g. number of children in a family (0,1,2,3,4,5)\n\n\n\nBut here we are going to look at how R handles factors. Factors have two parts, levels and codes. levels are what you see when you view a table column, codes are an underlying order to the data. Factors allow you to store data that has a known set of values taht you might want to display in an order other than alphabetical. For example, if we look at the month field ST003D02T using the levels(<field>) command:\n\nlevels(PISA_2018$ST003D02T)\n\n [1] \"January\"        \"February\"       \"March\"          \"April\"         \n [5] \"May\"            \"June\"           \"July\"           \"August\"        \n [9] \"September\"      \"October\"        \"November\"       \"December\"      \n[13] \"Valid Skip\"     \"Not Applicable\" \"Invalid\"        \"No Response\"   \n\n\nWe can see that the months of the year are there along with other possible levels. With this particular dataset, we have set all other levels as NA.\nCodes are the underlying numbers/order for each level, in this case 1 = January, 2 = February, etc.\n\nas.numeric(PISA_2018$ST003D02T)\n\n [1]  2  7  4  4  3  2  7  8  3  7 12  1 12  6  3 12  3  6  8 12  7  8  8  9 10\n[26] 11  6  4  9  4  1  2  9  5 12  5  1  2 10  9\n [ reached getOption(\"max.print\") -- omitted 611964 entries ]\n\n\nHow can this be useful? A good example is how plots are made, they will use the codes to give an order to the display of columns, in the plot below, February (2) comes before March (3), even though there were more students born in March:\n\ngrph_data <- PISA_2018 %>% \n         group_by(ST003D02T) %>% \n         summarise(n=n())\n\nggplot(data=grph_data, aes(x=ST003D02T, y=n)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nTo re-order the columns to match the number of students, we can either try to do this manually, which is rather cumbersome:\n\nmy_levels <- c(\"July\", \"September\", \"January\", \"March\", \"February\",\"April\", \"May\", \"June\", \"August\", \"October\", \"November\", \"December\", \"Valid Skip\", \"Not Applicable\", \"Invalid\", \"No Response\")\n\ngrph_data$ST003D02T <- factor(grph_data$ST003D02T, levels=my_levels)\n\nggplot(data=grph_data, aes(x=ST003D02T, y=n)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nOr get R to do this for us:\n\n# get the levels in order and pull/create a vector of them\nmy_levels <- grph_data %>% arrange(desc(n)) %>% pull(ST003D02T)\n\n# reassign the re-ordered levels to the dataframe column\ngrph_data$ST003D02T <- factor(grph_data$ST003D02T, levels=my_levels)\n\nggplot(data=grph_data, aes(x=ST003D02T, y=n)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nTo learn a lot more about factors, see Hadley’s chapter"
  },
  {
    "objectID": "index.html#seminar-tasks-1",
    "href": "index.html#seminar-tasks-1",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n2.12 Seminar tasks",
    "text": "2.12 Seminar tasks\n\n2.12.1 Student dataset\n\n\nHow many unique values are there in the OCOD3 field for student intended future occupation? How does the most desired career vary by gender?\n\n\nanswerPISA_2018$OCOD3 %>% unique() %>% length()\n\nPISA_2018 %>% \n  group_by(ST004D01T, OCOD3) %>%\n  summarise(n =n()) %>%\n  arrange(desc(n))\n\n\n\nwrite code to work out the mean and median number of hours of learning Maths MMINS for each country CNT.\n\n\nanswerPISA_2018 %>% \n  group_by(CNT) %>%\n  summarise(mean_MMINS = mean(MMINS, na.rm=TRUE),\n            median_MMINS = median(MMINS, na.rm=TRUE)) %>%\n  arrange(desc(median_MMINS))\n\n\n\nwhat is the fourth most popular language at home LANGN spoken by students in schools in the United Kingdom, how does this compare to France?\n\n\nanswerPISA_2018 %>% \n  filter(CNT %in% c(\"France\", \"United Kingdom\")) %>%\n  group_by(CNT, LANGN) %>%\n  summarise(n = n()) %>%\n  arrange(desc(n))\n\n# a bit of a rubbish answer really, as France only codes this at French or varieties of Other\n\n\n\nSpot the five errors with the following code. Can you make it work? What does it do?\n\n\n# Work out when more time spent in language lessons than maths lessons\nPISA_2018_lang < PISA_2018 %>%\n  rename(gender = ST004D01T) %>%\n  mutate(language importance = LMINS - MMINS) %>%\n  filter(is.na(language_importance)) %>%\n  group_by(CNT gender) %>%\n  summarise(students = n,\n            lang_win = sum(language_importance >= 0),\n            per_lang_win = 100*(lang_win/students))\n\n\nanswer# Work out when more time spent in language lessons than maths lessons\nPISA_2018_lang <- PISA_2018 %>%  #1 make sure you have the assignment arrow <-\n  rename(gender = ST004D01T) %>%\n  mutate(language_importance = LMINS - MMINS) %>% #2 _ not space in name of field\n  filter(!is.na(language_importance)) %>%  #3 this needs to be !is.na, otherwise it'll return nothing\n  group_by(CNT, gender) %>% #4 missing comma\n  summarise(students = n(),   #5 missing brackets on the n() command\n            lang_win = sum(language_importance >= 0),\n            per_lang_win = 100*(lang_win/students))\n\n\n\nBy gender work out the average attitudes to learning activities ATTLNACT\n\n\n\n\n2.12.2 Teacher dataset\n\n\n\nTo further check your understanding of this section you will be attempting to analyse the 2018 teacher dataset. This dataset includes records for 107367 teachers from 19 countries, including 351 columns, covering attitudinal, demographic and workplace data. You can find the dataset here in the .parquet format.\n\n\n\n\n\nWork out how many teachers are in the dataset for the United Kingdom\n\n\n\nanswerPISA_2018_teacher %>% \n  group_by(CNT) %>%\n  summarise(n=n()) %>%\n  filter(CNT == \"United Kingdom\")\n\n\n\nFor each country CNT by gender TC001Q01NA, what is the mean time that a teacher has been in the teaching profession TC007Q02NA? Include the number of teachers in each group. Order this to show the country with the longest serving workforce:\n\n\nanswerPISA_2018_teacher %>%\n  group_by(CNT, TC001Q01NA) %>%\n  summarise(avg_years = mean(TC007Q02NA, na.rm=TRUE),\n            n = n()) %>%\n  arrange(desc(avg_years))\n\n\n\nFor each country CNT find out which teachers provide the most opportunities for students to improve their critical thinking skills TC207Q06HA:\n\n\nanswerPISA_2018_teacher %>% \n  rename(crit_think = TC207Q06HA) %>%\n  group_by(CNT) %>%\n  mutate(teachers=n()) %>%\n  group_by(CNT, crit_think) %>%\n  summarise(n = n(),\n            per = n()/unique(teachers)) %>%\n  arrange(desc(per))\n\n\n\nExplore the data on use of technology in the classroom TC169____\n\n\n\nanswerPISA_2018_teacher %>% select(CNT, TC001Q01NA, starts_with(\"TC169\"))\n\n\n\nSave the results of one of the above questions using write_csv().\n[EXTENSION] explore the dataset and find out some more interesting facts to share with your group"
  },
  {
    "objectID": "index.html#sec-graphing",
    "href": "index.html#sec-graphing",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n3.1 Introduction to graphing in R",
    "text": "3.1 Introduction to graphing in R\nThe tidyverse includes the incredibly powerful ggplot2 package. This package is pretty much the industry standard for making graphs for publication. ggplot2 is built on the grammar of graphics where you build graphs by specifying underlying attributes and layering geometric objects on top of each other. In the diagram below you can see how a graph is built from geometric objects (the things that are plotted such as points and bars) a scale, and plot annotations (e.g. a key, title etc). You can then apply faceting to the graph to automatically split one graph into multiple plots, allowing you to easily compare different groupings. Publications, such as the Financial Times, make daily use of ggplot2.\n\n\nAdapted from A Layered Grammar of Graphics, Wickham, 2010\n\n\nThe basic structure of ggplot code is to combine different graphing elements through the use of the + operator. To demonstrate this, let’s look at the relationship between a poverty indicator ESCS and the performance in Maths PV1MATH, by gender ST004D01T and country CNT:\n\nlibrary(tidyverse)\n# wrangle our data\ngraph_data <- PISA_2018 %>% \n  filter(CNT %in% c(\"France\", \"United Kingdom\"))\n\n# display a graph of the results\nggplot(data = graph_data, \n       aes(x = ESCS, y = PV1MATH, colour = ST004D01T)) +\n  geom_point() +\n  geom_smooth(method = 'lm') +\n  facet_wrap(. ~ CNT) +\n  ggtitle(\"Comparison of poverty indicator and Maths result, by gender and country\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\nHopefully you can work out what lines 1-3 do from the previous chapter, let’s focus on the ggplot commands:\n\n6-7 these lines set up the ggplot giving it the table object graph_data as its data input and setting up the aesthetics for the rest of the graph elements using columns from graph_data. The aes(<attribute>, <attribute>, ...) command allows us to specify aesthetic elements of the graph that will change dependent on the dataset we use. In the PISA_2018 data set, the variable ESCS refers to an index of economic status, and PV1Math, is the plausible value of the mathematics score. We set the x and y variables x=ESCS and y=PV1MATH , defining aes() inside ggplot() means we will pass down these values to subsequent geometric objects so we don’t have to define these x and y axis items again and again.\n8 using the data and aes values defined on lines 6-7, geom_point uses the x and y values defined on line 19 to draw a point for each school in our dataset. There are lots of different parameters we could give geom_point e.g. specifying size and shape, but here we are content with using the defaults.\n9 we add another geometric object on top of the points, this time we add a line of best fit geom_smooth, again this geometric object uses the values specified on lines 6-7, and we define the method as lm, to calculate a linear model line of best fit.\n10 next we use facet_wrap(. ~ CNT) to create a graph for each group of CNT in the dataset, i.e. a graph for each country defined on line 3.\n11 finally we customise the title of the graph, ggtitle, ready for display.\n\n\n\n\n\n\n\nImportant\n\n\n\nSwitching between the pipes and ggplot can get rather confusing. A very common mistake in using ggplot is to try and link together the geom_ elements with a pipe command %>% rather than the +."
  },
  {
    "objectID": "index.html#geoms",
    "href": "index.html#geoms",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n3.2 Geoms",
    "text": "3.2 Geoms\nThere are about 40 different geometric objects in ggplot, allowing you to create almost any sort of graph. We will be exploring a few of them in detail, but if you want to explore others, please follow some of the links below:\n\n\ngeom_bar for creating bar charts and histograms\n\ngeom_point for plotting single points\n\ngeom_line for connecting points together and showing trends\n\ngeom_text for adding text labels to data points\n\ngeom_boxplot for representing the range of data\n\ngeom_hex for creating heat maps\n\ngeom_map for adding geographic maps\n\ngeom_smooth for adding lines of best fit\n\ngeom_hline for adding static horizontal lines to a graph\n\ngeom_vline for adding static vertical lines to a graph\n\n\n3.2.1 geom_point\nRather unsurprisingly, geom_point allows us to plot a layer of points using x and y coordinates. The below example shows how we can specify within the ggplot function data=school_plot_data. We then define the aesthetic attributes of the graph, passing the x x=NumberOfBoys and y y=NumberOfGirls values. Once these have been declared in the ggplot(...) function, their values are passed down to any subsequent geom_, in this case geom_point will use the data and x and y values that have been specified in ggplot(...)\n\n# create a new dataframe of maths and reading scores by country and OECD status\ncountry_plot_data <- PISA_2018 %>% \n  group_by(OECD, CNT) %>%\n  summarise(mean_maths = mean(PV1MATH),\n            mean_read = mean(PV1READ),\n            sz = n())\n\n# using this new dataframe, show the relationship between maths and reading score\n# using geom_points\nggplot(data=country_plot_data, \n       aes(x=mean_maths, y=mean_read)) +\n  geom_point(aes(size=sz, colour=OECD), alpha = 0.6)\n\n\n\n\n\nIn line 2 above we pipe the large data.frame PISA_2018 to apply a number of functions.\nLine 3 groups by OECD (a Yes or No indicating membership) and CNT (the name of the country).\nLines 4-5 calculate the mean mathematics and reading score, and create new variables (mean_maths, and mean_read) for their values.\nIn addition, in line 6, the variables sz is created which counts the number of responses per country through the n() command.\nThis whole pipe is then saved to the country_plot_data object, using the <- on line 2\n\nThis new dataframe is then passed to ggplot.\n\nIn line 10, we specify the data that should be plotted - the new dataframe country_plot_data we have created.\nLine 11, then we pass the x and y variables, mean_maths, and mean_read, inside the aesthetic function. These values will be passed to any subsequent geom_\n\nIn line 12, we make a number of tweaks to the points: first setting the aesthetics - the size of the points is linked to the sz variable we created, the number of responses per country, and the colour is linked to OECD membership. Finally (and note this is outside the aes brackets, we set an alpha value which makes the point slightly transparent, which is more visually appealing where points overlap.\n\n\n\n\n\n\n\nImportant\n\n\n\nDefining things inside aes mean that they will change with the dataset you use, if you define them outside aes then they will be constant values. For example\n\n# plotting number of boys as x, number of girls as y and % disadvantged as size,\n# all inside aes, so each point is a table row\nggplot(data=PISA_2018_school) +\n  geom_point(aes(x = SC002Q01TA,\n                 y = SC002Q02TA,\n                 size=SC048Q03NA))\n\n\n\n\n\n# there is an error if we put size outside the aes, and set it a value from the \n# dataset, it can't find value!\nggplot(data=PISA_2018_school) +\n  geom_point(aes(x = SC002Q01TA,\n                 y = SC002Q02TA),\n             size=SC048Q03NA)\n\nError in list2(na.rm = na.rm, ...): object 'SC048Q03NA' not found\n\n\n\n# but if we set the size explicitly, outside the aes, then all points will be that size\nggplot(data=PISA_2018_school) +\n  geom_point(aes(x = SC002Q01TA,\n                 y = SC002Q02TA),\n             size=3)\n\n\n\n\n\n\n\n3.2.2 Questions\n\n\nSpot the three errors in this graph code\n\n\nggplot(adta=diamonds, x=depth, y=price) +\n  geom_point() %>% \n  ggtitle(\"diamond graph\")\n\n\nanswer#1 data not adta; #2 x and y need to be inside aes\nggplot(data=diamonds, aes(x=depth, y=price)) +\n  geom_point() + #3 %>% instead of +\n  ggtitle(\"diamond graph\")\n\n\n\nUsing the PISA_2018 dataset, plot a graph for students from Norway to look at the relationship between wealth WEALTH and reading grade PV1READ. Colour each point with the gender ST004D01T of the student. Give the graph sensible x and y labels (e.g. xlab(\"label\")).\n\n\nanswer dataframegraph_data <- PISA_2018 %>% filter(CNT == \"Norway\")\n\n\n\nanswer graphggplot(graph_data,\n       aes(x=WEALTH,\n           y=PV1READ)) +\n  geom_point(aes(colour=ST004D01T)) +\n  xlab(\"Wealth\") +\n  ylab(\"Reading grade\")\n\n\n\nUsing the PISA_2018 dataset for each country CNT, create a graph to explore how the median of the sense of school belonging BELONG relates to the median of the disciplinary climate in the school DISCLIMA, adjust the colour of each point to reflect the mean wealth of students in each country ESCS.\n\nHINT: You’ll need create a new dataframe with summarised variables for median_belong, median_discipline and mean_wealth.\n\nanswer dataframegraph_data <- PISA_2018 %>%\n  group_by(OECD, CNT) %>%\n  summarise(median_belong = median(BELONG, na.rm=TRUE),\n            median_discipline = median(DISCLIMA, na.rm=TRUE),\n            mean_wealth = mean(ESCS, na.rm=TRUE))\n\n\nHINT: To make your colours stand out more, add + scale_color_gradientn(colours = rainbow(3)) to the end of your plot.\n\nanswer graph# display a graph of the results\nggplot(data = graph_data, \n       aes(x = median_belong, \n           y = median_discipline)) +\n  geom_point(aes(colour = mean_wealth)) + \n  scale_color_gradientn(colours = rainbow(3))\n\n\n\n\n3.2.3 geom_bar\nThe geom_bar function is versatile, allowing the creation of bar, multiple bar, stacked bar charts and histograms. This first example shows how we can use bar charts to represent the number of cars in a household ST012Q02TA:\n\nplot_cars <- PISA_2018 %>% filter(!is.na(ST012Q02TA))\n\nggplot(data = plot_cars, \n       aes(x=ST012Q02TA)) + \n  geom_bar()\n\n\n\n\n\n2 gets the PISA_2018 dataset and removes all rows where ST012Q02TA is NA, storing this new dataset as plot_cars\n\n4 passes the plot_cars to ggplot, as the dataset we are going to plot\n5 specifies the x values to be the values stored in ST012Q02TA, i.e. we will have a bar for each response given in ST012Q02TA: None, One, Two, Three or more.\n6 geom_bar tell ggplot to make bars, it uses the aesthetic from line 5, to plot the x axis, note we haven’t given it a y value, this is auto-calculated from the number of students in each x group.\n\nWe can choose to let ggplot split the results into different groups for us by setting a fill option, in this case on the OECD status of the country, i.e. do students in OECD countries have more cars than those not in OECD countries, to do this, we add fill=OECD to the aes on line 2 below:\n\nggplot(data = plot_cars, \n       aes(x=ST012Q02TA, fill=OECD)) + \n  geom_bar()\n\n\n\n\n\nThe bars are now coloured with a key, but, annoyingly, the bars are on top of each other not easily allowing us to make direct comparisons. To compare different groups we need the bars to not be stacked, we want them next to each other, or in ggplot language, we want the bars to dodge each other, to do this we add the position=position_dodge() command to line 3 below:\n\nggplot(data = plot_cars, \n       aes(x=ST012Q02TA, fill=OECD)) + \n  geom_bar(position=position_dodge())\n\n\n\n\n\n3.2.3.1 Raising the bars yourself\nggplot can do a lot of the hard work when putting together bar charts, e.g. counting the number of students in each group, but there might also be times when you want to use pipes to calculate summary values that you then want plot. That is, you want to specify the heights of the bars yourself. To do this we will specify the y axis in the aes and use stat=\"indentity\" to tell ggplot that’s what we’re doing. Take the example where you want to find the overall percentage of students for a range of countries getting over 500 in PV1SCIE:\n\nplot_data <- PISA_2018 %>%\n  group_by(OECD, CNT) %>%\n  summarise(all_students = n(),\n            upper_sci_per = sum(PV1SCIE > 500) / n())\n\nggplot(data=plot_data, \n       aes(x=CNT, y=upper_sci_per)) +\n  geom_bar(aes(fill=OECD), \n           position=position_dodge(),\n           stat=\"identity\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n1 to 4 creates a dataframe plot_data that calculates the percentage of students in each country CNT, that have a science grade PV1SCIE over 500\n\n7 as we are setting the heights of the bars ourselves, we need to give the ggplot aes command a y value, in this case y=upper_sci_per\n\n8 the geom_bar is given a fill value of OECD, this will allow us to see how countries in and out of the OECD compare\n9 we use position=position_dodge() as we want the percentage grades of each country to be next to each other so we can look for differences in heights\n10 stat=\"identity\" tells geom_bar that you have defined your own bar heights in the y attribute and not to count the number of rows.\n11 this theme command helps rotate the x-axis labels 90 degrees, so they don’t overlap.\n\nAlternatively, you can use the geom_col() function that can handle you setting the y values and not specifying stat=\"identity\"\n\nggplot(data=plot_data, \n       aes(x=CNT, y=upper_sci_per)) +\n  geom_col(aes(fill=OECD), \n           position=position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n3.2.4 Questions\n\n\nCan you spot the 4 errors in this code.\n\n\nggplot(data=schools %>% filter(Phase == \"Secondary\"), \n       x=Region +\n  geom_bar(aes(fill=Gender) position=\"full\") \n\n\nanswerggplot(data=schools %>% filter(Phase == \"Secondary\"), \n       aes(x=Region)) + # 1 no aes() around the x value # 2 missing close brackets\n  geom_bar(aes(fill=Gender), position=\"fill\") # 3 missing comma # 4 position=\"full\" rather than fill \n\n\n\nCreate a bar chart showing the total number of students for each grouping of “Think about your school, how true: Students seem to value competition” ST205Q01HA. Adjust this graph to see if there is a difference for this amongst females and males ST004D01T:\n\n\nanswerggplot(data=PISA_2018,\n       aes(x=ST205Q01HA)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\nanswer with gender addedggplot(data=PISA_2018 %>% filter(!is.na(ST205Q01HA)),\n       aes(x=ST205Q01HA, fill=ST004D01T)) +\n  geom_bar(position=position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\nPlot bars for the number of Females and Males ST004D01T who answer each grouping for: “Use digital devices outside of school: Browsing the Internet for fun (such as watching videos, e.g. )” IC008Q08TA. Make sure that the bars position_dodge() each other so we can compare the heights.\n\n\n\nanswergraph_data <- PISA_2018 %>% filter(!is.na(IC008Q08TA))\n\nggplot(data=graph_data,\n       aes(x=IC008Q08TA, fill=ST004D01T)) +\n  geom_bar(position=position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\nFor France and the United Kingdom, plot the total number of students who gave each answer for IC010Q09NA “Use digital devices outside of school: Doing homework on a computer”. Filter out all the NA values first !is.na(...)\n\n\n\nanswer dataframeplot_data <- PISA_2018 %>% \n  filter(CNT %in% c(\"France\", \"United Kingdom\"),\n         !is.na(IC010Q09NA))\n\n\n\nanswerggplot(plot_data,\n       aes(x=IC010Q09NA, fill=CNT)) +\n  geom_bar(position=position_dodge()) +\n  theme(legend.position = \"bottom\")\n\n\n\nUsing the PISA_2018_school dataset (available here] create a table that stores for each country CNT\n\n\n\nthe total number of schools,\nthe total number of teachers working full-time SC018Q01TA01,\nthe total number of teachers working part-time SC018Q01TA02,\nand the overall total number of teachers\n\nAdd an additional column working out the % of teachers working part-time in each country, call this per_part\n\ncreating the dataframeplot_workforce <- PISA_2018_school %>% \n  group_by(CNT) %>% \n  summarise(schools = n(),\n            fulltime = SC018Q01TA01 %>% sum(na.rm=TRUE),\n            parttime = SC018Q01TA02 %>% sum(na.rm=TRUE),\n            teachers = fulltime + parttime,\n            per_part = parttime / teachers)\n\n\nUsing this dataframe plot a bar graph for each country of the per_part, use the number of schools as a fill:\n\ncreating the dataframeggplot(data=plot_workforce,\n       aes(x=CNT, y=per_part, fill=schools)) +\n  geom_bar(stat=\"identity\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  theme(legend.position=\"top\")\n\n\n\n[Extension] Explore other patterns in the school and student pisa datasets.\n\n\n\n3.2.5 geom_text\nOur bar charts look great, but finding the actual value of each bar can be a little clumsly if we have to get a ruler out and read off the y-axis. Better would be for us to have numbers listed at the top of each bar by adding a geom_text element:\n\nplot_cars <- PISA_2018 %>% filter(!is.na(ST012Q02TA))\n\nggplot(data = plot_cars, \n       aes(x=ST012Q02TA, fill=OECD)) + \n  geom_bar(position=position_dodge()) +\n  geom_text(stat='count', \n            aes(label=..count..), \n            position = position_dodge(width=0.9),\n            vjust=-0.5)\n\n\n\n\n\nline 6 starts the geom_text command, telling the geom to use the count statistic from ggplot, this means it will be able to fetch the number of rows in each grouping.\nline 7 as we want the label to change for each bar element, we put label=..count.. inside aes. The x location of the labels is inherited from line 4 and the y location will be calculated from the height of each bar\nline 8 we want the labels to align to the bars, so we tell the geom_text to also position_dodge, passing a width=0.9 to the dodge function, so the labels line up above the columns,\nfinally, on line 9, we vertically adjust the labels vjust, so they sit on top of the columns.\n\nRather than adding the count, you might want to add the percentage that each bar represents, we can do this by changing the value given to label on line 5, below:\n\nggplot(data = plot_cars, \n       aes(x=ST012Q02TA, fill=OECD)) + \n  geom_bar(position=position_dodge()) +\n  geom_text(stat='count', \n            aes(label=100*(..count../sum(..count..)) %>% round(3), \n            group = OECD), \n            position = position_dodge(width=0.9),\n            vjust=-0.5)\n\n\n\n\nAdditionally, when we make graphs we often want to label the dataset, for example if we were to plot all the countries and their PV1MATH and PV1READ scores, we would get:\n\nplot_data <- PISA_2018 %>%\n  group_by(OECD, CNT) %>%\n  summarise(m_read  = mean(PV1READ, na.rm=\"TRUE\"),\n            m_maths = mean(PV1MATH, na.rm=\"TRUE\"))\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() \n\n\n\n\nThis looks great, but we don’t actually know which countries are which. To get this data we need to add text to the graph, using geom_text.\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() +\n  geom_text(aes(label=CNT), \n            colour=\"black\", \n            check_overlap = TRUE)\n\n\n\n\nHere we have used colour=\"black\" outside the aes to define the colour for all the labels, and check_overlap = TRUE which removes any labels that are on top of each other. It’s still a little bit hard to understand, and maybe we want to focus on just a few of the labels for countries we are interested in. For example\n\n# make a vector of countries you want to have labels for\nfocus_cnt <- c(\"United Kingdom\", \"France\", \"Argentina\")\n\n# add a new column to the plot_data where these countries are\nplot_data <- plot_data %>% mutate(focus = CNT %in% focus_cnt)\n\nplot_data\n\n# A tibble: 80 × 5\n# Groups:   OECD [2]\n   OECD  CNT                    m_read m_maths focus\n   <fct> <fct>                   <dbl>   <dbl> <lgl>\n 1 No    Albania                  407.    438. FALSE\n 2 No    United Arab Emirates     421.    430. FALSE\n 3 No    Argentina                415.    392. TRUE \n 4 No    Bulgaria                 423.    440. FALSE\n 5 No    Bosnia and Herzegovina   403.    407. FALSE\n 6 No    Belarus                  476.    473. FALSE\n 7 No    Brazil                   416.    384. FALSE\n 8 No    Brunei Darussalam        409.    429. FALSE\n 9 No    Costa Rica               426.    403. FALSE\n10 No    Dominican Republic       344.    327. FALSE\n# … with 70 more rows\n\n\nNow we can adjust out geom_text to only show those countries that we want to focus on:\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() +\n  geom_text(data=plot_data %>% filter(focus == TRUE),\n            aes(label=CNT), \n            colour=\"black\", \n            check_overlap = TRUE)\n\n\n\n\n\nline 5 changes the data that is being passed to the geom_text, it no longer uses the data defined in line 2, but has a new dataset, that is filtered on focus == TRUE, i.e. only containing the countries that we want.\nNote that the x and y mappings from line 3 are inherited by line 6, it’s only the data that we have redefined\n\n\n\n\n\n\n\nTip\n\n\n\ngeom_text is great, but you might find that ggrepel package useful as it’ll add lines connecting the text the data points. Using the plot_data from above:\n\nlibrary(ggrepel)\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() +\n  geom_text_repel(data=plot_data %>% filter(focus == TRUE),\n            aes(label=CNT),\n            box.padding = 0.5,\n            max.overlaps = Inf,\n            colour=\"black\")\n\nWarning: Removed 1 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "index.html#faceting",
    "href": "index.html#faceting",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n3.3 Faceting",
    "text": "3.3 Faceting\nFaceting allows you to easily create multiple graphs from one dataset and one ggplot definition by splitting the data on different factors, by defining:\nfacet_grid(<column_to_split> ~ .)\nor\nfacet_grid(. ~ <column_to_split>)\nLooking at the PISA_2018 dataset, we can plot the WEALTH and reading test outcome PV1READ variables against each other:\n\n# create a subset of the data for plotting\nplot_data <- PISA_2018 %>% \n  select(OECD, CNT, WEALTH, PV1READ) %>%\n  filter(CNT %in% c(\"Germany\", \"Russian Federation\", \n                    \"United Kingdom\"))\n\nggplot(data=plot_data, aes(x=WEALTH, y=PV1READ)) + \n  geom_point() + \n  geom_smooth() +\n  theme(legend.position = \"bottom\")\n\n\n\n\nBut it isn’t clear how this graph varies between countries. We could try plotting separate graphs for each country, but there is a faster way. Using:\n+ facet_grid(CNT ~ .)\nggplot will automatically create graphs for subsets of plot_data, split on each different country in CNT\n\nggplot(data=plot_data, aes(x=WEALTH, y=PV1READ)) + \n  geom_point() + \n  geom_smooth() +\n  theme(legend.position = \"bottom\") +\n  facet_grid(CNT ~ .)\n\n\n\n\nIf the column you want to split on it on the left hand side of facet_grid(CNT ~ .), then the graphs will be piled on top of each other, if it’s on the right hand side facet_grid(. ~ CNT), then they’ll be side by side.\n\nTake a subset of the overall dataset, by filtering on a few countries, take another one of your plots and use facet_grid(CNT ~ .) to explore the graphs for different countries."
  },
  {
    "objectID": "index.html#exporting-plots",
    "href": "index.html#exporting-plots",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n3.4 Exporting plots",
    "text": "3.4 Exporting plots\nggplot can export data in a variety of formats suitable for printing, publication and the web. Once you have created a graph and stored it in an object my_graph <- ggplot(..., the command to save the graph to your hard drive is:\nggsave(<file_location_name_and_extension>, <object_name>, width = 5, height = 4, device=<file_ext>)\n\nggsave(\"my_graph.pdf\", my_graph, width = 5, height = 4, device=\"pdf\")\n\nIf you want to change the output format, just change the extension of the file you are saving:\n\n“poverty_size.pdf” perfect for publication and printing, large size\n“poverty_size.svg” the same as pdf, also suitable for putting on webpages\n“poverty_size.png” smaller file size, suitable for websites and presentations\n“poverty_size.jpg” same as the png"
  },
  {
    "objectID": "index.html#additional-support-on-graphing",
    "href": "index.html#additional-support-on-graphing",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n3.5 Additional support on graphing",
    "text": "3.5 Additional support on graphing"
  },
  {
    "objectID": "index.html#using-r-to-do-descriptive-statistics-and-plot-graphs",
    "href": "index.html#using-r-to-do-descriptive-statistics-and-plot-graphs",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n3.6 Using R to do descriptive statistics and plot graphs",
    "text": "3.6 Using R to do descriptive statistics and plot graphs\n\n\nYou can find the code used in the video below:\n\nShow the code# Introduction to plotting graphs\n#\n# Download data from /Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\n# You want the file: Students_2018_RBDP_none_levels.rds\n# and place in your own file system\n# change loc to load the data directly. Loading into R might take a few minutes\nlibrary(tidyverse)\nloc <- \"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\"\nPISA_2018 <- read_rds(loc)\n\n# Calculating means of groups\n# The PISA_2018 dataframe is piped to a new dataframe MeanPISA\n# The data are grouped by the country variable (CNT)\n# The countries of interest are chosen (UK, France, Germany and the US)\n# The summarise function is used to output the mean and standard deviation score for each country\n# on the Science Plausible Value (PV1SCIE) and NAs are ignored na.rm=TRUE\n\nMeanPISA <- PISA_2018 %>%\n  group_by(CNT)  %>%\n  filter(CNT==\"United Kingdom\" | CNT== \"France\" | CNT== \"Germany\" | CNT==\"United States\")  %>%\n  summarise(mean_sci = mean(PV1SCIE, na.rm=TRUE), sd_sci= sd(PV1SCIE, na.rm=TRUE)) \nprint(MeanPISA)\n\n\n# To plot data we can use the ggplot function. \n# We will start by plotting a column graph use geom_col\n# We specify the data set for ggplot to use (MeanPisa) and then \n# define the x and y variables:\n# ggplot(MeanPISA,\n#       aes(x=CNT, y=mean_sci))\n# geom_col() (Note the plus is on the line before) plots the graph and the fill colour is set to red\n# The next three lines set the formatting of the axis text and add x and y axis labels\n\nggplot(MeanPISA,\n       aes(x=CNT, y=mean_sci))+\ngeom_col(fill=\"red\") +\n  theme(axis.text.x = element_text(angle = 90, hjust=0.95, vjust=0.2, size=10)) +\n  xlab(\"Country\") +\n  ylab(\"Science Score\")\n\n# For plotting a scatter plot or PISA reading scores against science scores\n#, first we make a managable data set\n# I will filter the data set to include only the UK data\n# and remove any NAs\n\nUKData <- PISA_2018 %>%\n  filter(CNT==\"United Kingdom\") %>%\n  drop_na(PV1SCIE)\n\n# This time I will use ggplot to plot a scatter graph\n# I feed UKDATA to ggplot, specify the x (PISA Reading score)\n# And y (PISA science score). This time, I have linked the colour\n# to a variable (ST004D01T) which is the gender value, giving\n# plot points of different colours for boys and girls\n# To produce a scatter plot, I use geom_point to plot points,\n# Giving the size of point and the transparency (alpha=0.5) -\n# some transparency of points is helpful when plots become dense\n# The x and y lables are added\n# Finally, a line is plotted - geom_smooth(method='lm')\n# sets the line to a linear ('lm') line\n\n  ggplot(UKData,\n       aes(x=PV1READ, y=PV1SCIE, colour=ST004D01T)) +\n  geom_point(size=0.1, alpha=0.5) +\n  ylab(\"Science Score\") +\n  xlab(\"Reading Score\") +\n  geom_smooth(method='lm')\n  \n# Where R becomes very powerful is being able to produce multiple charts rapidly\n# In the code below, I plot reading against science scores as above, but this time\n# Use the entire data set - for the whole world!\n# All the steps are the same, except, I use the facet_wrap, a way to create multiple\n# graph panels - the instruction creates a set of graphs for each country  \n  \n  WorldData <- PISA_2018 %>%\n    drop_na(PV1SCIE)\n  \n  ggplot(WorldData,\n         aes(x=PV1READ, y=PV1SCIE, colour=ST004D01T)) +\n    geom_point(size=0.1, alpha=0.5) +\n    ylab(\"Science Score\") +\n    xlab(\"Reading Score\") +\n    geom_smooth(method='lm') +\n    facet_wrap(CNT~.)"
  },
  {
    "objectID": "index.html#seminar-activities",
    "href": "index.html#seminar-activities",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n4.1 Seminar activities",
    "text": "4.1 Seminar activities\n\n4.1.1 Discussion activity\nBased on Davis (2013) Link to chapter\n\nConsider how and why we think of things as being ‘normal’ (or not). Some suggested questions are:\n\nWhat were your immediate thoughts on reading this paper?\nIn what ways have you yourself been aware of being compared to norms or ideals?\nHow do you feel about that? As an education professional, have you made comparisons between individual students and expected norms or averages? Between groups of students?\nWhen and how was this useful?\nWhen and how was this problematic?\n\n4.1.2 Tasks\nGetting set up\nUsing the following .csv data set and the read.csv command: DfE_SEN_School_Level to load data on Special Educational Needs (SEN) students in UK schools.\n\n# Descriptive Statistics using the DfE SEN School Level Data\n\nlibrary(\"tidyverse\")\nloc <- \"<your drive>/sen_school_level_underlying_data.csv\"\nDfE_SEN_data <- read.csv(loc)\n\n\n\n\n\n\n\nTip\n\n\n\nYou may find these explanation of acronyms used in the spreadsheet useful:\n\nLA stands for local authority and is an administrative region, for example, Camden and Greenwich.\nFSM refers to students who receive free school meals - this funding is available for students whose parents or carers receive certain government benefits, typically due to relatively low income. It is taken, by some policy makers and researchers, as a marker of socioeconomic disadvantage\nSEN support indicates a school has made a judgement that a student needs further support in school because of special educational needs or disabilities, for example dyslexia or speech and communication needs. If students need a higher level of support, they can be assessed by a specialist and are then placed on an education, health and care (EHC) plan. Students on EHC plans receive a higher level of support than those on SEN support.\nA Pupil Referral Unit (PRU) is a type of school for children who are not able to attend a mainstream school due to illness or behavioural issues that have led to being excluded.\nA special school is a school that provides support for students with special educational needs, for example, autism or physical disabilities, like deafness.\nEHC_primary_need_spld = specific learning difficulties, for example, dyslexia and dyspraxia\nEHC_primary_need_mld = moderate learning difficulties, indicating a delay in development\nEHC_primary_need_sld = severe learning difficulties, indicating significant learning needs\nEHC_primary_need_pmld = profound and multiple learning difficulties - students with multiple and complex needs\n\n\n\n\n4.1.2.1 Descriptive statistics\nWe will now learn how to calculate means of subgroups of schools using the filter and summarise functions. We can use filter to focus on only a subset of our data.frame. For example, below, we choose to focus on schools in Camden.\nIn line 3 below, we focus on schools in Camden. Note that, in filter we use ==. Then we use summarise to calculate the totals of the variables we are interested in, students getting SEN support (SEN.support), students on an EHC plan (EHC.plan) and the total (Total.Pupils).\n\n# Selecting only schools in one LA and finding the mean of various variables\n\nDfE_SEN_data %>% \n  filter(la_name == \"Camden\") %>% # Filter to only include schools in Camden (note the ==)\n  summarise(SEN_total=sum(SEN.support), \n            EHCplan=sum(EHC.plan), \n            Total=sum(Total.pupils))\n\n  SEN_total EHCplan Total\n1      4389    1107 31622\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to filter by a different vector (that is, a different column in the table), don’t forget to change the name of the vector in the filter command, for example, to filter by the gender of pupils at the school. Don’t forget to use the %>% and the == in filter!\n\nDfE_SEN_data %>% \n filter(sex_of_school_description==\"Boys\")%>%\n  summarise(SEN_total=sum(SEN.support), \n            EHCplan=sum(EHC.plan), \n            Total=sum(Total.pupils))\n\n  SEN_total EHCplan  Total\n1     22028    7451 217220\n\n\n\n\n\n4.1.2.2 Task 1\n\n\nFind the total number of students with SEN support, on EHC plans, and the total number of students (using Total.pupils) in Greenwich\n\n\nAnswer# Selecting only schools in one LA and finding the mean of various variables\n\nDfE_SEN_data %>% \n  filter(la_name==\"Greenwich\") %>% \n  summarise(SEN_total=sum(SEN.support), \n            EHCplan=sum(EHC.plan), \n            Total=sum(Total.pupils))\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nMake sure you have spelled the name of the variables SEN.support, etc. correctly. They are case sensitive. You can use the function colnames(DfE_SEN_data) to get a list of names and copy and paste them\n\n\n\n4.1.2.3 Task 2\n\n\nSelect a single local authority (LA) or region.\nCalculate the total number of pupils in the LA, the total number listed as receiving SEN support, and the total number with an EHC plan.\n\n\nAnswer# Selecting only schools in Hackney and finding the total pupils on SEN support and EHC plans\n\nDfE_SEN_data %>% \n  filter(la_name==\"Hackney\") %>% \n  summarise(SEN_total=sum(SEN.support), \n            EHCplan=sum(EHC.plan))\n\n\n\nCalculate the totals for all of London (note, you will need to change the name of the column you are filtering by).\n\n\nAnswer# Filter for London  schools and finding the total pupils on SEN support and EHC plans\n\nDfE_SEN_data %>% \n  filter(region_name==\"London\") %>% \n  summarise(SEN_total=sum(SEN.support), \n            EHCplan=sum(EHC.plan))\n\n\n\nAn extension task - use the functions mean() to calculate mean values, and sd() to calculate standard deviation in the summarise functions above, in Camden schools.\n\n\nAnswer# Filter for London schools and finding the mean and standard deviation of pupils on SEN support and EHC plans\n\nDfE_SEN_data %>% \n  filter(region_name==\"London\") %>% \n  summarise(SENmean=mean(SEN.support), \n            EHCmean=mean(EHC.plan),\n            SENsd=sd(SEN.support),\n            EHCsd=sd(EHC.plan))\n\n\n\n\n4.1.2.4 Calculating Percentages\nNext, we will use the totals of SEN supported and EHC plan students to calculate percentages. We simply do an additional summarise with the equation to find the percentage of EHCplan students =(EHCplan/Total)*100.\n\n\n\n\n\n\nTip\n\n\n\nWhen using summarise, be careful to add a comma after each function, and check you have closed as many brackets as you open!\n\n\n\n# Descriptive Statistics using the DfE SEN School Level Data\n\n# Calculating Percentages of students on EHC plans\nPercenttable <- DfE_SEN_data  %>% \n  group_by(district_administrative_name) %>%\n  summarise(SEN_support = sum(SEN.support), \n            EHCplan     = sum(EHC.plan), \n            Total       = sum(Total.pupils),\n            percentageEHCplan = (EHCplan/Total)*100) \n\nprint(Percenttable)\n\n# A tibble: 310 × 5\n   district_administrative_name SEN_support EHCplan Total percentageEHCplan\n   <chr>                              <int>   <int> <int>             <dbl>\n 1 Adur                                1427     350  9315              3.76\n 2 Allerdale                           1701     523 14994              3.49\n 3 Amber Valley                        2409     823 18819              4.37\n 4 Arun                                2621     556 18742              2.97\n 5 Ashfield                            2485     420 20140              2.09\n 6 Ashford                             2357    1280 22832              5.61\n 7 Babergh                             1910     675 15097              4.47\n 8 Barking and Dagenham                5286    1570 45153              3.48\n 9 Barnet                              7269    2505 68481              3.66\n10 Barnsley                            3849    1579 35271              4.48\n# … with 300 more rows\n\n\nThis gives a table as an output, with the percentage of students on an EHC plan in each local authority.\n\n\n\n\n\n\nTip\n\n\n\nYou can use the signif function to display a given number of decimal places. Here, I have used signif( ,2) to limit the percentage calculation to two significant figures\n\n# Calculating Percentages of students on EHC plans\nPercenttable <- DfE_SEN_data  %>% \n  group_by(district_administrative_name) %>%\n  summarise(SEN_support = sum(SEN.support), \n            EHCplan     = sum(EHC.plan), \n            Total       = sum(Total.pupils),\n            percentageEHCplan = signif((EHCplan/Total)*100,2))\n\n\nprint(Percenttable)\n\n# A tibble: 310 × 5\n   district_administrative_name SEN_support EHCplan Total percentageEHCplan\n   <chr>                              <int>   <int> <int>             <dbl>\n 1 Adur                                1427     350  9315               3.8\n 2 Allerdale                           1701     523 14994               3.5\n 3 Amber Valley                        2409     823 18819               4.4\n 4 Arun                                2621     556 18742               3  \n 5 Ashfield                            2485     420 20140               2.1\n 6 Ashford                             2357    1280 22832               5.6\n 7 Babergh                             1910     675 15097               4.5\n 8 Barking and Dagenham                5286    1570 45153               3.5\n 9 Barnet                              7269    2505 68481               3.7\n10 Barnsley                            3849    1579 35271               4.5\n# … with 300 more rows\n\n\n\n\n\n4.1.2.5 Task 3\n\n\n\n\n\n\nTip\n\n\n\nDon’t forget to use the pipe operator %>% between each function\n\n\n\nFor each administrative district (local authority), calculate the percentages of pupils with SEN support.\n\nAnswer# Descriptive Statistics using the DfE SEN School Level Data\n\n\n# Calculating Percentages of students with SEN support in each administrative district (local authority)\nPercenttable <- DfE_SEN_data  %>% \n  group_by(district_administrative_name) %>%\n  summarise(SEN_support = sum(SEN.support), \n            EHCplan     = sum(EHC.plan), \n            Total       = sum(Total.pupils),\n            percentagesupport = (SEN_support/Total)*100)\n\n\n print(Percenttable)\n\n\n\n\n4.1.2.6 Finding the mean, median, maximum, and minimum\n\nExample, Find the mean, median, maximum and minimum percentages of students with SEN support in each administrative district.\n\nTo find the mean, we can use summarise to find the mean (summarise(Mean_support=mean(SEN.support))). Similarly, we can use the max, min and median function to find the respective values (modes are little more complicated).\n\nlibrary(tidyverse)\n\n# We do the steps above to create our percentage table for SEN support\nDescrip <- DfE_SEN_data  %>% \n  group_by(district_administrative_name)  %>%  \n  summarise(SEN_support = sum(SEN.support), \n            Total       = sum(Total.pupils),\n            percentagesupport = (SEN_support/Total)*100,\n            Max_support = max(SEN.support),\n            Mean_support = mean(SEN.support),\n            Min_support=min(SEN.support),\n            Median_support=median(SEN.support))\n  \n\n# describe is a function from the psych package (remember to load tidyverse after it) which gives summary data for max, min, mean etc for the whole country.\nprint(Descrip)  \n\n# A tibble: 310 × 8\n   district_administrati…¹ SEN_s…² Total perce…³ Max_s…⁴ Mean_…⁵ Min_s…⁶ Media…⁷\n   <chr>                     <int> <int>   <dbl>   <int>   <dbl>   <int>   <dbl>\n 1 Adur                       1427  9315    15.3     251    71.4       0    54.5\n 2 Allerdale                  1701 14994    11.3     157    24.3       0    13  \n 3 Amber Valley               2409 18819    12.8     182    33         0    23  \n 4 Arun                       2621 18742    14.0     213    57.0       0    32  \n 5 Ashfield                   2485 20140    12.3     309    50.7       0    35  \n 6 Ashford                    2357 22832    10.3     266    39.3       0    26  \n 7 Babergh                    1910 15097    12.7     333    34.1       0    14  \n 8 Barking and Dagenham       5286 45153    11.7     288    81.3       0    68  \n 9 Barnet                     7269 68481    10.6     472    43.5       0    30  \n10 Barnsley                   3849 35271    10.9     247    41.4       0    30  \n# … with 300 more rows, and abbreviated variable names\n#   ¹​district_administrative_name, ²​SEN_support, ³​percentagesupport,\n#   ⁴​Max_support, ⁵​Mean_support, ⁶​Min_support, ⁷​Median_support\n\n# An alternative way to do this is to turn the table into the longer format\n# This converts each entry in the table into an individual row in a list\n# which can then be used to calculate descriptive statistics\n#\n# new_table <- DfE_SEN_data %>%\n#  group_by(district_administrative_name) %>%\n#  summarise(SEN_support = sum(SEN.support), \n#            EHCplan     = sum(EHC.plan), \n#            Total       = sum(Total.pupils))\n#\n# new_table %>%\n#  pivot_longer(!district_administrative_name,\n#               names_to = \"variable\",\n#               values_to = \"value\") %>%\n#  group_by(variable) %>%\n#  summarise(mean_value = mean(value),\n#            max_value = max(value),\n#            median_value = median(value))\n\n\n\n\n\n\n\nTip\n\n\n\nSurprisingly, there is no function to calculate the mode in tidyverse. However, you can get one by loading the modeest package and using the most frequent value (nfv) function.\n\n# Install the modeest package to calculate a mode\n\nlibrary(modeest)\nlibrary(tidyverse)\n# The mode can be found with the most frequent value (mfv) function\n\nPISAUKMath<-PISA_2018%>%\n  select(CNT, PV1MATH)\n\nmfv(PISA_2018$PV1MATH, na_rm= TRUE)\n\n[1] 455.767\n\n\n\n\n\n4.1.2.7 Task 4\n\n\nFind the mean, median, maximum and minimum percentages of students with EHC plans in each local authority for the whole country.\n\n\nAnswerlibrary(tidyverse)\n\n# We do the steps above to create our percentage table for EHC plans\n# after grouping by districts (LAs)\nEHCDescrip <- DfE_SEN_data  %>% \n  group_by(district_administrative_name) %>%\n  summarise(EHC_support = sum(EHC.plan), \n            Total       = sum(Total.pupils),\n            percentagesupport = (EHC_support/Total)*100,\n            Max_support = max(EHC.plan),\n            Mean_support = mean(EHC.plan),\n            Min_support=min(EHC.plan),\n            Median_support=median(EHC.plan))\n\nprint(EHCDescrip)\n\n\n\nFind the mean, median, maximum and minimum percentages of students with EHC plans in the UK as a whole, and for London. What differences can you see?\n\n\nAnswer# To get the descriptive statistics for EHC plans in all of the UK:\n\nEHCDescripTotal <- DfE_SEN_data  %>% \n  summarise(EHC_support = sum(EHC.plan), \n            Total       = sum(Total.pupils),\n            percentageEHC = (EHC_support/Total)*100,\n            Max_EHC = max(EHC.plan),\n            Mean_EHC = mean(EHC.plan),\n            Min_EHC=min(EHC.plan),\n            Median_EHC=median(EHC.plan))\n\nprint(EHCDescripTotal)\n\n# To get the descriptive statistics for EHC plans in London, we add a filter first\nEHCDescripLon <- DfE_SEN_data  %>% \n  filter(region_name==\"London\")  %>%\n  summarise(EHC_support = sum(EHC.plan), \n            Total       = sum(Total.pupils),\n            percentageEHC = (EHC_support/Total)*100,\n            Max_EHC = max(EHC.plan),\n            Mean_EHC = mean(EHC.plan),\n            Min_EHC=min(EHC.plan),\n            Median_EHC=median(EHC.plan))\n\nprint(EHCDescripLon)\n\n\n\n\n4.1.3 Graphing\nUsing the same data set ( DfE_SEN_School_Level) we are going to now plot some graphs\nFor more details on graphing with the PISA_2018 dataset, see Section 3.1\n\n4.1.4 Column graphs\nImagine we want to plot a graph of the the percentage of students on EHC plans by gender of school\nWhen plotting graphs, it makes things easier to have a data.frame of the data you will pass to ggplot - a bit like the final table of data you will actually plot when drawing a graph in real life.\nTo complete our take we are going to create a new data.frame we will use in the plot. I have called that data.frame genderplot (the data about percentage of students on EHC plans by gender, that I will plot). Then, I take the main data.frame and group_by sex_of_school_description, to get the schools grouped by whether they are single of mixed sex. Next I use the mutate function to create percentage columns, as we did before.\nThe new element here is using ggplot, R’s graphing function (more details on how to use geom_bar are in the section above: Geom_bar).\nTo plot a graph, you call ggplot and specify the data you want to use for the graph (in our case, the new data.frame we have created, genderplot).\nThe next layer of ggplot is the aesthetics (aes), i.e., what our graph will look like. First, we tell ggplot what we want our x (sex_of_school_description) and y (percentageEHCplan) variables to be. Finally, we use geom_col() to plot a column graph.\n\n# Presenting % on EHC by gender of school\ngenderplot <- DfE_SEN_data %>%\n  group_by(sex_of_school_description) %>%\n  summarise(SEN_support=sum(SEN.support), \n            EHCplan=sum(EHC.plan), \n            Total=sum(Total.pupils),\n            percentageEHCplan = (EHCplan/Total)*100, \n            percentagesupport = (SEN_support/Total)*100)\n\n\n# using the genderplot data create a graph\nggplot(data=genderplot,\n       aes(x=sex_of_school_description,\n           y=percentageEHCplan)) +\n  geom_col()\n\n\n\n\n\n4.1.4.1 Task 5\n\nPlot a column graph of the % of students of EHC.plans by the type of school (the type_of_establishment variable)\n\nAnswer# Calculate percentage on plan and support by type of school\n\nestabdata <- DfE_SEN_data %>%\n  group_by(type_of_establishment) %>%\n  summarise(EHCplan=sum(EHC.plan), \n            Total=sum(Total.pupils),\n            percentageEHCplan = (EHCplan/Total)*100)\n\n# Plot the type of school data\nggplot(data=estabdata,\n       aes(x=type_of_establishment,\n           y=percentageEHCplan)) +\n  geom_col(fill=\"red\")+ # I have filled the columns in red here\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) \n  # The final line rotates the text and spaces it nicely\n\n\n\n\n4.1.5 Scatter Graphs\nTo plot a scatter graph we use the geom_point (see also: Geom_Point section), which works in a similar way to geom_col.\nExample\nImagine I want to plot a graph of total number of students (on the x-axis) against those with EHC plans (y-axis) for all schools in London.\nA above, I first want to create a data.frame to plot - in this case I have called it plotdata. I filter to select only London schools from the DfE dataset.\nThen I pass ggplot plotdata. As with geom_col, I use ggplot and first specify the data I want to plot (ggplot(data=plotdata,). Next, I set the aesthetic variables, to keep things simple,only the x and y variables. Then I call geom_point to plot the points as a scatter graph.\n\n# Filter to create a dataframe of only London schools\nplotdata<-DfE_SEN_data %>%\n  filter(region_name==\"London\")\n# Plot the type of school data\nggplot(data=plotdata,\n       aes(x=Total.pupils,y=EHC.plan)) +\n  geom_point()\n\n\n\n\nWe can make things more pleasing by adding more features to the aesthetic variable. For example, I can add colour (geom_point(colour=\"blue\")) and rename the axes labs(x=\"Total number of pupils\", y=\"Number of pupils on EHC plans\"). Note when adding to ggplot, the + should come at the end of the line before the new addition to avoid an error.\n\n#  Filter to create a dataframe of only London schools\nplotdata<-DfE_SEN_data %>%\n  filter(region_name==\"London\")\n# Plot the type of school data\nggplot(data=plotdata,\n       aes(x=Total.pupils,y=EHC.plan)) +\n  geom_point(colour=\"blue\")+\n  labs(x=\"Total number of pupils\", y=\"Number of pupils on EHC plans\")\n\n\n\n\nI can also add a line using (geom_smooth(method='lm')) - here ‘lm’ specifies a linear plot (i.e. a straight line).\n\n# Filtter to create a dataframe of only London schools\nplotdata<-DfE_SEN_data %>%\n  filter(region_name==\"London\")\n# Plot the type of school data\nggplot(data=plotdata,\n       aes(x=Total.pupils,y=EHC.plan)) +\n  geom_point(colour=\"blue\")+\n  labs(x=\"Total number of pupils\", y=\"Number of pupils on EHC plans\")+\n  (geom_smooth(method='lm'))\n\n\n\n\nI can also change the colour of the points by a variable in the dataframe - for example by the type of school (aes(colour=type_of_establishment)). I can vary the size of points and make them slightly transparent (their alpha level): geom_point(alpha=0.4, size=0.6), and I can move the legend to the bottom\n\n# Filter to create a dataframe of only London schools\nplotdata<-DfE_SEN_data %>%\n  filter(region_name==\"London\")\n# Plot the type of school data\nggplot(data=plotdata,\n       aes(x=Total.pupils,y=EHC.plan, colour=sex_of_school_description)) +\n  geom_point(alpha=0.4, size=0.6)+\n  labs(x=\"Total number of pupils\", y=\"Number of puupils on EHC plans\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor a summary of all the elements of a graph you can change in ggplot - see this help sheet\n\n\n\n4.1.5.1 Task 6\n\nFor schools in London, plot the number of students receiving SEN support (SEN.Support) against those on an EHC plan (EHC.plan). The try varying the colour of points by type of school, adding a line and changing the size of plot point by size of school\n\nAnswer# Filter to create a dataframe of only London schools\nplotdata<-DfE_SEN_data %>%\n  filter(region_name==\"London\")\n# Plot the type of school data\nggplot(data=plotdata,\n       aes(x=SEN.support,y=EHC.plan, colour=\"red\", size=Total.pupils)) +\n  geom_point(alpha=0.4)+\n  labs(x=\"Total number of pupils\", y=\"Number of puupils on EHC plans\")\n\n\n\n\n4.1.5.2 Extension task - Binning data\nIf we want to plot a frequency plot, the kind of chart that often gives a normal distribution, we need to divide data into counts of ranges of data.\nFor example, if we wanted to plot a frequency chart of heights, we might divide the counts into those between 1.5m-1.6m, 1.6m-1.7m etc. To do this we can use the cut(<field>,<breaks>) function within the mutate command on a ‘data.frame’.\nIn the example below, I will use the data on Total.pupils. I use cut(Total.pupils, breaks=seq(0,1500, 25)) to create a new vector (column in the table) with the total number of pupils divided up into bins. The specification breaks=seq(0,1500, 25)) sets how the data are broken up - into bins (i.e. groups of schools) of pupil numbers starting at 0 and rising to 1500 in steps of 25.\n\n# Creates distribution of schools by size\nbinnedsize <- DfE_SEN_data %>% # Creates a new data frame with binned data\n  mutate(Total.pupils = cut(Total.pupils, breaks=seq(0,1500, 25)))%>%\n  na.omit()\nggplot(binnedsize,\n       aes(x=Total.pupils)) +\n  geom_bar(fill=\"dark green\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  labs(y=\"Number of schools\", x=\"Pupil range\")\n\n\n\n\n\nCreate a graph of the binned counts of number of students on SEN support in schools in the UK\n\n\n\n\n\n\nTip\n\n\n\nTo find out a range of a vector, you can use the range function in the console - for example, to get a sense of the range of numbers of students on SEN support. I can type: range(DfE_SEN_data$SEN.support)\n\n\n\nAnswer# Creates distribution of those on SEN support\nbinnedSEN <- DfE_SEN_data %>% # Creates a new data frame with bins\n  mutate(SENbins = cut(SEN.support, breaks=seq(0,100, 2)))%>%\n  na.omit()\nggplot(binnedSEN,\n       aes(x=SENbins)) +\n  geom_bar(fill=\"dark green\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  labs(y=\"Number of schools\", x=\"Number on SEN support\")"
  },
  {
    "objectID": "index.html#statistical-analysis",
    "href": "index.html#statistical-analysis",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n6.1 Statistical analysis",
    "text": "6.1 Statistical analysis\nThere are probably statistical libraries in R to do every sort of test you will ever need, from the typical ANOVA to cutting edge machine learning. The full list of R packages sits on the cran server and you can load packages as and when you need them at no cost. R comes pre-packaged with some common statistical tools, for example, the t.test() and linear model regression lm(). For other stats tools you’ll need to install the package and load it (see Section 2.6.1) before you can use the functions."
  },
  {
    "objectID": "index.html#t-tests",
    "href": "index.html#t-tests",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n6.2 T-tests",
    "text": "6.2 T-tests\nT-tests are statistical tests that determine if there are statistically significant differences between the means of two groups. Consider the data giving the results of girls and boys on a test:\nBoys’ scores\n\n\nBoy\nScore (/10)\n\n\n\nA\n7\n\n\nB\n8\n\n\nC\n6\n\n\nD\n5\n\n\nE\n8\n\n\nMean\n6.8\n\n\n\nGirls’ scores\n\n\nGirls\nScore (/10)\n\n\n\nA\n9\n\n\nB\n4\n\n\nC\n7\n\n\nD\n8\n\n\nE\n8\n\n\nMean\n7.2\n\n\n\nThe means of the two groups are different (6.8 for boys and 7.2 for girls) but the difference may simply be due to random variation. A t-test can report the probability that a difference is means is due to chance.\n\nlibrary(tidyverse)\nBoys<-data.frame(Score=c(7,8,6,5,8))\nGirls<-data.frame(Score=c(9,4,7,8,8))\nprint(mean(Boys$Score))\n\n[1] 6.8\n\nprint(mean(Girls$Score))\n\n[1] 7.2\n\nt.test(Boys$Score, Girls$Score)\n\n\n    Welch Two Sample t-test\n\ndata:  Boys$Score and Girls$Score\nt = -0.3849, df = 7.035, p-value = 0.7117\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.854915  2.054915\nsample estimates:\nmean of x mean of y \n      6.8       7.2 \n\n\nThe t.test function returns a p-value greater than 0.05 so the mean test-results can be assumed to the result of chance, and we conclude there are no detectable differences by gender for this data set.\n\n6.2.1 Task 1\nConsider the following scenarios. Which (if any) of the t-tests would be most of appropriate, including whether it would be a one or two tailed test.\n\n\n\n\n\n\nNote\n\n\n\nOne and two-tailed tests\nRemember that a one-tailed test only looks for differences in one direction from the mean (for example, that one sample has a higher mean than the other). A two-tailed tests tests for the possibility of the means of the two groups being higher or lower than each other.\n\n\n\n\nAn educational researcher wants to test a teaching approach with a group of 12 students to see if an intervention increases performance in their year 6 SATs results. Pupils are given a SATS paper before the intervention and again after. The results of these are normalised and then compared.\nA teacher wants to see if their pupils’ GCSE computer science test scores are in line with the national average or not. The tests are out of 180 marks.\nThe DfE want to compare uptake of STEM subjects pre and post pandemic to see if there has been any change in the percentage of students studying at least one STEM subject for A level.\nA school wants to compare salaries of staff between this academic year and last academic year to see whether there has been a significant increase.\nThe same school as in d) wants to compare salaries of support staff and teaching staff to see if there is a significant difference.\nA researcher wants to find out how much time pupils spend looking at screens during lesson time, to see if there is a difference between year 7 and year 10 students. 10 pupils in year 7 and 10 pupils in year 10 are randomly selected across a school and observed throughout a school day in November. The times are recorded to the nearest minute.\nA business manager wants to check if the financial expenditure on STEM teachers per year is similar to the national average (based on average numbers of pupils on role)\n\n\n\n6.2.2 Task 2\nProgress 8 is a ‘value-added’ measure (DfE 2023). It indicates how much a secondary school has helped pupils progress academically over a five year period, from the end of primary school (age 11) to the end of the end year 11 (age 16).\nThe score is calculated across 8 subjects (hence Progress 8): English; mathematics; three other English Baccalaureate (EBacc) subjects (sciences, computer science, geography, history and languages); and three further subjects\n\nA progress 8 score of zero means a pupil did as well as other pupils in England who got similar results\nPositive and negative scores indicate a pupil did better or less well than similar pupils\n\nThe Department for Education dataset that we will use can be downloaded here: DfE_Data_2019\nYou can then load the data into R using the read_excel function from the readxl package. This function will need two “strings”, one giving the location of the including the file name and file extension, and the second giving the name of the sheet within the excel file that you are trying to open\nread_excel(\"<file_location>\", \"<sheet_name>\")\nMy example of using this code is here:\n\n# Don't forget to change the pathname to where you have downloaded on your \n# device. Do check back to section 2.8.3 Loading data for how to find\n# the path of the file on your device.\nlibrary(readxl)\nDfE_2019 <- read_excel(\"data/Amy/DfE Data 2019 for Seminar.xlsx\", \"Filtered\")\n\n\n\n# A tibble: 4 × 15\n  LA_nu…¹ Local…² DfE_n…³ Uniqu…⁴ Schoo…⁵ NFTYPE Insti…⁶ Admis…⁷ Gende…⁸ Gende…⁹\n    <dbl> <chr>     <dbl>   <dbl> <chr>   <chr>  <chr>   <chr>   <chr>   <chr>  \n1     302 Barnet  3025950  144784 Oak Hi… ACCS   Specia… 999 ot… Mixed   Mixed  \n2     211 Tower … 2117171  143630 Ian Mi… ACCS   Specia… 999 ot… Boys    Boys   \n3     872 Woking… 8727000  143862 Northe… ACS    Academ… 999 ot… Mixed   Mixed  \n4     354 Rochda… 3547006  105861 Brownh… CYS    Commun… 999 ot… Mixed   Mixed  \n# … with 5 more variables: `New_academy?` <chr>, Pupils_at_end_KS4 <dbl>,\n#   P8SCORE <dbl>, BASICS94 <dbl>, BASICS95 <dbl>, and abbreviated variable\n#   names ¹​LA_number, ²​Local_Authority_name, ³​`DfE_number_(LAESTAB)`,\n#   ⁴​`Unique_Reference_Number_(URN)`, ⁵​School_or_college_name,\n#   ⁶​Institution_type, ⁷​Admissions_policy, ⁸​Gender_of_Entry,\n#   ⁹​Gender_of_Sixth_Form_Entry\n\n\nUse the dataset to complete the following tasks:\n\n\n\n\n\nReplicate the t-test used in example 2 in the lecture with boys’ schools and girls’ schools in Birmingham local authority. Check for normality of the data and whether variances are equal also.\n\n\n\n\n\n\n\nNote\n\n\n\nNormality checking\nTo check for normality we can use a number of different tests and approaches, some of which will be covered in the seminar. For data sets that are below 5000 observations then Sharpiro-Wilk is a good test to use. For data sets above 5000 (as with the PISA data) then the D’Agostino-Pearson test is a good approach. Histograms and qqplots can also be used to help visualise the data and compare with the normal distribution.\n\n\n\n\n\n\n\n\nNote\n\n\n\nChecking for Equal Variances\nTo check for equal variances, we can divide the variance of one sample by the other sample. If the ratio of the variances is greater than 2 or less than 0.5 then we conclude that they are unequal. R will check this for you, and if they are unequal, will use the test for unequal variances (Welch’s test).\n\n\n\nAnswerBirminghamboys <- DfE_2019 %>%\n  select(Local_Authority_name, Gender_of_Entry, P8SCORE)%>%\n  filter(Local_Authority_name == \"Birmingham\" & \n         Gender_of_Entry==\"Boys\")\n\nBirminghamgirls<-DfE_2019 %>%\n  select(Local_Authority_name, Gender_of_Entry, P8SCORE)%>%\n  filter(Local_Authority_name ==\"Birmingham\" &\n         Gender_of_Entry==\"Girls\")\n\nshapiro.test(Birminghamboys$P8SCORE)\n#Shapiro-Wilk normality test\n#data:  Birminghamboys$P8SCORE\n#W = 0.85654, p-value = 0.05193\n\nshapiro.test(Birminghamgirls$P8SCORE)\n#Shapiro-Wilk normality test\n#data:  Birminghamgirls$P8SCORE\n#W = 0.97786, p-value = 0.9675\n\nvarboys <- var(Birminghamboys$P8SCORE)\n\nvargirls <- var(Birminghamgirls$P8SCORE)\n\nvarboys/vargirls\n#12.43959\n\nt.test(Birminghamboys$P8SCORE, Birminghamgirls$P8SCORE, var.equal=FALSE, alternative = 'two.sided')\n#Welch Two Sample t-test\n#data:  Birminghamboys$P8SCORE and Birminghamgirls$P8SCORE\n#t = -1.3796, df = 11.363, p-value = 0.1943\n#alternative hypothesis: true difference in means is not equal to 0\n#95 percent confidence interval:\n# -1.1825235  0.2690969\n#sample estimates:\n#mean of x mean of y \n#0.1263636 0.5830769 \n\n\n\nNow, filter out any outliers in the data for part a) i) and repeat the t-test.\n\n\n\n\n\n\n\nNote\n\n\n\nChecking and Filtering for Outliers\nOften, we need to check and filter for outliers in the data. There are many ways to do this, depending on the distribution of the data and how extreme the outliers are that we want to remove. A good rule of thumb is the median +/- 1.5 times the interquartile range (IQR), where the IQR is the upper quartile - lower quartile. If the data is normally distributed, then the mean +/- 1.5 time the standard deviation (sd) can be used. If we only want to remove more extreme outliers, then 2 or even 3 times the IQR (or sd) from the median (or mean) can be used instead.\nOnce we have determined the upper and lower bound of our outliers, we can remove any data points that lie outside of this and then perform our statistical test on the data.\n\n\n\nAnsweroutl_h_b <- mean(Birminghamboys$P8SCORE) + 1.5 * sd(Birminghamboys$P8SCORE)\n\noutl_l_b <- mean(Birminghamboys$P8SCORE) - 1.5 * sd(Birminghamboys$P8SCORE)\n\n\n\noutl_h_g <- mean(Birminghamgirls$P8SCORE) + 1.5 * sd(Birminghamgirls$P8SCORE)\n\noutl_l_g <- mean(Birminghamgirls$P8SCORE) - 1.5 * sd(Birminghamgirls$P8SCORE)\n\n\n\nBirminghamboys <- Birminghamboys %>%\n  select(Local_Authority_name, Gender_of_Entry, P8SCORE)%>%\n  filter(P8SCORE > outl_l_b &\n           P8SCORE < outl_h_b)\n\nshapiro.test(Birminghamboys$P8SCORE)\n\n#Shapiro-Wilk normality test\n\n#data:  Birminghamboys$P8SCORE\n#W = 0.94364, p-value = 0.5942\n\nshapiro.test(Birminghamgirls$P8SCORE)\n#Shapiro-Wilk normality test\n\n#data:  Birminghamgirls$P8SCORE\n#W = 0.97786, p-value = 0.9675\n\n\nvarboys <- var(Birminghamboys$P8SCORE)\n\nvargirls <- var(Birminghamgirls$P8SCORE)\n\nvarboys/vargirls\n#4.101412\n\n\nt.test(Birminghamboys$P8SCORE, Birminghamgirls$P8SCORE, \n       var.equal=FALSE, \n       alternative = 'two.sided')\n\n#Welch Two Sample t-test\n\n#data:  Birminghamboys$P8SCORE and Birminghamgirls$P8SCORE\n#t = -0.89463, df = 12.366, p-value = 0.3881\n#alternative hypothesis: true difference in means is not equal to 0\n#95 percent confidence interval:\n# -0.6446256  0.2684718\n#sample estimates:\n#mean of x mean of y \n#0.3950000 0.5830769 \n\n\n\n\n\n\nReplicate the t-test used in Example 3 of the lecture when comparing 2018 and 2019 data in Birmingham. Again, check for normality and equal variances.\n\nThe data for 2018 and 2019 can be found in the Filtered 3 sheet, so make sure you load this data, as follows:\n\n# Don't forget to change the pathname to where you have downloaded on your # device. Do check back to section 2.8.3 Loading data for how to find\n# the path of the file on your device.\nlibrary(readxl)\nDfEdata20182019 <- read_excel(\"data/Amy/DfE Data 2019 for Seminar.xlsx\", \"Filtered 3\")\n\n\n\n# A tibble: 4 × 18\n  LA_nu…¹ Local…² DfE_n…³ Uniqu…⁴ Schoo…⁵ NFTYPE Insti…⁶ Admis…⁷ Gende…⁸ Gende…⁹\n    <dbl> <chr>     <dbl>   <dbl> <chr>   <chr>  <chr>   <chr>   <chr>   <chr>  \n1     302 Barnet  3025950  144784 Oak Hi… ACCS   Specia… 999 ot… Mixed   Mixed  \n2     872 Woking… 8727000  143862 Northe… ACS    Academ… 999 ot… Mixed   Mixed  \n3     354 Rochda… 3547006  105861 Brownh… CYS    Commun… 999 ot… Mixed   Mixed  \n4     390 Gatesh… 3907006  108426 Furrow… CYS    Commun… 999 ot… Mixed   Mixed  \n# … with 8 more variables: `New_academy?` <chr>, Pupils_at_end_KS4 <dbl>,\n#   P8SCORE2019 <dbl>, BASICS942019 <dbl>, BASICS952019 <dbl>,\n#   P8SCORE2018 <dbl>, BASICS942018 <dbl>, BASICS952018 <dbl>, and abbreviated\n#   variable names ¹​LA_number, ²​Local_Authority_name, ³​`DfE_number_(LAESTAB)`,\n#   ⁴​`Unique_Reference_Number_(URN)`, ⁵​School_or_college_name,\n#   ⁶​Institution_type, ⁷​Admissions_policy, ⁸​Gender_of_Entry,\n#   ⁹​Gender_of_Sixth_Form_Entry\n\n\n\nAnswerBirminghamall <- DfEdata20182019 %>%\n  select(Local_Authority_name, Institution_type, Gender_of_Entry, P8SCORE2018, P8SCORE2019)%>%\n  filter(Local_Authority_name == \"Birmingham\")\n\nshapiro.test(Birminghamall$P8SCORE2018)\n#p-value is 4.76e-05 – not normally distributed\n\nshapiro.test(Birminghamall$P8SCORE2019)\n#p-value is is 7.78e-– not normally distributed\n\nt.test(Birminghamall$P8SCORE2018, Birminghamall$P8SCORE2019,\n       var.equal=TRUE, alternative = 'greater', paired = TRUE)\n\n#Paired t-test\n\n#data:  Birminghamall$P8SCORE2018 and Birminghamall$P8SCORE2019\n#t = -3.3994, df = 87, p-value = 0.9995\n#alternative hypothesis: true mean difference is greater than 0\n#95 percent confidence interval:\n# -0.1516149        Inf\n#sample estimates:\n#mean difference \n#     -0.1018182 \n\n\n\nUsing the data in Example 3, filter out any schools designated as Special Academy, Foundation Special School or Community Special School as their Institution_type from the data set, then repeat the t-test.\n\n\nAnswerBirmNOTspecial <- Birminghamall %>% \n  filter(Institution_type != \"Special Academy\" &\n         Institution_type != \"Community Special School\" &\n         Institution_type != \"Foundation Special School\")\n\n# The following filter() commands would achieve the same outcome:\n# filter(!grepl(\"Special|special\", Institution_type))\n# filter(!Institution_type %in% \n#  c(\"Special Academy\", \"Community Special School\", \"Foundation Special School\")) \n\nshapiro.test(BirmNOTspecial$P8SCORE2018) \n#p-value 0.5729 - normally distributed\n\nshapiro.test(BirmNOTspecial$P8SCORE2019)\n#p-value 0.8679 - normally distributed\n\nt.test(BirmNOTspecial$P8SCORE2019, BirmNOTspecial$P8SCORE2018, var.equal=TRUE, alternative = 'greater', paired = TRUE)  \n\n#Paired t-test\n\n#data:  BirmNOTspecial$P8SCORE2019 and BirmNOTspecial$P8SCORE2018\n#t = 3.6533, df = 77, p-value = 0.0002352\n#alternative hypothesis: true mean difference is greater than 0\n#95 percent confidence interval:\n# 0.06196414        Inf\n#sample estimates:\n#mean difference \n#      0.1138462 \n\n\n\nChoose different data sets from either the 2018 or 2019 (or both) data to compare. Set out your null and alternative hypothesis, your significance level, the type of t-test and number of tails, and then calculate the p-value. State the outcome of the test.\n\n\n\n6.2.3 Task 3\nLook at the PISA_2018 dataset. You can load the PISA_2018 data set using these steps. Click here to download the parquet file: PISA_2018.parquet\nTo load the data, use the code below:\n\ninstall.packages(\"arrow\") # if you haven't already\nlibrary(arrow)\nlibrary(tidyverse)\nPISA_2018 <- read_parquet(\"<location of the downloaded PISA_2018.parquet file>\")\n\n\n\n\n\n\n\nNote\n\n\n\nTesting for normality\nOne way to test whether a sample is normal (a condition of a t-test), is to plot a quantile-quantile plot ggqqplot.If the data are normal, the dots should form a straight line.\n\n# The ggpubr package includes the function to test normality (a ggqqplot)\n\nlibrary(ggpubr)\n\n# Plot a qq plot for all the UK science scores in the PISA sample\nUKsci<-PISA_2018%>% \n  filter(CNT==\"United Kingdom\")\n\nggqqplot(UKsci$PV1SCIE)\n\n\n\n\n\n\n\n\nReplicate the test Richard performs in the video, comparing performance in males and females ST004D01T in the UK in mathematics PV1MATH using a t.test.\n\n\nAnswer# Are there differences between the mean scores of UK boys and girls in PISA mathematics?\n#\n\nlibrary(tidyverse)\n\n# Select the gender (ST004D01T) and math score columns (PV1MATH)\n# Filter the data to select UK responses\n\nMaleUK <- PISA_2018 %>%\n  select(CNT, ST004D01T, PV1MATH) %>%\n  filter(CNT=='United Kingdom',\n         ST004D01T=='Male')\n\nFemaleUK <- PISA_2018 %>%\n  select(CNT, ST004D01T, PV1MATH) %>%\n  filter(CNT=='United Kingdom',\n         ST004D01T=='Female')\n\n# The conditions to do a t-test include that the data are normally distributed\n# and there is homogeneity (similarity) of the variances (the squared standard deviations)\n# Let us check the conditions are met by calculating first if the data sets are normally\n# distributed using the qq plot in the ggpubr package\n\nggqqplot(MaleUK$PV1MATH)\nggqqplot(FemaleUK$PV1MATH)\n\n# The plots produces relatively straight lines so the distributions can be assumed to be normal\n#\n# We will then check the variances of the two data sets\n\nVarM <- var(MaleUK$PV1MATH)\nVarF <- var(FemaleUK$PV1MATH)\nVarM / VarF\n\n# The variance ratio is close to 1 (1.1)\n# So our two conditions are met and can we can perform the t-test\n\nt.test(MaleUK$PV1MATH, FemaleUK$PV1MATH)\n\n# The p-value is <0.05 (4.061e-08) suggesting there are statistically\n# differences between boys and girls\n\n\n\nChoose a different country of interest to compare performance in males and females in that country\n\n\nAnswer# Are there differences between the mean scores of boys and girls in China PISA mathematics?\n#\n# Select the gender (ST004D01T) and math score columns (PV1MATH)\n# Filter the data to select UK responses\n\nMaleChina <- PISA_2018 %>%\n  select(CNT,ST004D01T, PV1MATH) %>%\n  filter(CNT=='B-S-J-Z (China)', ST004D01T=='Male')\n\nFemaleChina<-PISA_2018 %>%\n  select(CNT,ST004D01T, PV1MATH) %>%\n  filter(CNT=='B-S-J-Z (China)', ST004D01T=='Female')\n\n# The conditions to do a t-test include that the data are normally distributed\nggqqplot(MaleChina$PV1MATH)\nggqqplot(FemaleChina$PV1MATH)\n\n# The plots produces relatively straight lines so the distributions can be # assumed to be normal\n#\n# We will then check the variances of the two data sets\n\nVarM<-var(MaleChina$PV1MATH)\nVarF<-var(FemaleChina$PV1MATH)\nVarM/VarF\n\n# The variance ratio is close to 1 (1.17)\n# So our two conditions are met and can we can perform the t-test\n\nt.test(MaleChina$PV1MATH, FemaleChina$PV1MATH)\n\n# The p-value is <0.05 (2.414e-07) suggesting there are statistically\n# differences between boys and girls in mathematics in China\n\n\n\nNow try to compare the performance of males and females in all OECD countries in the PISA dataset. You may need to think about how to do this using R without repeating the test for each country\n\n\nAnswerMaleOECD <- PISA_2018 %>%\n  select(OECD, ST004D01T, PV1MATH) %>%\n  filter(OECD=='Yes', ST004D01T=='Male')\n\nFemaleOECD <- PISA_2018 %>%\n  select(OECD, ST004D01T, PV1MATH) %>%\n  filter(OECD=='Yes', ST004D01T=='Female')\n\nggqqplot(MaleOECD$PV1MATH)\nggqqplot(FemaleOECD$PV1MATH)\n\n# The plots produces relatively straight lines so the distributions can be assumed to be normal\n\n# We will then check the variances of the two data sets\n\nVarM <- var(MaleOECD$PV1MATH)\nVarF <- var(FemaleOECD$PV1MATH)\nVarM / VarF\n\n# The variance ratio is close to 1 (1.1)\n# So our two conditions are met and can we can perform the t-test\n\n# The p-value is <0.05 (2.2e-16) suggesting there are statistically\n# differences between boys and girls\nt.test(MaleOECD$PV1MATH, FemaleOECD$PV1MATH)\n\n\n\n\n6.2.4 Task 4\n\nLooking at the reading Cook (2014), consider the following\n\n\nIs it possible to replicate the results using the PISA 2018 data set? Make a graph showing the difference in male and female PV1MATH results for each country CNT. To do this we are going to have to:\n\n\nwork out the mean() maths score PV1MATH for each country CNT and gender ST004D01T grouping, call this meanmath and create a new dataframe to store this\nfrom this dataframe, create two new dataframes, one for males only and one for females only\n\nrename() (see Section 2.10.3) the meanmath score in each dataframe to male_mean and female_mean\n\nbind the dataframes together using using column bind function cbind(<male_df>, <female_df>) and store this in a new dataframe called Mathgendergap. NOTE: cbind only accepts tables with different names, so you’ll need to select select(CNT, male_mean) from the male dataframe and select(female_mean) from the female dataframe.\nuse mutate (see Section 2.10.5) to calculate the difference in male and female mean maths scores for each country\nplot the results for each country\n\n\ncreating difference dataset# A relatively simple recreation (without significance testing)\nMathgendergap <- PISA_2018 %>%\n  select(CNT,PV1MATH,ST004D01T) %>%\n  group_by(CNT,ST004D01T)%>%\n  summarise(meanmath=mean(PV1MATH)) %>%\n  ungroup()\n\n# alternative, using column binding, cbind():\nMathgendergap<-  cbind(Mathgendergap %>% \n                           filter(ST004D01T == \"Male\") %>%\n                           rename(male_mean = meanmath) %>%\n                             select(CNT, male_mean),\n                        Mathgendergap %>%\n                           filter(ST004D01T == \"Female\") %>%\n                             rename(female_mean = meanmath) %>%\n                             select(female_mean))\n\n# alternatively you can use pivot_wider\n# Mathgendergap <- pivot_wider(Mathgendergap, names_from = ST004D01T, values_from = meanmath)\n\nMathgendergap <- Mathgendergap %>%\n  mutate(difference = female_mean - male_mean) %>%\n  arrange(desc(difference))\n\n\n\nthe graphggplot(Mathgendergap,\n       aes(x=reorder(CNT, difference), y=difference, fill=difference))+\n  geom_col() +\n  geom_hline(yintercept = 0, lty=2) +  # add a line on 0\n  coord_flip() +                      # rotate the graph\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=5))\n\n\nThe above code doesn’t include the t-test results for each country, to do this we need to run some more complex code, you can see how it works below:\n\nAnswer# A fuller recreation with t-tests\n# conduct a ttest across countries on a specified column\nlibrary(broom)\n\nttest_by_country <- function(data, column = PV1MATH){\n\n  # work out which countries have full 30+ datasets for this ttest\n  countries <- data %>% ungroup() %>%\n    filter(!is.na({{column}})) %>%    # {{column}} allows you to change the field of focus\n    select(CNT, ST004D01T, {{column}}) %>%\n    group_by(CNT) %>%\n    filter(n() > 30) %>%\n    pull(CNT) %>%  # the pull command returns the column as a vector, not a table\n    unique()\n \n  # list the countries that don't meet that criteria\n  message(\"dropping: \", setdiff(unique(data$CNT), countries), \" as too few entries for ttest\")\n \n  # reduce the dataset to only those countries with 30+ entries\n  data <- data %>%\n    filter(CNT %in% countries)\n\n  # for each country in this new dataset perform a set of calculations\n  test_result <- map_df(unique(data$CNT),\n                        function(x){\n   \n                            # make a subset of the data just for that country\n                            df <- data %>% filter(CNT == x)\n                           \n                            # get the results pull({{column}}) for females and males as two separate vectors\n                            f_data <- df %>% filter(ST004D01T == \"Female\") %>% pull({{column}})\n                            m_data <- df %>% filter(ST004D01T == \"Male\") %>% pull({{column}})\n                           \n                            # tell us the number of results\n                            message(x, \" f:\", length(f_data), \" m:\", length(m_data))\n                           \n                            # work out the means of each vector\n                            f_mean <- mean(f_data)\n                            m_mean <- mean(m_data)\n                           \n                            t.test(m_data, f_data) %>%  # conduct a ttest on the male and female results\n                              tidy() %>%      # convert the ttest result into a dataframe\n                              mutate(CNT = x,           # add columns to record the country\n                                     f_mean = f_mean,   # the mean female grade\n                                     m_mean = m_mean,   # the mean male grade\n                                     gender_diff = m_mean - f_mean,  # the difference between the two\n                                     prop_male = length(m_data) / (length(m_data) + length(f_data)))\n                                     # and the proportion who are male in the dataset\n    })\n  return(test_result)\n}\n\nplot_ttest_by_country <- function(data, column = \"PV1MATH\"){\n\n  ggplot(data %>% mutate(sig = p.value < 0.05),\n         aes(x=reorder(CNT, gender_diff), y=gender_diff, colour=sig))+\n    geom_point(aes(size = prop_male)) +  \n    geom_hline(yintercept = 0, lty=2) +  # add a line on 0\n    coord_flip() +     # rotate the graph\n    xlab(\"country\") +\n    ylab(\"mean(male - female)\") +\n    ggtitle(paste(\"gender differences for:\", column)) +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5,\n                                     hjust=1, size=5))\n}\n\n# run the first function using 2018 data and the PV1MATH column\nttest_results <- ttest_by_country(PISA_2018, PV1MATH)\n\n#plot the results\nplot_ttest_by_country(ttest_results, \"PV1MATH\")\n\n\n\nAnswer# Alternatively, you could run the following:\n# run a ttest for each country\n# ttest_results <- PISA_2018 %>%\n#     filter(!is.na(PV1MATH)) %>% # Vietnam no results?!\n#     select(CNT, ST004D01T, PV1MATH) %>%\n#     group_by(CNT) %>%\n#     nest(data = c(ST004D01T, PV1MATH)) %>% #create a dataframe of gender results for each country\n#     summarise(tt = map(data, function(df){ # apply a ttest to each country\n#       t.test(df %>% filter(ST004D01T == \"Female\") %$% PV1MATH,\n#              df %>% filter(ST004D01T == \"Male\") %$% PV1MATH) %>%\n#         tidy() # convert results into a dataframe\n#     })) %>%\n#     unnest(tt)\n\n\n\nWhat issues are there with using a t-test for the context given in the paper?\nHow do your findings from question 3 and the 2018 dataset compare with those in the paper? Are there any differences or disagreements with your findings?\nHow could the paper be improved?"
  },
  {
    "objectID": "index.html#doing-t-tests-in-r",
    "href": "index.html#doing-t-tests-in-r",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n6.3 Doing t-tests in R",
    "text": "6.3 Doing t-tests in R\n\n\nYou can find the code from the video below:\n\nShow the Code# Introduction to t-tests in R\n#\n# Download data from /Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\n# You want the file: Students_2018_RBDP_none_levels.rds\n# and place in your own file system\n# change loc to load the data directly. Loading into R might take a few minutes\ninstall.packages(\"nortest\")\n\nlibrary(tidyverse)\nlibrary(nortest)\nloc <- \"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\"\nPISA_2018 <- read_rds(loc)\n\n# Are there differences between the mean scores of UK boys and girls in PISA mathematics?\n#\n# Select the gender (ST004D01T) and math score columns (PV1MATH)\n# Filter the data to select UK responses\n\nMaleUK<-PISA_2018 %>%\n  select(CNT,ST004D01T, PV1MATH) %>%\n  filter(CNT=='United Kingdom') %>%\n  filter(ST004D01T=='Male')\n\nFemaleUK<-PISA_2018 %>%\n  select(CNT,ST004D01T, PV1MATH) %>%\n  filter(CNT=='United Kingdom') %>%\n  filter(ST004D01T=='Female')\n\n# The conditions to do a t-test include that the data are normally distributed\n# and there is homogeneity (similarity) of the variances (the squared standard deviations)\n# Let us check the conditions are met by calculating first if the data sets are normally\n# distributed using the Pearson test of normality from the nortest package\n\npearson.test(as.numeric(MaleUK$PV1MATH))\npearson.test(as.numeric(FemaleUK$PV1MATH))\n\n# The p-values are over 0.05 so both distriburtions are normal\n# Pearson chi-square normality test\n#\n# data:  as.numeric(MaleUK$PV1MATH)\n# P = 75.714, p-value = 0.1936\n# Pearson chi-square normality test\n#\n# data:  as.numeric(FemaleUK$PV1MATH)\n# P = 74.06, p-value = 0.2589\n#\n# We will then check the variances of the two data sets\n\nVarM<-var(MaleUK$PV1MATH)\nVarF<-var(FemaleUK$PV1MATH)\nVarM/VarF\n\n# The variance ratio is close to 1 (1.1)\n# So our two conditions are met and can we can perform the t-test\n\nt.test(MaleUK$PV1MATH, FemaleUK$PV1MATH)\n\n# The p-value is <0.05 (4.061e-08) suggesting there are statistically\n# differences between boys and girls"
  },
  {
    "objectID": "index.html#chi-square-tests",
    "href": "index.html#chi-square-tests",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n7.1 Chi-square tests",
    "text": "7.1 Chi-square tests\nChi squared (\\(\\chi^2\\)) tests are non-parametric tests, this means that the test isn’t expecting the underlying data to be distributed in a certain way. Chi-squared determines how well the frequency distribution for a sample fits the population distribution and will let you know when things aren’t distributed as expected. For example you might expect girls and boys to have the same coloured dogs, a chi squared test can tell you whether the null hypothesis, that there is no difference between the colours of dogs owned by girls and boys, is true or not.\nIn more mathematical terms, chi squared examines differences between the categories of an independent variable with respect to a dependent variable measured on a nominal (or categorical) scale. A nominal scale has values that aren’t ordered, or continuous, for example gender or favourite flavour of icecream.\nChi-square tests can be categorised in two groups:\n\nA test of goodness of fit - this is a form of hypothesis test which determines whether a sample fits a wider population. For example, does the pattern of exam results in one school fit the national distribution?\nA test of independence - allows inference to be made about whether two categorical variables in a population are related. For example, are there differences in the uptake of careers by gender?\n\nIn the example below you will be loading data about Ofsted inspections to see if the Ofsted grade of a state secondary school varies dependent on whether the school is all boys, all girls or mixed."
  },
  {
    "objectID": "index.html#an-example-are-schools-with-more-students-from-socio-economically-deprived-backgrounds-scored-in-the-same-as-schools-with-more-affluent-students-by-ofsted",
    "href": "index.html#an-example-are-schools-with-more-students-from-socio-economically-deprived-backgrounds-scored-in-the-same-as-schools-with-more-affluent-students-by-ofsted",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n7.2 An example: Are schools with more students from socio-economically deprived backgrounds scored in the same as schools with more affluent students by Ofsted?",
    "text": "7.2 An example: Are schools with more students from socio-economically deprived backgrounds scored in the same as schools with more affluent students by Ofsted?\n\n\n\n\n\n\nTip\n\n\n\nIn England, the Office for Standards in Education, Children’s Services and Skills (Ofsted), inspects schools to judge the quality of education. They categorise schools into five categories: Outstanding, Good, Requires Improvement, Inadequate, and Special Measures.\nFree School Meals refers to support for students who receive free meals at school - this funding is available for students whose parents or carers receive certain government benefits, typically due to relatively low income. It is taken, by some policy makers and researchers, as a marker of socioeconomic disadvantage"
  },
  {
    "objectID": "index.html#loading-the-data",
    "href": "index.html#loading-the-data",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n7.3 Loading the data",
    "text": "7.3 Loading the data\nThe data for this example come from the DfE edubase system. This system is updated almost daily with information on all education providers in the country.\n\n\n\n\n\n\nTip\n\n\n\nNote, we will use the term ‘providers’ rather than, for example, schools, as some of the institutions in the data set are not schools, but providers of education also inspected by Ofsted, such as childminders\n\n\nThe snapshot below was taken in 2018, you are welcome to download a later copy.\n\n# Download data on all educational providers in England\n# with details on FSM and Ofsted inspections\n\nlibrary(\"tidyverse\")\nlibrary(\"openxlsx\")\n\nDfE_schools_2018 <- read.xlsx(\"https://drive.google.com/uc?export=download&id=1tp9xe3dS__eg7RrXf0T_oMxcrz_TbMdM\",\n                      sheet=\"Schools\")"
  },
  {
    "objectID": "index.html#categorising-the-data",
    "href": "index.html#categorising-the-data",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n7.4 Categorising the data",
    "text": "7.4 Categorising the data\nThe dataset is very large, about 60Mb of data about 50,000 educational providers, both historic and current. For this exercise, we will filter the data set to state secondary schools that are currently open. As Chi-squared uses categorical variables, we will sort the schools into three categories (high, medium and low) based on the number of students receiving free school meals. The proportion of students receiving free school meals is sometimes taken as a proxy variable for social disadvantage (though that assumption has been critiqued Taylor (2018)).\n\n# note that 2018 data doesn't have inadequate\n\nOfsted_ratings <- DfE_schools_2018 %>%\n  filter(Open == \"Open\",\n         EstablishmentGroup != \"Independent schools\",\n         Phase == \"Secondary\",\n         OfstedRating %in% c(\"Outstanding\", \"Good\",\n                             \"Requires improvement\",\"Inadequate\",\n                             \"Special Measures\")) %>%\n  mutate(FSM_group = ntile(FSM, n=3)) %>%\n  mutate(FSM_group = ifelse(FSM_group == 3,\n                            \"High\",\n                            ifelse(FSM_group == 2,\n                                   \"Medium\",\n                                   \"Low\")))"
  },
  {
    "objectID": "index.html#contingency-tables",
    "href": "index.html#contingency-tables",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n7.5 Contingency tables",
    "text": "7.5 Contingency tables\nTo get a feel for what the data looks like we can build a contingency table. A contingency table is a table which shows the frequency of occurrence of different groups.\nIn our example, the contingency table, will show the number of providers that match each combination of of the two groupings we are looking at, OfstedRating and the FSM_group. To make a contingency table, we will first count each group of OfstedRating and FSM_group. This makes a list of the number of instances of each group:\n\n# to get a frequency table of the above we can use group_by\n\nOfsted_ratings_freq <- Ofsted_ratings %>%\n  group_by(OfstedRating, FSM_group) %>%\n  count()\n\nprint(Ofsted_ratings_freq)\n\n# A tibble: 12 × 3\n# Groups:   OfstedRating, FSM_group [12]\n   OfstedRating         FSM_group     n\n   <chr>                <chr>     <int>\n 1 Good                 High        486\n 2 Good                 Low         506\n 3 Good                 Medium      577\n 4 Outstanding          High         90\n 5 Outstanding          Low         252\n 6 Outstanding          Medium      100\n 7 Requires improvement High        222\n 8 Requires improvement Low          69\n 9 Requires improvement Medium      145\n10 Special Measures     High         34\n11 Special Measures     Low           5\n12 Special Measures     Medium       10\n\n\nTo put this into a contingency table we can use pivot_wider (see below), this will keep the FSM_group and by fetching names_from = OfstedRating, it will create a new column for each OfstedRating and will then show how many instances of each combined OfstedRating and FSM_group there are.\n\n# build a contingency table of Ofsted rating\ncontingency_table <- Ofsted_ratings_freq %>% \n  pivot_wider(names_from = OfstedRating,\n              values_from = n)\nprint(contingency_table)\n\n# A tibble: 3 × 5\n# Groups:   FSM_group [3]\n  FSM_group  Good Outstanding `Requires improvement` `Special Measures`\n  <chr>     <int>       <int>                  <int>              <int>\n1 High        486          90                    222                 34\n2 Low         506         252                     69                  5\n3 Medium      577         100                    145                 10\n\n\n\n\n\n\n\n\nTip\n\n\n\nAn important step in using chisq.test (and many statistical functions in R) is getting the data into the right format to pass to chisq.test. As you can see, most of the steps above involve formatting the data so it is in a form the function expects. R tends to use a long format, whereas in the real world we tend to use a wide format.\nThe wide format looks like this (there are multiple measurements per row and the school names don’t repeat):\n\n\n\nMath\nEnglish\nScience\n\n\n\nSchool A\n82\n91\n88\n\n\nSchool B\n52\n56\n57\n\n\nSchool C\n23\n31\n32\n\n\n\nThe long format has values that repeat in the first column\n\n\n\nSubject\nAvg Score\n\n\n\nSchool A\nMath\n82\n\n\nSchool A\nEnglish\n91\n\n\nSchool A\nScience\n88\n\n\nSchool B\nMath\n52\n\n\nSchool B\nEnglish\n56\n\n\n\nThe pivot_wider and pivot_longer functions switch between the two forms of table\nUsing pivot_wider\npivot_wider is a function that turns a table in wide form into long form. The inputs of pivot wider are first, the names of the columns you want to turn into a single column. For example, to produce the long form of the table of results above, I want to turn the three columns of Math, English and Science scores into a single column.\nThe first information I pass pivot_wider is the names of those columns: cols=c(\"Math\", \"English\", \"Science\"). Second, when I stack those values, I will end up with two new columns, one with the names of the subjects, and one with the values of the scores. I tell pviot_wider what I want the titles of the new column to be: names_to= \"subject\" with the values stored in a column called values_to= \"scores\".\n\n# Imagine you start with this table of data on students\n#\n# | Student | Math | English | Science |\n# |---------|------|---------|---------|\n# | A       | 27   | 31      | 21      |\n# | B       | 81   | 92      | 78      |\n#\n# pivot_longer can convert this table into a long form table:\n#\n# | Student | Subject | Score\n# | A       | Math    | 27\n# | A       | English | 31\n# | A       | Science | 21\n# | B       | Math    | 81\n# | B       | English | 92\n# | B       | Science | 78\n# \n# \n#\n\nlibrary(tidyverse)\nresults <- data.frame(student=c(\"A\",\"B\"),    # Create the data.frame of the table above\n                     Math=c(27,81),\n                           English=c(31,92),\n                             Science=c(21,78))\nprint(results)                            # Display the wide form of the table\n\n  student Math English Science\n1       A   27      31      21\n2       B   81      92      78\n\nlongresults <- results %>% \n  pivot_longer(cols=c(\"Math\", \"English\", \"Science\"),  \n                        # indicates we want to stack these 3 columns\n  names_to= \"Subject\",  # gives the name of the new, longer label column\n  values_to= \"Score\")  # gives the name of the new, longer values column\n                        \nprint(longresults)     # Print the wide form of the table\n\n# A tibble: 6 × 3\n  student Subject Score\n  <chr>   <chr>   <dbl>\n1 A       Math       27\n2 A       English    31\n3 A       Science    21\n4 B       Math       81\n5 B       English    92\n6 B       Science    78"
  },
  {
    "objectID": "index.html#plotting-the-chi-square-relationships",
    "href": "index.html#plotting-the-chi-square-relationships",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n7.6 Plotting the chi-square relationships",
    "text": "7.6 Plotting the chi-square relationships\nThe numbers in the contingency table are hard to interpret - it is challenging to see how far out the numbers for each row are from each other. Alternatively, we can visualise the data from the contingency table by building a mosaic plot, a form of stacked bar chart. Mosaic plots can be a useful visulations before running a chi-squared test.\nTo create a mosaic plot, you are going to need to install and load the ggmosaic package. See Section 2.6.1 for more details on how to do this. To create the mosaic plot we use ggplot, as we used for previous graphs. As before, we first pass the data (in this case Ofsted_ratings) to ggplot. Then, to create the graph, geom_mosaic is used. geom_mosaic does not have a direct mapping of input to x and y variable so we need to pass it what we want plotted on the y-axis (OfstedRating) and x-axis (FSM_group) within the product function. We can also specify how we want the rectangles to be coloured (in our case, by OfstedRating).\n\n # install.packages(\"ggmosaic\")\nlibrary(ggmosaic)\n# plot results\nggplot(data = Ofsted_ratings) +\n  geom_mosaic(aes(x = product(OfstedRating, \n                              FSM_group), \n                  fill = OfstedRating))\n\n\n\n\nYou can see in the example above, that the order of the axes is not what we would normally expect. The y-axis goes from requires improvement, to outstanding, and then to good. The x-axis runs: high, low, medium.\nThe order of the x and y axis on the table are defined by the levels of the data. This is an R-specific concept. Where R stores categorical variables, for example, high, medium and low, to save space, the variables are converted to numbers, e.g. low=0, medium=1, high=2. These values are known as factors and can be ordered or unordered (for more information about factors see Section 2.11.2). To reorder the factors in the axes, we can reorder the factors, by creating a vector that sets out the order we want (rdr <- c(\"Outstanding\", \"Good\", \"Requires improvement\", \"Special Measures\")). We then use mutate to make the change to the data.frame. In the case of the FSM_groups, rather than defining a new vector (as we did for Ofsted_rating, e.e. the vector rdr), we set the new order directly in the mutate function: FSM_group = factor(FSM_group, levels=c(\"Low\", \"Medium\", \"High\"))\n\n# install.packages(\"ggmosaic\")\nlibrary(ggmosaic)\n\n# add order to the factors involved in the mosaic\nrdr <- c(\"Outstanding\", \"Good\", \"Requires improvement\", \"Special Measures\") \n\nOfsted_ratings <- Ofsted_ratings %>% \n  mutate(OfstedRating = factor(OfstedRating, \n                               levels=rdr),\n        FSM_group = factor(FSM_group, \n                           levels=c(\"Low\", \"Medium\", \"High\")))\n\n# plot results\nggplot(data = Ofsted_ratings) +\n  geom_mosaic(aes(x = product(OfstedRating, \n                              FSM_group), \n                  fill = OfstedRating))"
  },
  {
    "objectID": "index.html#running-chi-square-tests",
    "href": "index.html#running-chi-square-tests",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n7.7 Running Chi square tests",
    "text": "7.7 Running Chi square tests\nNow we have the providers that we want, we can start to build a chi-square test. This is very easy in R and it follows the following structure:\nchisq.test(<column_one>, <column_two>)\nFor the data above, we are comparing the combinations of entries for OfstedRating and FSM_group:\n\nchisq.test(Ofsted_ratings$OfstedRating, Ofsted_ratings$FSM_group)\n\n\n    Pearson's Chi-squared test\n\ndata:  Ofsted_ratings$OfstedRating and Ofsted_ratings$FSM_group\nX-squared = 230.58, df = 6, p-value < 2.2e-16\n\n# summary(chisq.test(Ofsted_ratings$OfstedRating, Ofsted_ratings$FSM_group))\n\nIn the case of a goodness of fit test, we can set the two columns to the observed populations and the expected probabilities. The expected vector should be of the form of probabilities and so add to one. With a goodness of fit, the null hypothesis is that the sample is part of the population. A p-value of greater than 0.05 implies that the null hypothesis should be accepted and that the sample fits well with the population as a whole.\nFor example, imagine we want to determine whether the biology a-level results of a school match, the national scores. We can look up the national levels of performance and express them as probabilities:\n\n\n\n\n\n\n\n\nGrade\nPercentage nationally (in 2022)\nProbability nationally\nObserved numbers in school\n\n\n\nA*\n13.3%\n0.133\n10\n\n\nA\n21.6\n0.216\n15\n\n\nB\n21.6\n0.216\n20\n\n\nC\n19.5\n0.195\n5\n\n\nD\n14.2\n0.142\n1\n\n\nE\n7.6\n0.076\n0\n\n\nU\n2.2\n0.022\n0\n\n\n\nWe need to define an expectedbio vector which contains the probabilities of gaining a particular grade. We create the observedbio vector with the actual numbers getting a grade in school. Then pass the vectors to chisq.test:\n\nexpectedbio<-c((13.3/100), (21.6/100), (21.6/100), (19.5/100), (14.2/100),(7.6/100), (2.2/100))\nobservedbio<-c(10,15,20,5,1,0,0)\nchisq.test(observedbio, expectedbio)\n\n\n    Pearson's Chi-squared test\n\ndata:  observedbio and expectedbio\nX-squared = 28, df = 25, p-value = 0.3079\n\n\nThe test here returns a p-value of 0.3079. This implies there is no statistically significant deviation from the null hypothesis. Hence, the null hypothesis, that the school sample matches the national population can be accepted."
  },
  {
    "objectID": "index.html#seminar-tasks-2",
    "href": "index.html#seminar-tasks-2",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n7.8 Seminar Tasks",
    "text": "7.8 Seminar Tasks\n\n7.8.1 Activity 1 - Uptake of single science in a school\nFor the initial activity, we will replicate the chi-square goodness of fit test in example on in the lecture. By goodness of fit test, we mean to determine if the data in a sample match the whole population (that is, is a there a good fit between the sample and the whole population?). In this activity we ask, does the number of students taking single or combined science in a particular school matches the national pattern.\n\n\n\n\n\n\nTip\n\n\n\nIn England, studying science till the age of sixteen is compulsory. However, schools and students can decide on the depth of material they wish to study.\nStudents opting for the lowest level, take a course called single science. Those wanting to learn more about science can take double science (and the highest level of study is triple science, where students study the three sciences, physics, biology, and chemistry as separate courses).\nA school has a frequency count of 129 students taking combined sciences and 111 opting for single science. The national total for combined sciences was 424,704 and for single sciences was 164,944. Use a chi squared test (as a goodness of fit test) to determine whether the proportion of students taking combined and single science in the school is inline or not with the national average.\n! Hint - look at the example above. Make two vectors, an expected vector, for the country and an observed vector for the school. Recall you can simply use the <- operator to put data into a vector (e.g. observed<-c(50,100)) . You will need to calculate percentages for the expected values.\n\n\n\nShow the code#Find totals\nTotalSchool <- sum(129,111)\nTotalNational <- sum(424704,164944)\n#create contingency tables\nobserved <- c(129,111)\nexpected <- c(424704/TotalNational,164944/TotalNational) \n#For R, the expected must total 1, so you find the percentage expected not the total\n#Check you've done the calculation correctly for expected by printing\nprint(expected)\n#run the chi-square test\nchisq.test(x=observed,p=expected)\n#Chi-squared test for given probabilities\n\n#data:  observed\n#X-squared = 39.79, df = 1, p-value = 2.828e-10\n\n#since p<0.05 we reject H0 (the null hypothesis), so accept H1 (the alternative hypothesis) that the school does not fit the national pattern\n\n\n\n7.8.2 Activity 2 - Vocational schools and gender in the PISA dataset\nFor these activities, we will first use the PISA 2018 data set.You can load the PISA_2018 data set using these steps. Click here to download the parquet file: PISA_2018.parquet\nTo load the data, use the code below:\n\ninstall.packages(\"arrow\") # if you haven't already\nlibrary(arrow)\nlibrary(tidyverse)\nPISA_2018 <- read_parquet(\"<location of the downloaded PISA_2018.parquet file>\")\n\n\nWe will now use the the chi-squared test as a test of independence.\nWe want to see if there are more boys or girls in vocational schools than might be expected. That is, we want to test if the variables of gender and school orientation are independent.\nThe null hypothesis in this case is: gender and school orientation are independent.\nRecall that a p-value greater than 0.05 suggest the null hypothesis is accepted (i.e. there is no statistically significant difference in gender distribution by school orientation). If p is less than 0.05, then the null hypothesis can be rejected, and we assume there are statistically significant differences in the gender distribution by school orientation.\nDetermine if the distribution of genders (ST004D01T) and school orientation (ISCEDO) (Pre-vocational, Vocational, General) is independent or not, for:\na) the whole data set,\nb) the UK,\nc) Germany,\nd) a country of your choice.\nST004D01T is the gender variable (Male, Female) and ISCEDO is a categorical variable (Vocational, General, Pre-Vocational).\nComplete the following steps to help answer the question:\na) Create a table to display sets of data for each case and use this to check for any issues with the data such as missing frequency counts. Note that R requires the two vectors passed to chisq.test to be the same length. if a particular type of school is missing in your table, you will need to add it in to make sure the two vectors are the same length. You can add another row, with zeros using: add_row(ISCEDO=\"Modular\", type=0) Note that, ISCEDO and type are the names of the two columns.\nb) Run the chi-square test.\nc) Write down the p-value and the result of your chi-square test in the context of the question.\nd) Extension- Display the data using geom_mosaic\n\n\nShow the code# Are there differences in the type of school by gender\n# ST004D01T is the gender variable (Male, Female)\n# ISCEDO is a categorical variable (Vocational, General, Pre-Vocational)\n\n#i) a)\n#Sort data and table\n\nTotalchidata <- PISA_2018 %>%\n  select(ST004D01T,ISCEDO)%>%\n  drop_na()\n\ntable(Totalchidata$ST004D01T, Totalchidata$ISCEDO)\n\n#i) b)\n# run the test\nchisq.test(Totalchidata$ST004D01T, Totalchidata$ISCEDO)\n\n#check expected values\nchisq.test(Totalchidata$ST004D01T, Totalchidata$ISCEDO)$expected\n\n#i) c)\n# p-value < 2.2e-16, so reject H0 and accept H1 that proportion of gender is related to institution type\n\n#i) d)\nlibrary(ggmosaic)\nggplot(data = Totalchidata) +\n  geom_mosaic(aes(x = product(ST004D01T, \n                              ISCEDO), \n                  fill = ISCEDO), check_overlap=TRUE)+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n#ii) a)\n\nUKchidata <- PISA_2018 %>%\n  select(CNT,ST004D01T,ISCEDO)%>%\n  filter(CNT==\"United Kingdom\")%>%\n  drop_na()\n\ntable(UKchidata$ST004D01T,UKchidata$ISCEDO)\n\n#ii)b)\n# run the test\nchisq.test(UKchidata$ST004D01T, UKchidata$ISCEDO)\n\n#check expected values\nchisq.test(UKchidata$ST004D01T, UKchidata$ISCEDO)$expected\n#note than one value is <5, but over 80% cells are >5 so OK. Perhaps consider removing one variable\n\n#ii)c)\n\n#p-value = 0.9956 so >0.05 so accept H0 that proportion of gender is independent of school type.\n\n#ii)d)\nggplot(data = UKchidata) +\n  geom_mosaic(aes(x = product(ST004D01T, \n                              ISCEDO), \n                  fill = ISCEDO))+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n# iii)a)\nGerchidata <- PISA_2018 %>%\n  select(CNT,ST004D01T,ISCEDO)%>%\n  filter(CNT==\"Germany\")%>%\n  drop_na()\n\ntable(Gerchidata)\n\n#iii)b)\n# run the test\nchisq.test(Gerchidata$ST004D01T, Gerchidata$ISCEDO)\n\n#check expected values\nchisq.test(Gerchidata$ST004D01T, Gerchidata$ISCEDO)$expected\n\n#iii)c)\n#p-value = 6.892e-07, so <0.05, therefore reject H0 and accept H1 that gender proportion is related to school type\n\n#iii)d)\nggplot(data = Gerchidata) +\n  geom_mosaic(aes(x = product(ST004D01T, \n                              ISCEDO), \n                  fill = ISCEDO))+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n7.8.3 Activity 3 - Are the number of students in vocational and general schools in Germany proportionate to the whole PISA 2018 data set?\n\nComplete the following steps to determine if the number of students in general and vocational schools in Germany are proportionate to the whole PISA 2018 data set.\n\nCreate the expected vector with the proportions of General, Pre-Vocational, Vocational and Modular schools out of the overall total.\nCreate the observed vector the total number of General, Pre-Vocational, Vocational and Modular schools in Germany.\nCalculate the chi-square test p-value.\nState the p-value and interpret the result in the context of the question.\n\n\n\nShow the code#a)\nTotalchidata2<- PISA_2018 %>% \n  select(ISCEDO) %>% \n  drop_na() %>% \n  mutate(total = n()) %>% \n  group_by(ISCEDO) %>% \n  summarise(type = n(), per = type /unique(total))\n\nTotalexpected<-c(Totalchidata2$per)\n\n#b)\nGerchidata2 <- PISA_2018 %>% \n  select(CNT,ISCEDO)%>% \n  filter(CNT==\"Germany\")%>% \n  drop_na()%>% \n  mutate(total = n()) %>% \n  group_by(ISCEDO) %>% \n  summarise(type = n())\n\nGerchidata3 <- Gerchidata2%>% add_row(ISCEDO=\"Modular\", type=0)\nTotalobserved<-c(Gerchidata3$type)\n\n#c)\nchisq.test(x=Totalobserved,p=Totalexpected)\n\n#d) p-value < 2.2e-16, so p<0.05, therefore reject H0 and accept H1\n\n\n\n7.8.4 Activity 4 - Create your own question that uses the chi-square test from the PISA Dataset\n\nCreate your own question that investigates the PISA data using either the chi-square test for independence or chi-square goodness of fit test.\n\n\n7.8.5 Activity 5 - Determine if admissions type in LAs are proportionate to national averages\n\n\n\n\n\n\nTip\n\n\n\nTo join together two vectors you can use the rbind function to join two vectors together\n\nVector1<-data.frame(Names=c(\"A\",\"B\",\"C\"))\nVector2<-data.frame(Names=c(\"D\",\"E\",\"F\"))\nVector3<-rbind(Vector1,Vector2)\nprint(Vector3)\n\n  Names\n1     A\n2     B\n3     C\n4     D\n5     E\n6     F\n\n\n\n\n\nLooking at the DfE Data set, choose a Local Authority (I suggest Dorset) and determine if the proportion of selective and non-selective schools are statistically similar or different to the national average. Comment on any potential issues with the data or the approach.\n\n\nShow the code# Load the file for the task\nloc<-\"https://drive.google.com/uc?export=download&id=1tp9xe3dS__eg7RrXf0T_oMxcrz_TbMdM\"\nDfE_schools_2018 <- read.xlsx(loc,sheet=\"Schools\")\n# Create a dataframe of the admission policies of Dorset schools\nDorsetschAd<-DfE_schools_2018 %>%\n  select(LA,AdmissionsPolicy)%>%\n  filter(LA==\"Dorset\")\n# Create a dataframe of the admission policies of all non-Dorset schools (note LA! means\n# not equal to)\nOtherUKSch<-DfE_schools_2018 %>%\n  select(LA,AdmissionsPolicy)%>%\n  filter(LA!=\"Dorset\")\n# OtherUKSchs are labelled by LA so reset all these names just to UK\nOtherUKSch$LA<-\"UK\"\n# Join the two frames to give one long list\nAllSch<-rbind(OtherUKSch, DorsetschAd)\n# To check what test to do print the frequency table\ntable(AllSch)\n# And a percentage version\n(100*prop.table(table(AllSch)))\n# Expected values are fine so use the Chi squared test\n# AdmissionsPolicy\n# LA       Non-selective Not applicable    Selective\n# Dorset   0.059974356    0.349505729  0.006204244\n# UK      16.075195434   81.718161889  1.790958349\n# Note \nchisq.test(AllSch$LA, AllSch$AdmissionsPolicy, simulate.p.value = TRUE)\n\n\n\n7.8.6 Activity 6 - Determine if Ofsted rating and gender of school are independent\n\nLooking again at the DfE Data set, compare Ofsted rating of the school against gender to determine if these are independent or not. You may wish to focus on a particular phase (such as secondary) and only include certain Ofsted ratings. Comment on any issues with the data.\n\n\nShow the code# Is there a relationship between school gender and Ofsted Rating?\n\nchisq.test(DfE_schools_2018$Gender,DfE_schools_2018$OfstedRating, simulate.p.value = TRUE)\n# Yes!\n# Pearson's Chi-squared test with simulated p-value (based on 2000 replicates)\n#\n# data:  DfE_schools_2018$Gender and DfE_schools_2018$OfstedRating\n# X-squared = 675.4, df = NA, p-value = 0.0004998\n\n\n\n7.8.7 Activity 7 - Create your own problem\n\nUsing the DfE Data set (or otherwise), create a research question which requires one of the chi-square tests to answer the question. State clearly what your null and alternative hypothesis are, what you are using as the significance level, what the chi-square calc and/or p-values for the test are, what conclusion you make, and any issues you think there are with the test.\n\n\n7.8.8 Activity 8 - Checking chi-square test in a research paper\n\n\n\nIn this activity you are going to look at the data presented in a paper by Mutodi and Ngirande (2014). They present the relationships between a number of demographic factors and maths anxiety. For example, table 3 in the paper looks at the relationship between gender and maths anxiety.\n\nanx3_table_out\n\n\n\n\n\n\nGender\n      High level of anxiety\n      Moderate level of anxiety\n      No math anxiety\n      Not sure\n      Total\n    \n\n\nFemale\n14\n10\n3\n9\n36\n\n\nMale\n26\n35\n6\n17\n84\n\n\nTotal\n40\n45\n9\n26\n120\n\n\n\nSource: Table 3, Mutodi, P. and Ngirande, H. (2014) The influence of studentsperceptions on Mathematics performance. A case of a selected high school in South Africa. Mediterranean Journal of Social Sciences\n    \n\n\n\n\nThe raw survey data is available in a two column csv format, with each row equal to one survey response. The first column being the demographic data; in the case below, Gender, and the second column listing the student’s answer to the questions about maths anxiety, listed here as name:\n\nanx3_data %>% head(3)\n\n# A tibble: 3 × 2\n  Gender name                 \n  <chr>  <chr>                \n1 Male   High level of anxiety\n2 Male   High level of anxiety\n3 Male   High level of anxiety\n\n\n\n\nUsing the gender and maths anxiety dataset, group the Gender and name fields, counting the number of responses in each group.\nComment on any issues you find with the data, the methodological or the calculations.\nrepeat this for Table 4 (HINT: you won’t be grouping by Gender this time!)\nrepeat this for Table 5\n\n\nNow you have had a brief explore of the data we need to conduct some chi-square tests to check whether the results between groups are\n\n\nShow the code# Load the csv files for the three tables\nloc<-\"<your HDD>/anx_table_3.csv\"\nanxiety_table_3 <- read_csv(loc)\n\nloc<-\"<your HDD>/anx_table_4.csv\"\nanxiety_table_4 <- read_csv(loc)\n\nloc<-\"<your HDD>/anx_table_5.csv\"\nanxiety_table_5 <- read_csv(loc)\n\n\n# This section gets the data into the correct format for the square test in R\n# The Count tables are turned back into a long list of entries like this:\n# A tibble: 120 × 2\n#Gender name                 \n#<chr>  <chr>                \n# 1 Male   High level of anxiety\n# 2 Male   High level of anxiety\n# 3 Male   High level of anxiety\n#\n# That is done by \n# 1) Select(-total) removes the total column which we don't need \n# 2) filter(Gender !=\"Total\") removes the row that stores totals\n#    leaving just the rows storing actual data\n# 3) pivot_longer turns the table into a long dataframe, -Gender\n#    ignores/keeps the Gender column and converts all the other\n#    columns into one column, with the heading and matching value \n#    making up new rows\n# 4) uncount turns the counts stored in value in the table into \n#    individual entries, e.g. Male, No anxiety, 45 would create \n#    45 rows with \"Male, No anxiety\"\n\nanx_3 <- Anxietytable3 %>% \n  select(-Total) %>% \n  filter(Gender != \"Total\") %>%\n  pivot_longer(-Gender) %>% \n  uncount(value)\n\nanx_4 <- Anxietytable4 %>% \n  select(-Total) %>% \n  filter(Age != \"Total\") %>%\n  pivot_longer(-Age) %>% \n  uncount(value)\n\nanx_5 <- Anxietytable5 %>% \n  select(-Total) %>% \n  filter(HomeLang != \"Total\") %>%\n  pivot_longer(-HomeLang) %>% \n  uncount(value)\n\n# save long dataframes\n# write.csv(anx_3, glue(\"{loc_amy}Amy/anx_table_3.csv\"), row.names = FALSE)\n# write.csv(anx_4, glue(\"{loc_amy}Amy/anx_table_4.csv\"), row.names = FALSE)\n# write.csv(anx_5, glue(\"{loc_amy}Amy/anx_table_5.csv\"), row.names = FALSE)\n\n# conduct chi-square tests\nchisq.test(anx_3$Gender, anx_3$name)\nchisq.test(anx_4$Age, anx_4$name)\nchisq.test(anx_5$HomeLang, anx_5$name)\n\n# conduct - Kruskal-Wallis tests\nkruskal.test(anx_3$Gender, anx_3$name)\nkruskal.test (anx_4$Age, anx_4$name)\nkruskal.test (anx_5$HomeLang, anx_5$name)\n\n\n\n7.8.9 Doing Chi-Square tests in R\n\n\nYou can find the code used in the video below\n\n# Introduction to Chi-square\n#\n# Download data from /Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\n# You want the file: Students_2018_RBDP_none_levels.rds\n# and place in your own file system\n# change loc to load the data directly. Loading into R might take a few minutes\n\nloc <- \"https://drive.google.com/open?id=14pL2Bz677Kk5_nn9BTmEuuUGY9S09bDb&authuser=richardandrewbrock%40gmail.com&usp=drive_fs\"\nPISA_2018 <- read_rds(loc)\n\n# Are there differences between how often students change school?\n# ST004D01T is the gender variable (Male, Female)\n# SCCHANGE is a categorical variable (No change / One change / Two or more changes)\n\nchidata <- PISA_2018 %>%\n  select(CNT,ST004D01T,SCCHANGE) %>%\n  filter(CNT==\"United Kingdom\")\n\nchidata<-chidata[-c(1)]\nchidata<-drop_na(chidata)\n\n chidata <- PISA_2018 %>%\n   filter(CNT==\"United Kingdom\")\n   select(ST004D01T,SCCHANGE) %>% \n   drop_na()\n# Above is the approiach I took in the video\n# An alternative, Pete suggests, which is more elegant, is below\n# Note he drops the country varibale, within the piped section\n# using: elect(-CNT)\n#    \n# chidata <- PISA_2018 %>%\n#   select(CNT,ST004D01T,SCCHANGE) %>%\n#   filter(CNT==\"United Kingdom\") %>%\n#   select(-CNT) %>% \n#   drop_na()\n\n# run the test\nchisq.test(chidata$ST004D01T, chidata$SCCHANGE)"
  },
  {
    "objectID": "index.html#analysis-of-variation-anova",
    "href": "index.html#analysis-of-variation-anova",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.1 Analysis of Variation (Anova)",
    "text": "8.1 Analysis of Variation (Anova)\nYou have now learned how to find if the means of two groups are different to a statistically significant degree - you use a t-test. However, t-tests are used to compare two groups. When more than two groups are compared, a different test is required, an analysis of variation or anova test.\nAnova refers to a collection of tests that can be used to analyse the varriance in means between groups (hence analysis of variation, or anova for short). For example, consider the data below, which show students scores on a test, their age in years and socio-economic class (categorised as high or low):\n\n\nSocio\nAge\nScore\n\n\n\nHigh\n15\n100\n\n\nHigh\n16\n98\n\n\nHigh\n11\n89\n\n\nHigh\n15\n98\n\n\nLow\n11\n21\n\n\nHigh\n14\n31\n\n\nLow\n12\n23\n\n\nHigh\n16\n92\n\n\nHigh\n12\n99\n\n\nLow\n15\n19\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that an assumption of an anova test is that the variables are normally distributed, and have equal variance. This is not the case with the small data set in this example. It is a teaching illustration.\n\n\n\nWhich variable, age or socio-economic class, seems to explain the variation in test scores?\n\nWe can use anova to determine, first, if there is statistically significant differences in the variation of scores by class and age. Second an additional anova analysis (a post-hoc analysis, so-called because it comes after the first test) can determine how much variation each variable (class and age) accounts for.\nYou can get a sense of this difference graphically by plotting graphs of the distribution of scores by socio-economic class:\n\nTestscores <- data.frame(socio=c(\"High\",\"High\",\"High\",\"High\",\"Low\",\"High\",\"Low\",\"High\",\"High\",\"Low\"),\n                       score=c(100,98,89,98,21,31,23,92,99,19),\n                       Age=c(15,16,11,15,11,14,12,16,12,15))\nggplot(Testscores,\n       aes(x=score, fill=socio))+\n  geom_density(alpha=0.5)\n\n\n\n\nIt looks like there might be a difference in the variation of scores by those in different classes (notice that the normal distribution seems more spread out for the high socio-economic students’ group, i.e. there is a larger variance than for low socio-economic group students’ scores).\nTo simply the analysis of variation with age, we can categorise ages into two groups, under 15, and 15 and over:\n\n# Testscores$Age[Testscores$Age>=15] <- \"Fifteen and over\"\n# Testscores$Age[Testscores$Age<15]  <- \"Under fifteen\"\nTestscores <- Testscores %>% \n  mutate(Age = ifelse(Age >= 15, \n                      \"Fifteen and over\", \n                      \"Under fifteen\"))\n  # Here the mutate function changes the column age\n  # ifelse changes the Age column to \"Fifteen and over\" if\n  # the varibale is over 15, and otherwise (ifelse) to\n  # \"Under fifteen\"\n# Then we plot a graph, using geom_density, to get a representaiton of the\n# distribution\nggplot(Testscores,\n       aes(x=score, fill=Age))+\n  geom_density(alpha=0.5)\n\n\n\n\nThe difference is less clear for age than class, but, visually, there appears to be some difference in variance between the two groups.\nTo determine if there is a statistically significant difference between groups we run an anova calculation, using the aov function in R. The dependent variable is the one we are interested in explaining, the independent variables are the factors we think might explain the variance.\naov(data, dependent_var ~ independent_var + independent_var + ...)\nWe pass the function the data we wish to focus on (Testscores) and then indicate we wish to look for variation in the score, by Age and socio (social class) - aov(data=Testscores, score ~ Age + socio). We then summarise the result to get a table.\n\nresaov <- aov(data=Testscores, score ~ Age + socio)\nsumresaov <- summary(resaov)\nsumresaov\n\n            Df Sum Sq Mean Sq F value  Pr(>F)   \nAge          1   2074    2074   4.707 0.06667 . \nsocio        1   7638    7638  17.338 0.00422 **\nResiduals    7   3084     441                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe resulting table has three rows: Age and socio (the two vectors we input to examine) and a third, residuals. The aov function looks to determine if there is a difference in the variance of groups of different ages (under fifteen and over) and class (high and low). After determining any variation from those two variables, any remaining variation is associated with residuals - you can think of this as the unexplained variation that isn’t associated with the vectors we specified (age and class).\nFirst, look at the Pr(>F) column. This is a test of significance and reports if the groups in that row show statistically significant variation. For example, Age returns Pr(>F) 0.07 - which is over 0.05 therefore there is no significant difference in variance between the two age groups. However, for class, Pr(>F) is 0.00422** suggesting there is a significant difference by class."
  },
  {
    "objectID": "index.html#eta-squared",
    "href": "index.html#eta-squared",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.2 Eta-squared",
    "text": "8.2 Eta-squared\nNow knowing that there are significant differences between the two class groups, we can next determine how much variation in the test score is explained by class. To do this we calculate a variable called eta-squared.\nEta-squared gives the proportion of variance explained by each variable. The eta squared function is in the package lsr so we will install lsr, and then use the result of our anova (resaov) to calculate the eta squared variable using the function etaSquared. To report the value of eta as a percentage we need to multiply the output of eta by 100.\nEta squared tells us the proportion of the total variance that is explained by a variable (you can also think of it as an effect size). An eta squared value of 1 indicates all the variance of a sample is explain by some variable and 0 means the variable is not responsible for any of the observed variance. We can multiply the eta-squared score by 100 to get a value for the percentage of variance explained.\nThe percentage of variance explained is a useful figure. For example, it has been reported that schools only account for 14% of the variance in progress 8 scores, whilst family explains 43% (Wilkinson, Bryson, and Stokes (2018)).\n\nlibrary(lsr)\neta <- as.data.frame(etaSquared(resaov))\neta <- eta*100\neta\n\n         eta.sq eta.sq.part\nAge    5.028982    17.26414\nsocio 59.694279    71.23853\n\n\nThe important column here is the eta.sq column - it tells us that age only explains 5% of the variance in test scores, but socioeconomic class, explains 60%. (The second column contains information about partial eta-squared, which we won’t go into, but are used when the results of each measure are not independent i.e. one result influences another).\n\n\n\n\n\n\nNote\n\n\n\nAs a rule of thumb, a percentage variance explained of 1% is considered small, 6% medium and 14% and more large\n\n\nWe can now apply anova to the PISA_2018. Let us focus on science scores (PV1SCIE).\nFirst, load the PISA data and create a data.frame containing the UK results for the vectors of science scores (PV1SCIE), parental wealth (WEALTH), gender (ST004D01T) and age (AGE).\n\nPISAUK <- PISA_2018 %>%\n select(CNT, PV1SCIE, ST004D01T, WEALTH, AGE)%>%\n filter(CNT==\"United Kingdom\")\n\n\n\n\n\n\n\nNote\n\n\n\nTwo assumptions of anova tests are a) the normality of the groups and b) that the groups have equal variance. We can do those checks using the quantile-quantile plot of normality we have seen earlier, and the var function to find the variance.\n\nPISAUKmale   <- PISAUK %>% filter(ST004D01T==\"Male\")\nPISAUKFemale <- PISAUK %>% filter(ST004D01T==\"Female\")\n\nggqqplot(PISAUKmale$PV1SCIE)\n\n\n\nggqqplot(PISAUKFemale$PV1SCIE)\n\n\n\nvar=var(PISAUKmale$PV1SCIE)/var(PISAUKFemale$PV1SCIE)\nvar\n\n[1] 1.176446\n\n\nBoth plots come out as straight lines indicating normality. The ratio of variance is 1.2, close enough to equal variance to suggest the conditions for anova tests are met. The rule of thumb for equal variances is taken as anything less than 3:1.\n\n\nCurrently, the wealth scores are a numeric measure of family wealth, normalised around 0 (being the mean) and in the range of -0.935 to 1.20. To make the calculation simpler, we will categorise the scores into two groups, high wealth (over 0) and low wealth (0 or under). We will drop any NA values.\n\nPISAUK <- drop_na(PISAUK)\n\nPISAUK <- PISAUK %>% \n  mutate(WEALTH = ifelse(WEALTH > 0, \"High\", \"Low\"))\n\n# PISAUK$WEALTH<-replace(PISAUK$WEALTH,PISAUK$WEALTH>0, \"High\")\n# PISAUK$WEALTH<-replace(PISAUK$WEALTH,PISAUK$WEALTH<=0, \"Low\")\n\nTo visualise the difference in means, here are graphs of the science scores for the two wealth groups:\n\nggplot(PISAUK,\n       aes(x=PV1SCIE, fill=WEALTH))+\n  geom_density(alpha=0.5)\n\n\n\n\nVisually, there appear to be some differences, the high wealth group seems to have a higher mean, but to determine if they are statistically significant, we need to run an anova test.\nBelow is code to run the anova, just like in the example with test scores. We use aov and specify the data set as PISAUK. Then we state we wish to compare the variance in science scores PV1SCIE, against gender (ST004D01T), wealth and age: PV1SCIE ~ ST004D01T + WEALTH + AGE.\nWe then summarise and print the table:\n\nresaov <- aov(PV1SCIE ~ ST004D01T + WEALTH + AGE, data=PISAUK)\nsumresaov<-summary(resaov)\nsumresaov\n\n               Df    Sum Sq Mean Sq F value   Pr(>F)    \nST004D01T       1      6200    6200   0.695    0.405    \nWEALTH          1   1038412 1038412 116.371  < 2e-16 ***\nAGE            13    610655   46973   5.264 1.66e-09 ***\nResiduals   13351 119134784    8923                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNote that the p value for gender (ST004D01T) is 0.405, which is over 0.05, so there are no significant differences by gender. By contrast, for WEALTH and AGE, the p values are below the 0.05 cut off, so the two wealth groups and 14 different age groups are statistically significantly different.\nNote that, in the anova table, the df (degrees of freedom column), tells you how many groups there are. df is the number of groups minus one. So, for WEALTH groups, df is 1, because there are two groups (high and low, which we created) and so df=2-1=1. For age, which gives participants’ birth month, there are df=13-1=12 groups, i.e. the number of months of the year.\nFinally, we are interested in finding how much of the variance is explained by age and wealth, so we can run an eta-squared test, and multiply by 100 to get percentage variance explained\n\neta<-etaSquared(resaov)\neta<-eta*100\neta\n\n              eta.sq eta.sq.part\nST004D01T 0.01017853  0.01031889\nWEALTH    0.85001629  0.85446249\nAGE       0.50555112  0.50996135\n\n\nWEALTH and AGE only explain a small amount of the variation, 0.85% and 0.5% respectively."
  },
  {
    "objectID": "index.html#pre-seminar-tasks---please-complete-the-two-tasks-below-before-the-seminar",
    "href": "index.html#pre-seminar-tasks---please-complete-the-two-tasks-below-before-the-seminar",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.3 Pre-seminar tasks - please complete the two tasks below before the seminar",
    "text": "8.3 Pre-seminar tasks - please complete the two tasks below before the seminar"
  },
  {
    "objectID": "index.html#pre-seminar-task-1",
    "href": "index.html#pre-seminar-task-1",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.4 Pre-seminar task 1",
    "text": "8.4 Pre-seminar task 1\n\nDetermine if there is significant variation in UK PISA science scores by gender, and having a quiet place to study (ST011Q03TA). Then find the proportion of variance explained by each variable.\n\n\nanswer# Create a dataframe of UK results with science scores, gender and\n# the quiet place to study item\nPISAUK <- PISA_2018 %>%\n  select(CNT, PV1SCIE, ST004D01T, ST011Q03TA)%>%\n  filter(CNT==\"United Kingdom\")%>%\n  drop_na()\n# Perform the anova using the dataframe PISAUK\n# finding the variance in PV1SCIE by gender (ST004D01T) and\n# having a quiet place to study (ST011Q03TA)\nresaov<-aov(data=PISAUK, PV1SCIE ~ ST004D01T + ST011Q03TA)\n# summarise the results and print\nsumresaov<-summary(resaov)\nsumresaov\n\n               Df    Sum Sq Mean Sq F value   Pr(>F)    \nST004D01T       1      1007    1007   0.113    0.737    \nST011Q03TA      1    530338  530338  59.502 1.31e-14 ***\nResiduals   13201 117659885    8913                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanswer# No significant difference by gender (Pr(>)=0.737)\n# Significant differences by quiet space (Pr(>)=1.31e-14)\n#\n# To perform the eta-sqaured caluclation - i.e. how much\n# variation is explained by each varibale, install the\n# lsr package\n\n# Carry out the eta-squared calculation and times by 100 to get %s\neta=etaSquared(resaov)\neta=eta*100\neta\n\n                eta.sq eta.sq.part\nST004D01T  0.002130537 0.002140113\nST011Q03TA 0.448711871 0.448715693\n\nanswer# Gender is not significant, so won't report the eta-squared value\n# Quiet space explains 0.45% of the variance"
  },
  {
    "objectID": "index.html#pre-seminar-task-2",
    "href": "index.html#pre-seminar-task-2",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.5 Pre-seminar task 2",
    "text": "8.5 Pre-seminar task 2\n\nDetermine if there is significant variation in UK PISA mathematics scores by gender, and having an internet link in the home (ST011Q06TA). Then find the proportion of variance explained by each variable.\n\n\nanswer# Create a dataframe of mathematics scores, gender and internet connection\n# for UK students and remove NAs\nPISAUK <- PISA_2018 %>%\n  select(CNT, PV1MATH, ST004D01T, ST011Q06TA)%>%\n  filter(CNT==\"United Kingdom\")%>%\n  drop_na()\n# Perform the anova on the PISAU data, find variance in PV1MATH ~ (by)\n# gender (ST004D01T) and having an internet connection (ST011Q06TA)\nresaov<-aov(data=PISAUK, PV1MATH ~ ST004D01T + ST011Q06TA)\nsumresaov<-summary(resaov)\nsumresaov\n\n               Df    Sum Sq Mean Sq F value   Pr(>F)    \nST004D01T       1    317167  317167   39.84 2.84e-10 ***\nST011Q06TA      1   1635601 1635601  205.45  < 2e-16 ***\nResiduals   13259 105553812    7961                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanswer# There are significant differences by gender (Pr(>F)=2.84e-10) and\n# by having an internet connection (Pr(>F)=< 2e-16)\n# Use eta squared to find the % of variance explained by each variable\neta=etaSquared(resaov)\neta=eta*100 # Times by 100 to get percentages\neta\n\n             eta.sq eta.sq.part\nST004D01T  0.321931   0.3268152\nST011Q06TA 1.521397   1.5258983\n\nanswer# Gender explains 0.32% of the variance\n# Having an internet connection 1.5%"
  },
  {
    "objectID": "index.html#seminar-tasks---please-leave-these-to-complete-in-the-seminar",
    "href": "index.html#seminar-tasks---please-leave-these-to-complete-in-the-seminar",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.6 Seminar Tasks - please leave these to complete in the seminar",
    "text": "8.6 Seminar Tasks - please leave these to complete in the seminar"
  },
  {
    "objectID": "index.html#task-1-2",
    "href": "index.html#task-1-2",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.7 Task 1",
    "text": "8.7 Task 1\nDiscussion points:\nRecall the presentation slide on validity. As you are already aware, it is important that we keep in mind what the data we are analysing are based on, so:\n\nWhat threats are there to the validity of PISA for its intended interpretations (e.g. scientific literacy) and uses (i.e. informing education policy)?\nTo what extent does the content of the PISA items used in the recommended reading reflect what you consider to be “inquiry-based teaching” and “teacher-directed teaching”?\n\nInquiry based science teaching (IBTEACH) items:\n• Students spend time in the laboratory doing practical experiments\n• Students do experiments by following the instructions of the teacher\n• Students are asked to draw conclusions from an experiment they have conducted\n• Students are required to design how a school science question could be investigated in the laboratory\n• Students are allowed to design their own experiments\n• Students are given the chance to choose their own investigations\n• Students are asked to do an investigation to test out their own ideas\nTeacher-directed science teaching (TDTEACH) items\n• The teacher explains scientific ideas\n• A whole class discussion takes place with the teacher.\n• The teacher discusses our questions.\n• The teacher demonstrates an idea.\nc) What are the assumptions of a one-way anova test? How might it be misapplied to some variables in the PISA dataset?"
  },
  {
    "objectID": "index.html#task-2-2",
    "href": "index.html#task-2-2",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.8 Task 2",
    "text": "8.8 Task 2\n\nDetermine if there is significant variation in UK PISA mathematics scores by gender, wealth, and having a computer in the home (ST011Q04TA). Then find the proportion of variance explained by each variable.\nHint, wealth is a normalised score which you can sort into two categories, high and low. We can consider a score above 0, high wealth, and scores below 0, low wealth.\nTo do this you can use the mutate (see Section 2.10.5) function to change a column, combined with the ifelse function (see Section 2.11.1).\nThis line mutates the WEALTH column, writing “High” when the value is over 0 and, if else, “Low”\nmutate(WEALTH = ifelse(WEALTH > 0, \"High\", \"Low\"))\n\n\nanswerPISAUK <- PISA_2018 %>%\n  select(CNT, PV1MATH, ST004D01T, WEALTH, ST011Q04TA)%>%\n  filter(CNT==\"United Kingdom\")%>%\n  drop_na()\n\nPISAUK <- PISAUK %>% \n  mutate(WEALTH = ifelse(WEALTH > 0, \"High\", \"Low\"))\n\n# PISAUK$WEALTH<-replace(PISAUK$WEALTH,PISAUK$WEALTH>0, \"High\")\n# PISAUK$WEALTH<-replace(PISAUK$WEALTH,PISAUK$WEALTH<=0, \"Low\")\n\nresaov<-aov(PV1MATH ~ ST004D01T + WEALTH + ST011Q04TA, data=PISAUK)\nsumresaov<-summary(resaov)\nsumresaov\n\n               Df    Sum Sq Mean Sq F value   Pr(>F)    \nST004D01T       1    324200  324200   41.54 1.19e-10 ***\nWEALTH          1   1318840 1318840  169.00  < 2e-16 ***\nST011Q04TA      1   2176070 2176070  278.84  < 2e-16 ***\nResiduals   13244 103356592    7804                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanswereta=etaSquared(resaov)\neta=eta*100\neta\n\n              eta.sq eta.sq.part\nST004D01T  0.2978265   0.3078806\nWEALTH     0.5907302   0.6088288\nST011Q04TA 2.0303766   2.0619876"
  },
  {
    "objectID": "index.html#task-3-2",
    "href": "index.html#task-3-2",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.9 Task 3",
    "text": "8.9 Task 3\n\nTry the same task again, determine if there is significant variation in UK mathematics scores by gender, Wealth, and having a computer in the home. This time, divide the wealth variable into four levels.\n\n\nanswerPISAUK <- PISA_2018 %>%\n  select(CNT, PV1MATH, ST004D01T, WEALTH, ST011Q04TA)%>%\n  filter(CNT==\"United Kingdom\")%>%\n  drop_na()\n\nPISAUK <- PISAUK %>% \n  mutate(WEALTH = ifelse(WEALTH >= 0.5, \"High\",\n                         ifelse(WEALTH > 0, \"Medium High\",\n                                ifelse(WEALTH <= -0.5, \"Low\",\n                                       ifelse(WEALTH <= 0,\"Medium Low\", \"ERROR\")))))\n\n# PISAUK$WEALTH<-replace(PISAUK$WEALTH,PISAUK$WEALTH>=0.5, \"High\")\n# PISAUK$WEALTH<-replace(PISAUK$WEALTH, PISAUK$WEALTH>0, \"Medium High\")\n# PISAUK$WEALTH<-replace(PISAUK$WEALTH,PISAUK$WEALTH<=-0.5, \"Low\")\n# PISAUK$WEALTH<-replace(PISAUK$WEALTH,PISAUK$WEALTH<=0,\"Medium Low\")\n\nresaov<-aov(PV1MATH ~ ST004D01T + WEALTH + ST011Q04TA, data=PISAUK)\nsumresaov<-summary(resaov)\nsumresaov\n\n               Df    Sum Sq Mean Sq F value   Pr(>F)    \nST004D01T       1    324200  324200   41.65 1.13e-10 ***\nWEALTH          3   1830726  610242   78.40  < 2e-16 ***\nST011Q04TA      1   1946438 1946438  250.06  < 2e-16 ***\nResiduals   13242 103074339    7784                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanswereta=etaSquared(resaov)\neta=eta*100\neta\n\n              eta.sq eta.sq.part\nST004D01T  0.2874810   0.2980291\nWEALTH     0.8540855   0.8802526\nST011Q04TA 1.8161186   1.8533837"
  },
  {
    "objectID": "index.html#tukeys-hsd",
    "href": "index.html#tukeys-hsd",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.10 Tukey’s HSD",
    "text": "8.10 Tukey’s HSD\nWhen an anova test reports that are some statistically significant differences between groups, it does not imply there are statistically significant differences between all subgroups. For example, if the anova reports statistically significant differences by age, statistically significant differences might exist between 11, 12 and 13-year old students, but not between 13 and 14-year olds.\nWe can use an additional anova test, Tukey’s Honest Significant Difference test (or Tukey’s HSD for short), to find out which pairs of subgroups have statistically significant differences in means.\nConsider the question: Are there statistically significant differences in the variance of science scores of the UK, US, France and Germany? To determine if such differences exist, we create a new subset for those countries’ science scores, and then run an anova test by country, reporting the eta squared value.\n\nPISAMULTI <- PISA_2018 %>%\n  select(CNT, PV1SCIE)%>%\n  filter(CNT==\"United Kingdom\" | CNT==\"United States\" | CNT==\"Germany\" | CNT==\"France\")\n  # filter(CNT %in% c(\"United Kingdom\", \"United States\", \"Germany\", \"France\"))\n\nggplot(PISAMULTI,\n       aes(x=PV1SCIE, fill=CNT))+\n  geom_density(alpha=0.5)\n\n\n\nresaov<-aov(PV1SCIE ~ CNT, data=PISAMULTI)\nsumresaov<-summary(resaov)\nsumresaov\n\n               Df    Sum Sq Mean Sq F value Pr(>F)    \nCNT             3   1071227  357076   37.36 <2e-16 ***\nResiduals   30411 290638789    9557                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\neta<-as.data.frame(etaSquared(resaov))\neta<-eta*100\neta\n\n       eta.sq eta.sq.part\nCNT 0.3672231   0.3672231\n\n\nThe anova results tell us there are significant differences between the countries, which account for 0.4% of variance in scores. We can then run a Tukey HSD test to determine which countries have significant differences between mean scores.\n\nTukeyHSD(resaov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1SCIE ~ CNT, data = PISAMULTI)\n\n$CNT\n                                   diff        lwr        upr     p adj\nFrance-Germany               -18.844787 -23.489214 -14.200359 0.0000000\nUnited Kingdom-Germany        -9.056104 -13.073086  -5.039123 0.0000000\nUnited States-Germany         -7.024614 -11.985354  -2.063874 0.0015665\nUnited Kingdom-France          9.788682   5.972393  13.604971 0.0000000\nUnited States-France          11.820172   7.020499  16.619845 0.0000000\nUnited States-United Kingdom   2.031490  -2.164019   6.226999 0.5987930\n\n\nFrom that we get a table with p values (p adj) for different pairs of countries. Note that these are below 0.005 for all pairs of countries, except the US and the UK. So we can conclude there are significant differences in science scores between all countries except the UK and the US."
  },
  {
    "objectID": "index.html#task-4-2",
    "href": "index.html#task-4-2",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.11 Task 4",
    "text": "8.11 Task 4\n\nFor the China, Thailand, Japan and Korea, determine if there are statistically significant differences in variation in mathematics scores.\n\n\nanswerPISAMULTI<-PISA_2018 %>%\n  select(CNT, PV1SCIE)%>%\n  filter(CNT==\"B-S-J-Z (China)\" | CNT==\"Thailand\" | CNT==\"Japan\" | CNT==\"Korea\")\n  # filter(CNT %in% c(\"B-S-J-Z (China)\", \"Thailand\", \"Japan\", \"Korea\"))\n\nggplot(PISAMULTI,\n       aes(x=PV1SCIE, fill=CNT))+\n  geom_density(alpha=0.5)\n\n\n\nanswerresaov<-aov(PV1SCIE ~ CNT, data=PISAMULTI)\nsumresaov<-summary(resaov)\nsumresaov\n\n               Df    Sum Sq  Mean Sq F value Pr(>F)    \nCNT             3 114287180 38095727    4596 <2e-16 ***\nResiduals   33446 277230531     8289                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanswereta<-as.data.frame(etaSquared(resaov))\neta<-eta*100\neta\n\n      eta.sq eta.sq.part\nCNT 29.19081    29.19081\n\nanswerTukeyHSD(resaov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1SCIE ~ CNT, data = PISAMULTI)\n\n$CNT\n                                diff        lwr         upr p adj\nKorea-Japan                -8.504429  -12.64948   -4.359374 8e-07\nB-S-J-Z (China)-Japan      64.662840   60.98971   68.335975 0e+00\nThailand-Japan            -85.694331  -89.60481  -81.783850 0e+00\nB-S-J-Z (China)-Korea      73.167270   69.59468   76.739859 0e+00\nThailand-Korea            -77.189902  -81.00610  -73.373707 0e+00\nThailand-B-S-J-Z (China) -150.357171 -153.65471 -147.059631 0e+00"
  },
  {
    "objectID": "index.html#task-5-1",
    "href": "index.html#task-5-1",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.12 Task 5",
    "text": "8.12 Task 5\nFinally, a significant open question is the extent to which discovery learning impacts students’ results. The PISA 2015 data contains a couple of variables related to whether students report their teachers use direct instruction (teacher-led activities) or not, and whether they experience inquiry based teaching (student-led activities), or not. In 2015, the two composite variables related to students’ reports of their teachers’ teaching styles in science are:\n\n\nIBTEACH quantifies teachers’ use of inquiry based teaching. It is based on responses to nine questions: frequency with which they experienced specific activities:\n\nstudents are given opportunities to explain their ideas;\nstudents spend time in the laboratory doing practical experiments;\nstudents are required to argue about science questions;\nstudents are asked to draw conclusions from an experiment they have conducted;\nthe teacher explains how a science idea can be applied to different phenomena;\nstudents are allowed to design their own experiments;\nthere is a class debate about investigations;\nthe teacher clearly explains the relevance of science concepts; and,\nstudents are asked to do an investigation to test ideas\n\n\n\nTDTEACH scores teachers use of teacher-directed approaches. It is based on 4 items on the survey asking the frequency of:\n\nThe teacher explains scientific ideas;\nA whole class discussion takes place with the teacher;\nThe teacher discusses our questions;\nand the teacher demonstrates an idea.\n\n\n\nFirst, download the PISA 2015 dataset: PISA_2015 and load the data using this code:\n\nlibrary(arrow)\nlibrary(tidyverse)\n\n#PISA_2015 <- read_parquet(\"<folder>PISA_2015_student_subset.parquet\")\n\n\nTask: For science, determine the amount of variation in scores explained by IBTEACH and TDTEACH for the whole data set. What is true in the context of students in the UK, China and the US? Are the patterns different for mathematics?"
  },
  {
    "objectID": "index.html#repeating-research",
    "href": "index.html#repeating-research",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n8.13 Repeating research",
    "text": "8.13 Repeating research\nThe direct instruction vs inquiry learning debate is a current one with impact upon national policy and classroom practice (Gove 2013). A piece of research by Mourshed, Krawitz, and Dorn (2017) suggested that there was a “sweet spot” which in practice is:\n\nteacher-directed instruction in most to all classes and inquiry-based learning in some\n\n\n\nthe sweet spot for teacher-directed instruction and inquiry-based learning (Mourshed, Krawitz, and Dorn 2017)\n\n\nUnfortunately Mourshed, Krawitz, and Dorn (2017) never published the code behind their study and it’s not actually clear how we can recreate their findings. Others have tried, but failed (Bokhove 2021). Now it’s our turn!\n\n8.13.1 Exploring the data\nFirst, let’s make sure that we have a dataset without any missing values for IBTEACH and TDTEACH\n\n# For the whole dataset\n# Remove any NAs\nPISA_2015<-PISA_2015 %>%\n  drop_na(IBTEACH) %>%\n  drop_na(TDTEACH)\n\n\n8.13.2 A simple attempt to recreate the sweet spot analysis\nTo recreate the sweet spot analysis: a) divide IBTEACH and TDTEACH intro three categories, using ifelse, as we have done above. b) Use group_by with IBTEACH and TDTEACH and summarise the mean to create a summary table c) use ggplot, with geom_point, and change the point size by the mean to create a similar plot to the McKinsey graph.\n\nanswer# Create a data set to plot including IBTEACH, TDTEACH and PV1SCIE\n\nPISAIBTD<-PISA_2015%>%\n  select(IBTEACH, TDTEACH, PV1SCIE)%>%\n  na.omit()\n# Create data to plot\nPlotdata<-PISAIBTD%>%\n# Categorise IBTEACH  into three levels\n  mutate(IBTEACH=ifelse(IBTEACH >=1, \"High\", \n                        ifelse(IBTEACH >-1.2, \"Medium\",\"Low\")))%>%\n  # Categorise TDTEACH  into three levels\n  # The function range(PISAIBTD$TDTEACH) and range(PISAIBTD$IBTEACH)\n  # was used to determine the range of the two variables\n  # The range was roughly divided into three parts\n  mutate(TDTEACH=ifelse(TDTEACH >=0.5, \"High\", \n                        ifelse(TDTEACH >-1, \"Medium\",\"Low\")))%>%\n  # Group by the IBTEACH and TDTEACH to create a table, and find the mean\n  # science scores\n  group_by(IBTEACH, TDTEACH)%>%\n  summarise(Mean_Sci_Score=mean(PV1SCIE))\n# Set an order for the levels of IBTEACH and TDTeach\n# so the plot comes out in right order\nPlotdata$IBTEACH=factor(Plotdata$IBTEACH, levels=c(\"Low\",\"Medium\",\"High\"))\nPlotdata$TDTEACH=factor(Plotdata$TDTEACH, levels=c(\"Low\",\"Medium\",\"High\"))\nggplot(Plotdata,\n       aes(x=IBTEACH, y=TDTEACH, size=Mean_Sci_Score))+\n  geom_point(colour=\"red\")+\n  labs(x=\"Inquiry Based Teaching\", y=\"Teacher directed Teaching\")\n\n\n\nanswer# Recreate the categorised dataset  \nAnovdata<-PISAIBTD%>%\n  mutate(IBTEACH=ifelse(IBTEACH >=1, \"High\", \n                        ifelse(IBTEACH >-1.2, \"Medium\",\"Low\")))%>%\n  mutate(TDTEACH=ifelse(TDTEACH >=0.5, \"High\", \n                        ifelse(TDTEACH >-1, \"Medium\",\"Low\")))\n# Perform the anova, Tukey HSD and eta-squared test.\nresaov<-aov(data=Anovdata, PV1SCIE~ TDTEACH + IBTEACH)\nsummary(resaov)\n\n                Df    Sum Sq  Mean Sq F value Pr(>F)    \nTDTEACH          2 5.077e+07 25385862    2601 <2e-16 ***\nIBTEACH          2 1.426e+08 71323568    7309 <2e-16 ***\nResiduals   429756 4.194e+09     9759                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanswerTukeyHSD(resaov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1SCIE ~ TDTEACH + IBTEACH, data = Anovdata)\n\n$TDTEACH\n                 diff       lwr       upr p adj\nLow-High    -36.29973 -37.52730 -35.07216     0\nMedium-High -17.33526 -18.15208 -16.51844     0\nMedium-Low   18.96448  17.84738  20.08157     0\n\n$IBTEACH\n                 diff       lwr       upr p adj\nLow-High    58.200772 56.554384 59.847159 0e+00\nMedium-High 55.051737 53.951855 56.151619 0e+00\nMedium-Low  -3.149035 -4.494467 -1.803603 1e-07\n\nanswereta<-etaSquared(resaov)\neta<-100*eta\n\n\n\n8.13.3 A fuller attempt - Step 1, Wrangling the data\nNow we have a statistical grasp of the data we can try to recreate the study. First, we need to categorise IBTEACH and TDTEACH into three levels, high, medium and low, we will use these instead of the “None to few lessons”, “Some to many lessons” and “Many to all lessons”. We can use the quantile function to do this. The function tells us the value of IBTEACH and TDTEACH which contain 1/3 and 2/3 of this responses. We can use these values to divide the data into 3 parts with equal numbers of students in each by using the mutate function with ifelse (as above) to replace the values with the categories, High, Medium and Low.\n\n# split into three 'quantiles'. The function returns the value of IBTEACH and TD teach which account for 33% and 66% of students\n\nquant_IBTEACH <- quantile(PISA_2015$IBTEACH, prob=c(.33,.66), na.rm=TRUE)\nquant_TDTEACH <- quantile(PISA_2015$TDTEACH, prob=c(.33,.66), na.rm=TRUE)\n\n# Mutate the IBTEACH and TDTEACH columns, replacing values with 'High', 'Low' and 'Medium' based on the quantile calculation values\n\nPISA_2015IBTD <- PISA_2015 %>% \n  select(PV1SCIE, IBTEACH, TDTEACH, ST004D01T, OECD, CNT) %>%\n  mutate(IBTEACH = ifelse(IBTEACH < quant_IBTEACH[\"33%\"], \"Low\",\n                       ifelse(IBTEACH >= quant_IBTEACH[\"33%\"] & \n                                IBTEACH < quant_IBTEACH[\"66%\"], \n                              \"Medium\", \"High\"))) %>%\n   mutate(TDTEACH = ifelse(TDTEACH < quant_TDTEACH[\"33%\"], \"Low\",\n                       ifelse(TDTEACH >=quant_TDTEACH[\"33%\"] & \n                                TDTEACH < quant_TDTEACH[\"66%\"],\n                              \"Medium\", \"High\"))) %>%\n  filter(!is.na(IBTEACH), !is.na(TDTEACH)) %>%\n  rename(gender = ST004D01T)\n\n# Plot graphs of variation in science score by level of inquiry based teaching\nggplot(PISA_2015IBTD,\n       aes(x=PV1SCIE, fill=IBTEACH))+\n  geom_density(alpha=0.5)\n\n\n\n\nThis graph shows the peak of High IBTEACH (in red) having a smaller PV1SCIE grade than the other categories. This suggests we should avoid high levels of IBTEACH\n\n# Plot graphs of variation in science score by level of teacher directed  teaching\nggplot(PISA_2015IBTD,\n       aes(x=PV1SCIE, fill=TDTEACH))+\n  geom_density(alpha=0.5)\n\n\n\n\nThis graph shows the peak of Low TDTEACH (in green) having a smaller PV1SCIE grade than the other categories. This suggests we should avoid low levels of TDTEACH\n\n\n\n\n8.13.4 Searching for the sweet spot(s)\nThe “sweet spot” chart by Mourshed, Krawitz, and Dorn (2017) looks at the average point increase in PISA scores given different teaching methods. We need to calculate this average difference.\nHere the mean score for PV1SCIE are calculated and then compared to the means for the groups by the levels of TDTEACH and IBTEACH.\n\n# Using ggplot\n# optional gender filter\nplot_data <- PISA_2015IBTD %>% \n  mutate(mean_sci  = mean(PV1SCIE),\n         median_sci= median(PV1SCIE)) %>%\n  group_by(IBTEACH, TDTEACH, mean_sci, median_sci) %>%\n  summarise(group_mean_sci=mean(PV1SCIE),\n            group_median_sci=median(PV1SCIE),\n            mean_diff = unique(group_mean_sci - mean_sci),\n            median_diff = unique(group_median_sci - median_sci),\n            mean_col = mean_diff > 0,\n            median_col = median_diff > 0,\n            n=n()) %>% \n  ungroup() %>%\n  mutate(IBTEACH = factor(IBTEACH, levels=c(\"Low\", \"Medium\", \"High\")),\n         TDTEACH = factor(TDTEACH, levels=c(\"Low\", \"Medium\", \"High\")))\n\n\nline 4 and 5 creates an overall mean and median score for PV1SCIE\n\nline 6 we want to find out the difference in average score for each combination of IBTEACH and TDTEACH, e.g. IBTEACH-Low and TDTEACH-Low, IBTEACH-Low and TDTEACH-Medium, etc. So we need to group these, and group the mean_sci, median_sci values so we don’t lose them when summarising.\nline 7 and 8 - creates a mean and median PV1SCIE score for each grouping\nline 9 and 10 - calculates the differences from the overall mean and median PV1SCIE score for each grouping\nline 11 and 12 - calculates whether this difference is positive (or negative) and stores this as True or False\n\nline 13 stores the number of students in each grouping\nline 15 and 16 uses factor to set the order of IBTEACH and TDTEACH, we want them running \"Low\", \"Medium\", \"High\" on our graph\n\nNow we can try and build our graph using geom_point\n\n\n\n\n plt_sweetspot <- ggplot(plot_data %>% \n         select(IBTEACH, TDTEACH, mean_diff, mean_col) %>%\n         mutate(mean_diff = signif(mean_diff,2),\n                mean_diff_txt = ifelse(sign(mean_diff)==1, \n                                   paste0(\"+\",mean_diff),\n                                   paste0(mean_diff))), \n       aes(x =IBTEACH, y = TDTEACH)) +\n  geom_point(aes(size=abs(mean_diff), colour=mean_col)) +\n  scale_size(range = c(0, 40)) +\n  geom_text(aes(label=mean_diff_txt, \n                colour=ifelse(abs(mean_diff) > 8, \"big\",\n                              ifelse(mean_diff > 0, \"positive\", \"negative\")))) +\n  scale_color_manual(values = c(\"big\" = \"white\", \"positive\" = \"#6592a5\", \n                                \"negative\" = \"#c37d7f\",\n                                \"TRUE\" = \"#6592a5\", \"FALSE\"= \"#c37d7f\")) +\n  theme(panel.background=element_rect(fill = \"#dce1e5\"),\n        legend.position = \"none\") +\n  ggtitle(\"Point change in PISA science scores relative to mean\") + \n  xlab(\"Inquiry-based science teaching\") +\n  ylab(\"Teacher-directed science instruction\")\n\n\nline 1 to 6 - we pass the plot_data dataframe specified above to ggplot, we also make a few changes to this dataframe, using signif to reduce the number of signficant digits in mean_diff and we create mean_diff_txt which is mean_diff but with the sign +/- on the front.\nline 7 - we pass the IBTEACH and TDTEACH to x and y, this means we’ll plot a point for each combination, Low/Low, Low/Medium, Low/High, etc.\nline 8 - geom_point takes the x and y from line 7 and adjusts the size of the points based on the abs (the number without a sign) value of mean_diff, and set the colour mean_col, whether the point is positive or negative.\nline 9 - this increases the overall size of the points to range from 0, the smallest, to 40 the biggest\nline 10 to 12 - add a text label to each point with the value of the difference and added sign mean_diff_txt. Change the colour of the text, if abs(mean_diff) > 8 then the text will go on top of the points and will need to be white, otherwise the colour of the text should be a colour to reflect positive or negative.\nline 13 to 15 - manually set the colours of the text and the points.\nline 16 to 17 - change the background colour, and get rid of the legend\nline 18 to 20 - add a title and new labels\n\n\n\n\n\n\nWe can see that our graph is very different to theirs?! We have two “sweet spots”, Low Inquiry and Medium Directed at +29 and Medium inquiry and High Directed at +25. Going back to our exploration above, this matches what we saw in the density charts (Section 8.13.3), where High Inquiry and Low Directed gave the worst results.\nBut why is ours different? It’s very hard to tell and without seeing the original code or a well written methodology; we might never know. Is our model better than theirs? Maybe! It’s just hard to tell. People have taken the McKinsey report very seriously and it does seem unlikely that national centres of education will be reading this subsection of session 7 of an MA STEM Quantitative methods course at KCL to shape their policy making decisions. Maybe you could explore this further in your dissertation and try to come up with a stronger conclusion.\n\nHow does the sweet spot change for the UK? Repeat the analysis above only looking at student results for the “United Kingdom”\n\nCodePISA_2015_UK <- PISA_2015 %>% filter(CNT == \"United Kingdom\")\n\nquant_IBTEACH <- quantile(PISA_2015_UK$IBTEACH, prob=c(.33,.66), na.rm = TRUE)\nquant_TDTEACH <- quantile(PISA_2015_UK$TDTEACH, prob=c(.33,.66), na.rm = TRUE)\n\n# Mutate the IBTEACH and TDTEACH columns, replacing values with 'High', 'Low' and 'Medium' based on the quantile calculation values\n\nPISA_2015IBTD <- PISA_2015_UK %>% \n  select(PV1SCIE, IBTEACH, TDTEACH, ST004D01T, OECD, CNT) %>%\n  mutate(IBTEACH = ifelse(IBTEACH < quant_IBTEACH[\"33%\"], \"Low\",\n                       ifelse(IBTEACH >= quant_IBTEACH[\"33%\"] & \n                                IBTEACH < quant_IBTEACH[\"66%\"], \n                              \"Medium\", \"High\"))) %>%\n   mutate(TDTEACH = ifelse(TDTEACH < quant_TDTEACH[\"33%\"], \"Low\",\n                       ifelse(TDTEACH >=quant_TDTEACH[\"33%\"] & \n                                TDTEACH < quant_TDTEACH[\"66%\"],\n                              \"Medium\", \"High\"))) %>%\n  filter(!is.na(IBTEACH), !is.na(TDTEACH)) %>%\n  rename(gender = ST004D01T)\n\n# Plot graphs of variation in science score by level of inquiry based teaching\nggplot(PISA_2015IBTD,\n       aes(x=PV1SCIE, fill=IBTEACH))+\n  geom_density(alpha=0.5)\n\nggplot(PISA_2015IBTD,\n       aes(x=PV1SCIE, fill=TDTEACH))+\n  geom_density(alpha=0.5)\n\n# optional gender filter\nplot_data <- PISA_2015IBTD %>% \n  mutate(mean_sci  = mean(PV1SCIE),\n         median_sci= median(PV1SCIE)) %>%\n  group_by(IBTEACH, TDTEACH, mean_sci, median_sci) %>%\n  summarise(group_mean_sci=mean(PV1SCIE),\n            group_median_sci=median(PV1SCIE),\n            mean_diff = unique(group_mean_sci - mean_sci),\n            median_diff = unique(group_median_sci - median_sci),\n            mean_col = mean_diff > 0,\n            median_col = median_diff > 0,\n            n=n()) %>% \n  ungroup() %>%\n  mutate(IBTEACH = factor(IBTEACH, levels=c(\"Low\", \"Medium\", \"High\")),\n         TDTEACH = factor(TDTEACH, levels=c(\"Low\", \"Medium\", \"High\")))\n\nplt_sweetspot <- ggplot(plot_data %>% \n         select(IBTEACH, TDTEACH, mean_diff, mean_col) %>%\n         mutate(mean_diff = signif(mean_diff,2),\n                mean_diff_txt = ifelse(sign(mean_diff)==1, \n                                   paste0(\"+\",mean_diff),\n                                   paste0(mean_diff))), \n       aes(x =IBTEACH, y = TDTEACH)) +\n  geom_point(aes(size=abs(mean_diff), colour=mean_col)) +\n  scale_size(range = c(0, 40)) +\n  geom_text(aes(label=mean_diff_txt, \n                colour=ifelse(abs(mean_diff) > 8, \"big\",\n                              ifelse(mean_diff > 0, \"positive\", \"negative\")))) +\n  scale_color_manual(values = c(\"big\" = \"white\", \"positive\" = \"#6592a5\", \n                                \"negative\" = \"#c37d7f\",\n                                \"TRUE\" = \"#6592a5\", \"FALSE\"= \"#c37d7f\")) +\n  theme(panel.background=element_rect(fill = \"#dce1e5\"),\n        legend.position = \"none\") +\n  ggtitle(\"Point change in PISA science scores relative to mean\") + \n  xlab(\"Inquiry-based science teaching\") +\n  ylab(\"Teacher-directed science instruction\")"
  },
  {
    "objectID": "index.html#self-study-tasks",
    "href": "index.html#self-study-tasks",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.1 Self study tasks",
    "text": "9.1 Self study tasks\nThe pages below set out a series of graded challenges that you can use to test your R and statistical skills. Sample code that solves each problem is included so you can compare your solution with ours. Don’t worry if you solve something in a different way, there will be multiple solutions to the same task. The tasks are all set on the PISA_2018 data set: PISA_2018\nTo load the data, use the code below:\n\ninstall.packages(\"arrow\") # if you haven't already\nlibrary(arrow)\nlibrary(tidyverse)\nPISA_2018 <- read_parquet(\"<location of the downloaded PISA_2018.parquet file>\")"
  },
  {
    "objectID": "index.html#task-1-practice-creating-a-summary-table-1",
    "href": "index.html#task-1-practice-creating-a-summary-table-1",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.2 Task 1 Practice creating a summary table #1",
    "text": "9.2 Task 1 Practice creating a summary table #1\n\nCreate a table that summarises the mean PISA science scores by country. You will need to use the group_by, summarise and mean functions.\n\n\nAnswerPISAsummary<-PISA_2018%>%  # Pipe the overall frame to a summary data.frame\n  select(CNT, PV1SCIE)%>%  # Select the two required columns\n  group_by(CNT) %>%        # Group the entries by country\n  summarise(meansci=mean(PV1SCIE)) # caluclate means for each country\nprint(PISAsummary)\n\n\nExtension, use the signif function to give the responses to three significant figures"
  },
  {
    "objectID": "index.html#task-2-practice-creating-a-summary-table-including-percentages-2",
    "href": "index.html#task-2-practice-creating-a-summary-table-including-percentages-2",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.3 Task 2 Practice creating a summary table (including percentages) #2",
    "text": "9.3 Task 2 Practice creating a summary table (including percentages) #2\n\nUse the table function to create a summary of numbers of types of school ISCEDO recorded in the data frame for the UK. Use the mutate function to turn these into percentages (you will need to calculate a total)\n\n\nAnswerUKPISA<-PISA_2018%>%\n  select(CNT,ISCEDO)%>%             # Select the country school type \n  filter(CNT==\"United Kingdom\")%>%  # filter for the UK\n  select(ISCEDO)                    # Just select the school type \n                                    # I.e. remove the country\n\nUKPISA<-table(UKPISA)               # Create a summary of counts\n                                    # To manipulate the table it is\nUKPISA<-as.data.frame(UKPISA)       # easier to convert it to a \n                                    # a data.frame\n\nUKPISA<-mutate(UKPISA, per=Freq/sum(Freq)*100)"
  },
  {
    "objectID": "index.html#task-3-practice-pivoting-a-table",
    "href": "index.html#task-3-practice-pivoting-a-table",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.4 Task 3 Practice pivoting a table",
    "text": "9.4 Task 3 Practice pivoting a table\n\nConvert a table of UK Science, Maths and Reading scores, extracted from the main data set, into the long format R prefers. In the long format, each score becomes a single so each student will have three entries.\n\n\nAnswer# Create a data frame in wide format, with three columns for each student's scores (math, reading and science)\nUKScores<-PISA_2018%>%\n  select(CNT,PV1MATH, PV1READ, PV1SCIE)%>%\n  filter(CNT==\"United Kingdom\")%>%\n  select(PV1MATH, PV1READ, PV1SCIE)\n# Use pivot longer to turn the three columns into one. First, pass pivotlonger the dataframe to be converted, then the three columns\n# to convert into one, the name of the new longer column and the\n# name of the new scores column\n\nUKScores<-pivot_longer(UKScores, cols=c('PV1MATH', 'PV1READ', 'PV1SCIE'),\n                       names_to = 'Subject', values_to = 'Score' )"
  },
  {
    "objectID": "index.html#task-4-graphing-practice-1-a-bar-chart",
    "href": "index.html#task-4-graphing-practice-1-a-bar-chart",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.5 Task 4 Graphing Practice #1 A Bar Chart",
    "text": "9.5 Task 4 Graphing Practice #1 A Bar Chart\n\nDraw a bar chart of the mean mathematics scores for Germany, the UK, the US and China\n\n\nAnswerPlotdata<-PISA_2018%>%\n  select(CNT, PV1MATH)%>%\n  filter(CNT==\"United Kingdom\"|CNT==\"United States\"|CNT==\"Germany\"|CNT==\"B-S-J-Z (China)\")%>%\n  group_by(CNT)%>%\n  summarise(mean=mean(PV1MATH))\n\nggplot(Plotdata,               # Pass the data to be plotted to ggplot\n       aes(x=CNT, y=mean))+    # set the x and y varibale\n  geom_col(fill=\"red\")         # plot a column graph and fill in red"
  },
  {
    "objectID": "index.html#task-5-graphing-practice-2-a-bar-chart-with-two-series",
    "href": "index.html#task-5-graphing-practice-2-a-bar-chart-with-two-series",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.6 Task 5 Graphing Practice #2 A Bar Chart with two series",
    "text": "9.6 Task 5 Graphing Practice #2 A Bar Chart with two series\n\n\nDraw a bar chart of the mean mathematics scores for Germany, the UK, the US and China for boys and girls\n\n\n\nAnswerPlotdata<-PISA_2018%>%\n  select(CNT, PV1MATH, ST004D01T)%>%\n  filter(CNT==\"United Kingdom\"|CNT==\"United States\"|CNT==\"Germany\"|CNT==\"B-S-J-Z (China)\")%>%\n  group_by(CNT, ST004D01T)%>%\n  summarise(mean=mean(PV1MATH))\n\nggplot(Plotdata,\n       aes(x=CNT, y=mean, fill=ST004D01T))+ # Setting the fill to the gender\n                                            # variable gives two series\n  geom_col(position = position_dodge())     # position_dodge here means the\n                                            # means the bars are plotted                                                # side by side"
  },
  {
    "objectID": "index.html#task-6-graphing-practice-3-a-scatter-plot",
    "href": "index.html#task-6-graphing-practice-3-a-scatter-plot",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.7 Task 6 Graphing Practice #3 A scatter plot",
    "text": "9.7 Task 6 Graphing Practice #3 A scatter plot\n\nPlot a graph of science scores against mathematics scores for students in the UK\n\n\nAnswerPlotdata<-PISA_2018%>%              # Create a new dataframe to be plotted\n  select(CNT, PV1MATH, PV1SCIE)%>%  # Choose the country, and scores vectors\n  filter(CNT==\"United Kingdom\")    # Filter for only Uk results\n\nggplot(Plotdata,                  # Pass the data to be plotted to ggplot\n       aes(x=PV1MATH, y=PV1SCIE))+ # Define the x and y varibale\n      geom_point(size=0.1, alpha=0.2, colour=\"red\")+ \n                                  # Use geom-point to create a scatter                                      # graph and set the size of the point \n                                    # alpha (i.e transparency)\n      labs(x=\"Math Score\", y=\"Science score\") # Add clearer labels"
  },
  {
    "objectID": "index.html#task-7-graphing-practice-4-a-scatter-plot-with-multiple-series",
    "href": "index.html#task-7-graphing-practice-4-a-scatter-plot-with-multiple-series",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.8 Task 7 Graphing Practice #4 A scatter plot with multiple series",
    "text": "9.8 Task 7 Graphing Practice #4 A scatter plot with multiple series\n\n\nPlot a graph of science scores against mathematics scores for students in the UK, with data split into two series for boys and girls\n\n\n\nAnswerPlotdata<-PISA_2018%>%              # Create a new dataframe to be plotted\n  select(CNT, PV1MATH, PV1SCIE, ST004D01T)%>%  \n  filter(CNT==\"United Kingdom\")    # Filter for only Uk results\n\nggplot(Plotdata,                  \n       aes(x=PV1MATH, y=PV1SCIE, colour=ST004D01T))+ \n      geom_point(size=0.1, alpha=0.2)+ \n                          # As above, but set colour by the gender varibale\n      labs(x=\"Math Score\", y=\"Science score\")"
  },
  {
    "objectID": "index.html#task-8-graphing-practice-4-a-scatter-plot-with-varying-size-points",
    "href": "index.html#task-8-graphing-practice-4-a-scatter-plot-with-varying-size-points",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.9 Task 8 Graphing Practice #4 A scatter plot with varying size points",
    "text": "9.9 Task 8 Graphing Practice #4 A scatter plot with varying size points\n\nPlot a graph of mean science scores against mean mathematics scores for all the countries in the data set. Vary the point size by the number of students per country.\n\n\nAnswerPlotdata<-PISA_2018%>%\n  select(CNT, PV1MATH, PV1SCIE) %>%\n  group_by(CNT) %>%\n  summarise(meansci=mean(PV1SCIE), meanmath=mean(PV1MATH), total=n())\n  # Summarise finds mean scores by countries and n() is used to sum\n  # the number of students in each country\nggplot(Plotdata,\n       aes(x=meansci, y=meanmath, size=total, colour=\"red\"))+\n  # The size aesthetic is set to the total entries value computed\n  # for the data set\n  geom_point()+\n  labs(x=\"Mean science score\", y=\"Mean math score\")"
  },
  {
    "objectID": "index.html#task-9-graphing-practice-5-a-mosaic-plot",
    "href": "index.html#task-9-graphing-practice-5-a-mosaic-plot",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.10 Task 9 Graphing Practice #5 A mosaic plot",
    "text": "9.10 Task 9 Graphing Practice #5 A mosaic plot\n\nPlot a mosaic plot of the number of students in general or vocational schools\n\n\nAnswerGenderschool<-PISA_2018%>%\n  select(ST004D01T,ISCEDO)%>%\n  filter(ST004D01T==\"Male\"|ST004D01T==\"Female\")%>%\n  filter(ISCEDO==\"General\"|ISCEDO==\"Vocational\")%>%\n  na.omit()\n\ninstall.packages(\"ggmosaic\")\nlibrary(ggmosaic)\nggplot(Genderschool)+\n  geom_mosaic(aes(x=product(ST004D01T,ISCEDO), fill=ISCEDO))"
  },
  {
    "objectID": "index.html#task-10-t-test-practice-1",
    "href": "index.html#task-10-t-test-practice-1",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.11 Task 10 T-test practice #1",
    "text": "9.11 Task 10 T-test practice #1\n\nUsing the PISA 2018 data set, determine if there are statistically significant differences between the science, reading and mathematics scores of the UK and the US.\n\n\nAnswer# Create data frames with the score results for UK and US\nUKscores<-PISA_2018%>%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE)%>%\n  filter(CNT==\"United Kingdom\")\nUSscores<-PISA_2018%>%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE)%>%\n  filter(CNT==\"United States\")\n# Perform the t-test with maths results\nt.test(UKscores$PV1MATH, USscores$PV1MATH)\n# p-value is < 2.2e-16 so signficant differences exist for maths\nt.test(UKscores$PV1READ, USscores$PV1READ)\n# p-value = 0.8442 so no signficant differences exist for reading\nt.test(UKscores$PV1SCIE, USscores$PV1SCIE)\n# p-value = 0.2124 so no signficant differences exist for reading"
  },
  {
    "objectID": "index.html#task-11-t-test-practice-2",
    "href": "index.html#task-11-t-test-practice-2",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.12 Task 11 T-test practice #2",
    "text": "9.12 Task 11 T-test practice #2\n\nDivide the UK population into two groups, those that have internet access at home and those who do not. Are there statistically significant differences in the means of their reading, science and mathematics scores?\n\n\nAnswer# Create data frames with the score results for UK in two\n# groups, has internet and no internet, based on ST011Q06TA\nUKHasIntscores<-PISA_2018%>%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE, ST011Q06TA)%>%\n  filter(CNT==\"United Kingdom\" & ST011Q06TA==\"Yes\")\nUKNoIntscores<-PISA_2018%>%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE, ST011Q06TA)%>%\n  filter(CNT==\"United Kingdom\" & ST011Q06TA==\"No\")\n# Perform the t-test with maths results\nt.test(UKHasIntscores$PV1MATH, UKNoIntscores$PV1MATH)\n# p-value is < 2.2e-16 so no signficant differences for maths scores from\n# those with and without internet\nt.test(UKHasIntscores$PV1READ, UKNoIntscores$PV1READ)\n# p-value is < 2.2e-16 so no signficant differences for reading scores from\n# those with and without internet\nt.test(UKHasIntscores$PV1SCIE, UKNoIntscores$PV1SCIE)\n# p-value is < 2.2e-16 so no signficant differences for science scores from\n# those with and without internet"
  },
  {
    "objectID": "index.html#task-12-t-test-practice-3",
    "href": "index.html#task-12-t-test-practice-3",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.13 Task 12 T-test practice #3",
    "text": "9.13 Task 12 T-test practice #3\n\nUsing the PISA 2018 data set, are the mean mathematics scores of US boys and girls different to a statistically significant degree?\n\n\nAnswer# Create a dataframe of US boys math scores\nUSboys<-PISA_2018 %>%\n  select(CNT, PV1MATH, ST004D01T)%>%\n  filter(CNT==\"United States\")\n# Create a dataframe of US girls math scores\nUSgirls<-PISA_2018 %>%\n  select(CNT, PV1MATH, ST004D01T)%>%\n  filter(CNT==\"United States\")\n# Perform the t-test, using $PVMATH to indicate which column of the dataframe to use\nt.test(USboys$PV1MATH, USgirls$PV1MATH)\n# The p-value is 1 which is over 0.05 suggesting we accept the null hypothesis, there are no  statistically signficant difference in US girls and boys math scores"
  },
  {
    "objectID": "index.html#task-13-t-test-practice-3",
    "href": "index.html#task-13-t-test-practice-3",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.14 Task 13 T-test practice #3",
    "text": "9.14 Task 13 T-test practice #3\n\nAre the mean science scores of all students in the US and the UK different to a statistically significant degree?\n\n\nanswer# Create a dataframe of US science scores\nUSSci<-PISA_2018 %>%\n  select(CNT, PV1SCIE)%>%\n  filter(CNT==\"United States\")\n# Create a dataframe of UK science scores\nUKSci<-PISA_2018 %>%\n  select(CNT, PV1SCIE)%>%\n  filter(CNT==\"United Kingdom\")\n# Perfom the t-test, using $PV1SCIE to indicate which column of the dataframe to use\nt.test(USSci$PV1SCIE, UKSci$PV1SCIE)\n# The p-value is 0.2124, over 0.05, so we accept the null hypothesis, there is no statistically significant difference between US and UK science scores"
  },
  {
    "objectID": "index.html#task-14-chi-square-practice-1",
    "href": "index.html#task-14-chi-square-practice-1",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.15 Task 14 Chi-square practice #1",
    "text": "9.15 Task 14 Chi-square practice #1\n\nAre statiscally significant differences in the proportion of boys and girls and the number of books in the home for the whole dataset?\n\n\nAnswer# Create a dataframe of boys and number of books in the home\nMalebooksinhome<-PISA_2018 %>%\n  select(ST004D01T, ST013Q01TA)%>%\n  filter(ST004D01T==\"Male\")\n# Sum these up and convert to a data frame for chisq.test\nMalebooksinhome<-as.data.frame(table(Malebooksinhome$ST013Q01TA))\n# Repeat for girls\nFemalebooksinhome<-PISA_2018 %>%\n  select(ST004D01T, ST013Q01TA)%>%\n  filter(ST004D01T==\"Female\")\n\nFemalebooksinhome<-as.data.frame(table(Femalebooksinhome$ST013Q01TA))\n# Perform the chisq.test\nchisq.test(Malebooksinhome$Freq,Femalebooksinhome$Freq)\n# The p-value is 0.00727, which is less than 0.05 so the null hypothesis, that are no signifcnat differneces between the number of boys in boys' and girls' homes is rejects. Girls and boys have different distributions of number of books."
  },
  {
    "objectID": "index.html#task-15-chi-square-practice-2",
    "href": "index.html#task-15-chi-square-practice-2",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.16 Task 15 Chi-square practice #2",
    "text": "9.16 Task 15 Chi-square practice #2\n\nAre there statistically significant differences, in the whole data set, between boys and girls use of the internet at school to browse for homework (IC011Q03TA)?\n\n\nAnswer# Create a data frame of the girls responses to the question on internet use at school \ngirlsint<-PISA_2018%>%\n  select(IC011Q03TA, ST004D01T)%>%\n  filter(ST004D01T==\"Female\")%>%\n   select(IC011Q03TA)\n# Do the same for boys\nboysint<-PISA_2018%>%\n  select(IC011Q03TA, ST004D01T)%>%\n  filter(ST004D01T==\"Male\")%>%\n   select(IC011Q03TA)\n# Create frequency count tables of those data frames\n# Note the chisq.test function takes data frames as inputs\n# but the output of table is a table, so we convert the tables\n# back to data frames\ngirlsint<-as.data.frame(table(girlsint))\nboysint<-as.data.frame(table(boysint))\n# Run the chi.sq test using the freq column in the dataframe\nchisq.test(girlsint$Freq,boysint$Freq)\n# The output p-value is 0.008362 which is less than 0.05. So reject the null hypothesis. There is a difference in usage."
  },
  {
    "objectID": "index.html#task-16-chi-square-practice-3",
    "href": "index.html#task-16-chi-square-practice-3",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.17 Task 16 Chi-square practice #3",
    "text": "9.17 Task 16 Chi-square practice #3\n\nAre there statistically significant differences between the availability of laptops (IC009Q02TA) in school in the US and the UK?\n\n\nanswer# IC009Q02TA - Available for use in school - a laptop\n# Filter the data to get laptop use in the UK, put that into a new dataframe UKchidata\nUKchidata<- PISA_2018 %>%\n  select(CNT, IC009Q02TA)%>%\n  filter(CNT==\"United Kingdom\")%>%\n  select(IC009Q02TA)%>%\n  na.omit()\n# Filter the data to get laptop use in the US, put that into a new dataframe USchidata\nUSchidata<- PISA_2018 %>%\n  select(CNT, IC009Q02TA)%>%\n  filter(CNT==\"United States\")%>%\n  select(IC009Q02TA)%>%\n  na.omit()\n# use table to count the entries and convert to a data frame\nUKchidata<-as.data.frame(table(UKchidata))\nUSchidata<-as.data.frame(table(USchidata))\n# Do the chi squared test\nchisq.test(UKchidata$Freq, USchidata$Freq)\n# p-value is less than 0.05, so reject the null hypotheses - there are statistically significant differences in access to laptops in the UK and the US"
  },
  {
    "objectID": "index.html#task-18-anova-practice-1",
    "href": "index.html#task-18-anova-practice-1",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.18 Task 18 Anova practice #1",
    "text": "9.18 Task 18 Anova practice #1\n\nAre there statistically significant differences in mathematics scores of France, Germany, Spain, the UK and Italy? Find between which pairs of countries statistically significant differences in mathematics scores exist.\n\n\nanswer# Create a dataframe of the required countries\nEuroPISA <- PISA_2018 %>%\n  select(CNT, PV1MATH)%>%\n  filter(CNT==\"Spain\"|CNT==\"France\"| CNT==\"United Kingdom\"| CNT==\"Italy\"|CNT==\"Germany\")\n# Perform the anova\nresaov<-aov(data=EuroPISA, PV1MATH ~ CNT)\nsummary(resaov)\n\n# Yes, statistically significant differences exist between the countries Pr(>F) <2e-16 ***\n# Perform a Tukey HSD test\nTukeyHSD(resaov)\n# Significant differences p<0.05 exist for all countries except Italy and the UK"
  },
  {
    "objectID": "index.html#task-19-anova-practice-2",
    "href": "index.html#task-19-anova-practice-2",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.19 Task 19 Anova practice #2",
    "text": "9.19 Task 19 Anova practice #2\n\nFor the UK PISA 2018 data set, which variable out of WEALTH, ST004D01T, OCOD1 (Mother’s occupation), OCOD2 (Father’s occupation), ST011Q06TA (having a link to the internet), and highest level of parental education (HISCED) accounts for the most variation in science score? What percentage of variance is explained by each variable?\n! This is a big calculation so will take some time to compute!\n\n\nanswerUKPISA_2018 <- PISA_2018 %>%\n  filter(CNT==\"United Kingdom\")\n\nresaov<-aov(data=UKPISA_2018, PV1SCIE ~ WEALTH + ST004D01T + OCOD1 + OCOD2 + ST011Q06TA + HISCED)\nsummary(resaov)\neta <- etaSquared(resaov)\neta <- 100*eta\neta <- as.data.frame(eta)\neta\n# Most variance explained by OCOD2 (father's occupation), OCOD1 (mother's occupation)  HISCED (highest level of parental education), ST011Q06TA (having an internet link), WEALTH, then ST004DO1T (gender)"
  },
  {
    "objectID": "index.html#task-18-anova-practice-3",
    "href": "index.html#task-18-anova-practice-3",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n9.20 Task 18 Anova practice #3",
    "text": "9.20 Task 18 Anova practice #3"
  },
  {
    "objectID": "index.html#pisa",
    "href": "index.html#pisa",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n10.1 PISA",
    "text": "10.1 PISA\n\n10.1.1 What is PISA\nThe Programme for International Student Assessment (PISA) is an OECD initiative that looks at the reading, mathematics and science abilities of students aged 15 years old. Data is collected from ~38 OECD countries and other partner countries every three years.\n\n\nDataset\nDescription\n03\n06\n09\n12\n15\n18\n\n\n\nStudent\ndemographic data on student participants\nx\nx\nx\nx\nx\nx\n\n\nSchool\ndescriptive data about schools\nx\nx\nx\nx\nx\nx\n\n\nParent\na survey for student’s parents including information about home environments and parental education\nx\nx\n\n\n\n\n\n\nTeacher\ndemographic, teaching, qualification and training data\n\n\n\nx\nx\nx\n\n\nCognitive\n\nx\nx\nx\nx\nx\nx\n\n\n\nPISA datasets above can be found on the OECD website. The links in the table above will allow you to download .rds versions of these files which we have created, though they might need additional editing, e.g. reducing the number of columns or changing the types of each column. If you want to find out more about what each field stores, take a look at the corresponding codebook, for example from 2018.\n\n10.1.2 How to use it\nThe PISA datasets come in SPSS or SAS formats. The data used in this course comes directly from downloading the SPSS .sav files and using the haven package to clean it into a native R format suitable for analysis, in most cases .parquet files (see: Section 2.8.6). There are a few quirks that you need to be aware of:\n\nR uses levels (factors) instead of labelled data\nAll SPSS fields are labelled, and auto conversion into the native R dataframe format would make numeric fields, factors(!?). To avoid this confusion we have stripped out the no-response data for numeric fields and replaced it with NA values. This means that you won’t be able to tell the reason that a field is missing, and the following labels have all been set to NA:\n\n\nLabels set to NA in .rds and .parquet files\n\nvalue\nlabel\n\n\n\n95\nValid Skip\n\n\n97\nNot Applicable\n\n\n98\nInvalid\n\n\n99\nNo Response\n\n\n\n\nAs the fields are now using R’s native factor format you might find that the data doesn’t quite match the format of the table labels. For example, CNT is labelled “Country code 3-character”, but the data is now instead the full country name.\nthe examples shown in the book use cut down PISA datasets, where only a limited number of columns are included. The full datasets are linked in the table above.\n\n10.1.3 Common issues\nThe PISA datasets can be absolutely huge and might bring your computer to its knees; if you are using a computer with less than 16GB of RAM you might not be able to load some tables at all. Tables such as the Cognitive dataset have hundreds of thousands of rows and thousands of columns, loading them directly might lead to an error similar to this: Error: cannot allocate vector of size 2.1 Gb. This means that R can’t find enough RAM to load the dataset and has given up. You can see a rough estimate of how much RAM R is currently using the top Environment panel:\n\nTo get around this issues you can try to clean your current R environment using the brush tool:\n\nThis will drop all the current dataframes, objects, functions and packages that you have loaded meaning you will have to reload packages such as library(tidyverse) and library(haven) before you can attempt to reload the PISA tables.\nA lack of RAM might also be the result of lots of other programs running concurrently on your computer. Try to close anything that you don’t need, web browsers can be particularly RAM hungry, so close them or as many tabs as you can.\nIf none of the above works, then please get in touch with the team, letting them know which table you need from which year, with which fields and for which countries. We will be able to provide you with a cutdown dataset.\n\n10.1.4 Questions\n\n10.1.4.1 What are Plausible Values?\nIn the PISA dataset, the outcomes of student tests are reported as plausible values, for example, in the variables of the science test (PV1SCIE, PV2SCIE, PV3SCIE, PV3SCIE, and PV5SCIE). It might seem counter intuitive that there are five values for a score on a test.\nPlausible values (PVs) are a way of expressing the error in a measurement. The number of questions in the full PISA survey is very large, so students are randomly allocated to take a subset of questions (and even then, the test still takes two hours!). As no student completes the full set of questions, estimating how a student would have performed on the full question set involves some error. Plausible values are a way of expressing the uncertainty in the estimation of student scores.\nOne way of thinking of the PV scores is that they represent five different estimates of students’ abilities based on the questions they have answered. To decrease measurement error, five different approaches are applied to create five different estimates, the PV scores.\nThe PISA Data Analysis Manual suggests:\n\nPopulation statistics should be estimated using each plausible value separately. The reported population statistic is then the average of each plausible value statistic. For instance, if one is interested in the correlation coefficient between the social index and the reading performance in PISA, then five correlation coefficients should be computed and then averaged\nPlausible values should never be averaged at the student level, i.e. by computing in the dataset the mean of the five plausible values at the student level and then computing the statistic of interest once using that average PV value. Doing so would be equivalent to an EAP estimate, with a bias as described in the previous section.\n(p. 100) Monseur et al. (2009)\n\n\nWhat are PV Values - exclude non-OECD? as mean too low\ndifference between TA and NA for field names\n\n10.1.4.2 Why are some countries OECD countries and others aren’t?\nThe Organisation for Economic Co-operation and Development (OECD) has 38 member states. PISA is run by the OECD and its member states normally take part in each PISA cycle, but other countries are allowed to take part as Partners. You can find more details on participation here.\nResults for OECD members are generally higher than for Partner countries:\n\nPISA_2018 %>% \n  group_by(OECD) %>% \n  summarise(country_n = length(unique(CNT)),\n            math_mean = mean(PV1MATH, na.rm=TRUE),\n            math_sd = sd(PV1MATH, na.rm=TRUE),\n            students_n = n())\n\n# A tibble: 2 × 5\n  OECD  country_n math_mean math_sd students_n\n  <fct>     <int>     <dbl>   <dbl>      <int>\n1 No           43      434.   106.      317477\n2 Yes          37      490.    93.8     294527\n\n\n\n10.1.4.3 Why are the PV grades pivoting around the ~500 mark?\nThe scores for students in mathematics, reading and science are scaled so that the mean of students in OECD countries is roughly 500 points with a standard deviation of 100 points. To see this, run the following code:\n\nPISA_2018 %>% \n  filter(OECD==\"Yes\") %>% \n  summarise(math_mean = mean(PV1MATH, na.rm=TRUE),\n            math_sd = sd(PV1MATH, na.rm=TRUE),\n            scie_mean = mean(PV1SCIE, na.rm=TRUE),\n            scie_sd = sd(PV1SCIE, na.rm=TRUE),\n            read_mean = mean(PV1READ, na.rm=TRUE),\n            read_sd = sd(PV1READ, na.rm=TRUE))\n\n# A tibble: 1 × 6\n  math_mean math_sd scie_mean scie_sd read_mean read_sd\n      <dbl>   <dbl>     <dbl>   <dbl>     <dbl>   <dbl>\n1      490.    93.8      490.    96.0      488.    101.\n\n\n\n10.1.4.4 Why are the letters TA and NA used in some field names?\n\n10.1.4.5 How are students selected to take part in PISA?\nStudents are selected by … (ref?)\nAdd Christian Bokhove papers https://bokhove.net/r-materials/\nFrom the data, you can see that 50% of schools entered fewer than 30 students into PISA.\n\nPISA_2018 %>% \n  group_by(CNTSCHID) %>%\n  summarise(size = n()) %>%\n  mutate(quartile = ntile(size, 4)) %>%\n  group_by(quartile) %>%\n  summarise(Qmax = max(size),\n            Qmedian = median(size),\n            Qmean = mean(size))\n\n# A tibble: 4 × 4\n  quartile  Qmax Qmedian Qmean\n     <int> <int>   <dbl> <dbl>\n1        1    19       9  9.53\n2        2    29      25 24.6 \n3        3    35      33 32.8 \n4        4   491      40 44.9 \n\nggplot(PISA_2018 %>% \n  group_by(CNTSCHID) %>%\n  summarise(size = n()), aes(x=size)) +\n  geom_density()\n\n\n\n\n\n10.1.5 Interesting papers and reading on PISA\nJerrim Jiang and McComas (2015) Monseur et al. (2009)\n\n10.1.6 Copyright\n\nAll PISA products are published under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)\n\nThis includes the .rds and .parquet formatted datasets linked above.\n\n10.1.7 fields to drop:\nCNTRYID, NatCen"
  },
  {
    "objectID": "index.html#english-department-for-education",
    "href": "index.html#english-department-for-education",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n10.2 English Department for Education",
    "text": "10.2 English Department for Education\n\n10.2.1 Students\n\n10.2.2 Schools\n\n10.2.3 School workforce\n\n10.2.4 School recruitment\n\n10.2.5 Restricted datasets\nEducation provider details https://www.get-information-schools.service.gov.uk/Downloads\nResults"
  },
  {
    "objectID": "index.html#timss",
    "href": "index.html#timss",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n10.3 TIMSS",
    "text": "10.3 TIMSS\n\n10.3.1 What is TIMSS"
  },
  {
    "objectID": "index.html#other-datasets",
    "href": "index.html#other-datasets",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n10.4 Other datasets",
    "text": "10.4 Other datasets\n\n10.4.1 What other datasets are there?\n\n10.4.1.1 Gender equality indices\nThere are several international datasets for studying gender equality. These have been used by researchers to look at the impact of gender equality on student attitudes and outcomes. For example Stoet and Geary (2018) use the Global Gender Gap Index (GGGI) too look at PISA science self-efficacy and science outcomes for females.\n\n10.4.1.1.1 Global Gender Gap Index (GGGI)\nThe world economic forum produces the Global Gender Gap Index (GGGI), this index combines female and male outcomes on Economic participation and opportunity, educational attainment, health and survival, and political empowerment.\nReports for: 2022, 2021, 2020,2018,2017,2016, 2015\nIt has proven difficult to find the 2015 dataset used by Stoet & Geary, 2013 dataset is here\n\n10.4.1.1.2 United Nations\nThe UN reports on two gender specific indexes:\nGender Inequality Index (GII)\nThe Gender Inequality Index is a index incorporating data on reproductive health, empowerment and the labour market. Values range from 0 - full equality for men and women, to 0, full inequality.\nGender Development Index (GII)\nThe Gender Development Index measures inequalities in human development, combining data on female and male life expectancy, years of schooling and earned income. Values of 1 indicate equality, with values of less than 1 showing males performing better, and values over 1 showing females doing better.\nDownloads for the GII and GDI are here\n\ncode to match to PISA 2018 data# see page 6 and 7 of this\n# https://eprints.leedsbeckett.ac.uk/id/eprint/4753/6/symplectic-version.pdf\n# scores<- c(364, 411, 344)\n# c(364, 411, 344) - mean(scores)\n\n\n\n10.4.1.2 UNESCO\nhttp://data.uis.unesco.org “Distribution of tertiary graduates” STEM degree entry by country\n\n10.4.1.3 ONS\nhttps://data.oecd.org/api/sdmx-json-documentation/#d.en.330346\nhttps://www.ons.gov.uk/census/2011census/2011censusdata\nhttps://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationandhouseholdestimatesenglandandwalescensus2021\n\n10.4.1.4 OECD\nhttps://stats.oecd.org/\n\n\n\n\n10.4.1.5 Ofsted\nhttps://public.tableau.com/app/profile/ofsted/viz/Dataview/DataViewsurvey"
  },
  {
    "objectID": "index.html#sec-QANDA",
    "href": "index.html#sec-QANDA",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n11.1 Questions about R",
    "text": "11.1 Questions about R\nWhy doesn’t my select/filter statement work?\nWhen you are loading packages, sometimes different packages have the same function names in them, and the functions themselves will do very different things. For example, there is a select function in the tidyverse, but also another select function in the package MASS that does something very different. If we load the tidyverse before loading MASS, then the MASS version of select is the one that will be used?!\n\n\n\n\nlibrary(tidyverse)\nlibrary(MASS)\n\ndiamonds %>% select(carat, cut, color)\n\nTo get around this make sure that you load the tidyverse after MASS, in fact you should always load the tidyverse last.\n\nlibrary(MASS) \nlibrary(tidyverse)\n\ndiamonds %>% select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   <dbl> <ord>     <ord>\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# … with 53,930 more rows\n\n\nyou can also specify the package that select comes from (in this case from a package within the tidyverse called dplyr):\n\ndiamonds %>% dplyr::select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   <dbl> <ord>     <ord>\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# … with 53,930 more rows\n\n\nHow can I unload packages\nIf you are finding yourself with a conflict as mentioned above and want to unload packages, then you need to run the following code:\n\n# adapted from: @mmfrgmpds https://stackoverflow.com/questions/7505547/detach-all-packages-while-working-in-r\nwhile(!is.null(sessionInfo()$loadedOnly)){\n  lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)\n  invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))    \n}\n\nWhy am I getting the error ‘could not find function “%>%”’\nThe pipe operator %>% is loaded when you load the tidyverse package - make sure you have installed tidyverse and loaded it\n\ninstall.packages(\"tidyverse\")  # install\nlibrary(tidyverse)             # load\n\nI am getting the error: ‘“Error: Mapping should be created with aes() or aes_().”’ when using ggplot\nThis may be caused by having a bracket after the geom rather than before it\n\ndata<-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x, y) +           # Reproduce error message\n         geom_point())\n\n\ndata<-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x, y)) +           # Fixed error by moving bracket\n         geom_point()"
  },
  {
    "objectID": "index.html#about-the-coursework",
    "href": "index.html#about-the-coursework",
    "title": "Quantitative methods in the context of STEM education research",
    "section": "\n11.2 About the coursework",
    "text": "11.2 About the coursework\n?filter"
  }
]