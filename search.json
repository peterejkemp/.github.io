[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Questions and Answers",
    "section": "",
    "text": "This session will introduce you to the assumptions that underpin quantitative research.\n\n\nIn the seminar we will consider this paper:\nPasha-Zaidi and Afari (2016)\nReflect on:\n\nWhat values are implied by and issues arise from the authors’ construction of quantitative variables of ‘teacher professionalism’ and ‘teacher warmth’?\nTo what extent does the authors’ survey validly probe the variables of ‘teacher professionalism’ and ‘teacher warmth’?\n\n\n\n\n\n\nWhat other critiques of the study can you propose?\n\nThe second task considers this paper: Gibson and Dembo (1984)\nFor the purpose of discussion, teacher efficacy has been defined as “the extent to which the teacher believes he or she has the capacity to affect student performance” (Berman et al. 1977, 137)\n\n\n\n\n\n(Gibson and Dembo 1984, 573)\n\n\n(Gibson and Dembo 1984, 577)\n\n\nDoes teacher efficacy measure a discrete aspect of teachers’ beliefs? Does that matter?\nDoes the construct have validity? I.e., does the questionnaire measure what it claims to?\nWhat issues arises from quantifying teacher efficacy?\nWhat alternatives are there to quantitative measures of teacher efficacy? What are their advantages and limitations?\n\n\n“‘Quantitative’ and ‘qualitative’ are frequently seen in opposition…. The contrast is drawn between the objective world (out there independently of our thinking about it) and the subjective worlds (in our heads, as it were, and individually constructed); between the public discourse and private meanings; between reality unconstructed by anyone and the ‘multiple realities’ constructed by each individual. The tendency to dichotomise in this way is understandable but misleading.” (Pring 2000, 248)\n\n\n\nWhat are the differing assumptions of qualitative and quantitative educational research?\nAre the two ‘paradigms’ completely distinct? Is the distinction helpful?\nHow should a researcher choose what approach to use?"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Questions and Answers",
    "section": "\n2.1 Introduction",
    "text": "2.1 Introduction\nThis short course aims to take you through the process of writing your first programs in the R statistical programming language to analyse national and international educational datasets. To do this we will be using the R Studio integrated development environment (IDE), a desktop application to support you in writing R scripts. R Studio supports your programming by flagging up errors in your code as you write it, and helping you manage your analysis environment by giving you quick access to tables, objects and graphs as you develop them. In addition, we will be looking at data analysis using the tidyverse code packages. The tidyverse is a standardised collection of supporting code that helps you read data, tidy it into a usable format, analyse it and present your findings.\nThe R programming language offers similar functionality to an application based statistical tool such as SPSS, with more of a focus on you writing code to solve your problems, rather than using prebuilt tools. R is open source, meaning that it is free to use and that lots of people have written code in R that they have shared with others. R statistical libraries are some of the most comprehensive in existence. R is popular1 in academia and industry, being used for everything from sales modelling to cancer detection.\n\n# This example shows how R can pull data directly from the internet\n# tidy it and start making graphs. All within 9 lines of code\nlibrary(tidyverse)\n\neducation <- read_csv(\n  \"https://barrolee.github.io/BarroLeeDataSet/BLData/BL_v3_MF.csv\")\n\neducation %>%\n  filter(agefrom == 15, ageto == 24,\n         country %in% c(\"Germany\",\"France\",\"Italy\",\"United Kingdom\")) %>%\n  ggplot(aes(x=year, y=yr_sch, colour=country)) +\n  geom_point() +\n  geom_line()\n\n\n\n\nWhilst it is possible to use R through menu systems and drop down tools, the focus of this course is for you to write your own R scripts. These are text files that will tell the computer how to go through the process of loading, cleaning, analysing and presenting data. The sequential and modular nature of these files makes it very easy to develop and test each stage separately, reuse code in the future, and share with others.\nThis booklet is written with the following sections to support you:\n\n# Code examples and questions appear like this\na <- 1 + 3\n\n[1] Code output appears like this\nCourier font indicates keyboard presses, column names, column values and function names.\n<folder> Courier font within brackets describe values that can be passed to functions and that you need to define yourself. I.e. copying and pasting these code chunks verbatim won’t work!\n\n\n\n\n\n\nNote\n\n\n\nspecifies things to note\n\n\n\n\n\n\n\n\nWarning\n\n\n\ngives warning messages\n\n\n\n\n\n\n\n\nImportant\n\n\n\nhighlights issues that might break your code\n\n\n\n\n\n\n\n\nTip\n\n\n\ngives suggestions on how to do things in a better way\n\n\n\nActivities and coding tasks look like this\n\nwhat <- \"does this\"\ncode == \"do\""
  },
  {
    "objectID": "index.html#getting-set-up",
    "href": "index.html#getting-set-up",
    "title": "Questions and Answers",
    "section": "\n2.2 Getting set up",
    "text": "2.2 Getting set up\n\n2.2.1 Installation (on your own machine)\n\n\nInstall R (default settings should be fine)\n\n\nWindows users visit: here\n\n\nMac users visit: here and make sure you get the correct version\n\n\nInstall RStudio, visit here and it should present you with the version suitable for your operating system.\n\n(If the above doesn’t work follow the instructions here)\n\n2.2.2 Installation (KCL restricted machine)\n\nload the software center\n\nSearch for and install “R Statistics”\n\n\n\nSearch for and install “RStudio”\n\n\n\nYou might find this tutorial video helpful:\nhttps://vimeo.com/203516510\n\n2.2.3 Setting up RStudio and the tidyverse\n\nOpen RStudio\n\nOn the bottom right-hand side, select Packages, then select Install, then type “tidyverse” into the Packages field of the new window:\n\n\nClick Install and you should see things happening in the console (bottom left). Wait for the console activity to finish (it’ll be downloading and checking packages).\n\nAdd a new R Script using the  button\n\n\n\nIn the new R script, write the following:\n\n\n\nSelect all the lines and press Control or Command and Enter on your keyboard at the same time. Alternatively, press the  button\n\n\n\nCheck that you have the following in the console window:\n\n\nThat’s it, you should be set up!\nAny issues, please mail peter.kemp@kcl.ac.uk and richard.brock@kcl.ac.uk"
  },
  {
    "objectID": "index.html#starting-to-code",
    "href": "index.html#starting-to-code",
    "title": "Questions and Answers",
    "section": "\n2.3 Starting to code",
    "text": "2.3 Starting to code\nAfter adding a new R Script using the button , there are four parts to R Studio’s interface. For the moment we are most interested in the Script file section, top left."
  },
  {
    "objectID": "index.html#your-first-program",
    "href": "index.html#your-first-program",
    "title": "Questions and Answers",
    "section": "\n2.4 Your first program",
    "text": "2.4 Your first program\n\n2.4.1 Objects and instructions\nIn programming languages we can attach data to a name, this is called assigning a value to an object (you might also call them variables). To do this in R we use the <- arrow command. For example, I want to put the word \"Pete\" into an object called myname (note that words and sentences such as \"Pete\" need speech marks):\n\nmyname <- \"Pete\"\nprint(myname)\n\n[1] \"Pete\"\n\n\nWe can also perform quick calculations and assign them to objects:\n\nHoursInYear <- 365 * 24\nprint(HoursInYear) \n\n[1] 8760\n\n\n\nType the two examples above into your RStudio script file and check that they work. Adapt them to say your full name and give the number of MinutesInADay\n\n\n\n\n\n\n\nTip\n\n\n\nRemember to select code and press control or command and Enter to run it\n\n\nObjects can form part of calculations, for example, the code below shows how we can use the number HoursInYear to (roughly!) calculate the number of HoursInWeek:\n\nHoursInYear <- 365 * 24\n\nHoursInWeek <- HoursInYear / 52\nprint(HoursInWeek)\n\n[1] 168.4615\n\n\nNotice from the above we can perform the main arithmetic commands using keyboard symbols: + (add); - (minus); * (multiply); / (divide); ^ (power)\nObjects can change values when you run code. For example in the code below:\n\na <- 2000\nb <- 5\n\na <- b\n\na <- a * b\nprint(a)\n\n[1] 25\n\n\nWhat’s going on here?\n\nline 1 sets a to equal 2000 (note: don’t use commas in writing numbers a <- 2,000 would bring up an error),\nline 2 sets b to equal 5,\nline 4 overwrites the value of a with the value stored in b, making object a now equal to 5\nline six is now 5 * 5\n\n\n\n2.4.1.1 Questions\n\nwhat are the outputs of the following code snippets/what do they do? One of the examples might not output anything, why is that? Type the code into your script file to check your answers:\ncode example 1\n\nrabbits <- 50\nfeet <- 4\n\ntotalfeet <- rabbits * feet\nprint(totalfeet)\n\n\nanswer200\n\n\ncode example 2\n\np <- 3.14 - 0.14\nr <- 5\n\nprint(p * r^2)\n\n\nanswer75\n\n\ncode example 3\n\ntax <- 17.5\nprice <- 4.50\nsales <- 128\ntax <- 20\n\nincome <- (sales * price) * (1 + (tax/100))\n\n\nanswer# prints nothing! there isn't a print statement\n\n\n\n\n2.4.2 Naming objects\nCorrectly naming objects is very important. You can give an object almost any name, but there are a few rules to follow:\n\nName them something sensible\nR is case sensitive, myName is not equal to (!=) myname\n\nDon’t use spaces in names\nDon’t start a name with a number\nKeep punctuation in object names to underscore (_ and full stop .) e.g. my_name, my.name 2.\nStick to a convention for all your objects, it’ll make your code easier to read, e.g.\n\n\nmyName, yourName, ourName (this is camelCase 3)\n\nmy_name, your_name, our_name\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe actual name of an object has no effect on what it does (other than invalid names breaking your program!). For example age <- \"Barry\" is perfectly valid to R, it’s just a real pain for a human to read.\n\n\n\n2.4.2.1 Questions\n\nWhich of these are valid R object names:\n\nmy_Number\nmy-Number\nmyNumber!\nfirst name\nFIRSTname\ni\n3names\nnames3\n\n\nanswers# my_Number  (VALID)\n# my-Number  (VALID)\n# myNumber!  (INVALID due to !)\n# first name (INVALID due to space)\n# FIRSTname  (VALID but don't recommend so many caps)\n# i          (VALID)\n# 3names     (INVALID starts with a 3)\n# names3     (VALID)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor more information on the R programming style guide, see this\n\n\n\n2.4.3 Comments\nCode can often look confusing and it’s a good idea to add # comments to your code to make it more understandable for you and others. The computer ignores comments when running your code:\n\n# this calculates the average sales per shop\n\nincome1 <- 132\nincome2 <- 665\nincome3 <- 233\nincome4 <- 1200\n\nshops <- 4 # everything after the hash is a comment\n\navgSales <- sum(income1, income2, income3, income4) / shops  \n\n# sometimes you might want to comment out code that\n# is no longer needed, but might be useful later\n# standard_deviation <- sd(c(income1, income2, income3, income4) )\n# the above code isn't run\n\nprint(avgSales) # but this code is\n\n[1] 557.5"
  },
  {
    "objectID": "index.html#sec-datatypes",
    "href": "index.html#sec-datatypes",
    "title": "Questions and Answers",
    "section": "\n2.5 Datatypes",
    "text": "2.5 Datatypes\nWe have already met two different datatypes, the character datatype for words and letters (e.g. \"Peter\") and the numeric datatype for numbers (e.g. 12). Datatypes tell R how to handle data in certain circumstances. Sometimes data will be of the wrong datatype and you will need to convert between datatypes.\n\nweeks <- 4\ndays_in_week <- \"7\"\n\n# we now attempt to multiply a number by a string\n# but it doesn't work!\ntotal_days <- weeks * days_in_week \n\nError in weeks * days_in_week: non-numeric argument to binary operator\n\n\nWhilst R will understand what to do when we multiply numbers with numbers, it gets very confused and raises an error when we try to perform an arithmetic operation using words and numbers.\nTo perform the calculation we will need to convert the days_in_week from a string to a number, using the as.numeric(<text>) command:\n\nweeks <- 4\ndays_in_week <- \"7\"\n\n# we now attempt to multiply a number by a string\ntotal_days <- weeks * as.numeric(days_in_week)\n\nThere is a logical datatype for boolean values of TRUE and FALSE. This will become a lot more useful later.\n\nlegs_snake <- TRUE # you can specify logical values directly\ndogs_legs <- 4\nlegs_dog <- dogs_legs > 0 # or as part of a calculation\n\n# Do dog's have legs?\nprint(legs_dog)\n\n[1] TRUE\n\n\nThere are actually three datatypes for numbers in R, numeric for most of your work, the rarer integer specifically for whole numbers and the even rarer complex for complex numbers. When you are looking at categorical data, factors are used on top of the underlying datatype to store the different values, for example you might have a field of character to store countries, factors would then list the different countries stored in this character field.\nTo change from one datatype to another we use the as.____ command: as.numeric(<text>), as.logical(<data>), as.character(<numeric>).\n\n2.5.0.1 Questions\n\n\nCan you spot the error(s) in this code and fix them so it outputs: “July is month 7”?\n\n\nmonth <- \"July\"\norder <- 7\n  \nprint(month)\nPrint(\"is\")\nprint(month)\nprint(\"order\")\n\n\nanswermonth <- \"July\"\norder <- 7\n  \nprint(month)    \nprint(\"is\")     #1 print needs a lowercase p\nprint(\"month\")  #2 month is a character not an object, use speech marks\nprint(order)    #3 order is an object, not a character, so drop the speech marks\n\n\n\nCan you spot the error(s) in this code and fix it?\n\n\na <- 7\nb <- \"8\"\nc < - 3\n  \nprint(a + b + c)\n\n\nanswera <- 7\nb <- 8 #1 b is numeric so drop the speech marks\nc <- 3 #2 the arrow needs to be together, remove the space\n  \nprint(a + b + c)\n\n\n\nCan you spot the error(s) in this code and fix it?\n\n\npass mark <- 50 \nexam_grade <- 50\n\n# did the student pass?\nprint(exam_grade > pass_mark)\n\n\nanswerpass_mark <- 50 #1 the variable name can't have any spaces\nexam_grade <- 50\n\n# did the student pass?\nprint(exam_grade >= pass_mark) # this needs to be >= as they had a passing grade\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to find out the datatype of an object you can use the structure str command to give you more information about the object. In this instance chr means that month is of character datatype and num means it is of the numeric datatype.\n\nmonth <- \"July\"\nstr(month)\n\n chr \"July\"\n\nmonth <- 7\nstr(month)\n\n num 7\n\n\n\n\n\n2.5.1 Vectors\nSo far we have seen how R does simple calculations and prints out the results. Underlying all of this are vectors. Vectors are data structures that bring together one or data elements of the same datatype. E.g. we might have a numeric vector recording the grades of a class, or a character vector storing the gender of a set of students. To define a vector we use c(<item>, <item>, ...), where c stands for combine. Vectors are very important to R4, even declaring a single object, x <- 6, is creating a vector of size one. Larger vectors look like this:\n\nmaths_grade <-   c(5,    4,    4,    1,     7,     5,     8)\nenglish_grade <- c(8,    5,    3,    2,     3,     6,     9)\ngenders <-      c(\"F\",  \"M\",  \"M\",  \"F\",   \"M\",   \"F\",   \"M\")\nstudents <-     c(\"Joe\", \"Al\", \"Mo\", \"Flo\", \"Olu\", \"Sam\", \"Jimmy\")\n\nYou can quickly perform calculations across whole vectors:\n\n# convert all genders to the lower case form\ntolower(genders) \n\n[1] \"f\" \"m\" \"m\" \"f\" \"m\" \"f\" \"m\"\n\n# raise everyone's maths grade by one(!?)\nmaths_grade + 1\n\n[1] 6 5 5 2 8 6 9\n\n\nWe can also perform calculations across vectors, in the example below we can find out which students got a better grade in Maths than in English.\n\n# this compares each pair of values\n# e.g. the first item in maths_grade (5) with\n# the first item in english_grade (8)\n# and so on\n# This returns a logical vector of TRUE and FALSE\nmaths_grade > english_grade\n\n[1] FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE\n\n# To work out how many students got a better grade \n# in maths than in English we can apply sum()\n# to the logical vector. \n# We know that TRUE == 1, FALSE == 0,\n# so sum() will count all the TRUEs\nsum(maths_grade > english_grade)\n\n[1] 2\n\n# if you want to find out the average grade for\n# each student in maths and english\n# add both vectors together and divide by 2\n(maths_grade + english_grade) / 2\n\n[1] 6.5 4.5 3.5 1.5 5.0 5.5 8.5\n\n# we can use square brackets to pick a value from a vector\n# vectors start couting from 1, so students[1] would pick Jo\nstudents[1]\n\n[1] \"Joe\"\n\n# we can pass a numeric vector to a another vector to create a\n# subset, in the example below we find the 3rd and 5th item\n\nstudents[c(3,5)]\n\n[1] \"Mo\"  \"Olu\"\n\n# we can also use a vector of TRUE and FALSE to pick items\n# TRUE will pick an item, FALSE will ignore it\n# for each maths_grade > english_grade that is TRUE\n# the name in that position in the student vector will be shown\nstudents[maths_grade > english_grade]\n\n[1] \"Mo\"  \"Olu\"\n\n\nYou should be careful when trying to compare vectors of different lengths. When combining vectors of different lengths, the shorter vector will match the length of the longer vector by wrapping its values around. For example if we try to combine a vector of the numbers 1 ot 10 with a two item logical vector TRUE FALSE, the logical vector will repeat 5 times: c(TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE). We can use this vector as a mask to return the odd numbers, TRUE means keep, FALSE means ignore:\n\nnums <- c(1,2,3,4,5,6,7,8,9,10)\nmask <- c(TRUE, FALSE) \n\n# you can see the repeat of mask by pasting them together\npaste(nums, mask)\n\n [1] \"1 TRUE\"   \"2 FALSE\"  \"3 TRUE\"   \"4 FALSE\"  \"5 TRUE\"   \"6 FALSE\" \n [7] \"7 TRUE\"   \"8 FALSE\"  \"9 TRUE\"   \"10 FALSE\"\n\n# now to filter out the numbers we don't want\nnums[mask]\n\n[1] 1 3 5 7 9\n\n\nThis might not seem very useful, but it comes in very handy when we want to perform a single calculation across a whole vector. For example, we want to find all the students who achieved grade 5 in English, the below code creates a vector of 5s the same size as english_grade:\n\n# this can also be rewritten english_grade >= c(5)\n# note, when we are doing a comparison, we need to use double ==\nstudents[english_grade == 5]\n\n[1] \"Al\"\n\n#which is the same as\nstudents[english_grade == c(5,5,5,5,5,5,5)]\n\n[1] \"Al\"\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen we are doing a comparison, we need to use double == equals sign. Using a single equals sign is the equivalent of an assignment = is the same as <-\n\n\n\n\n\n\n\n\nTip\n\n\n\nThere are several shortcuts that you can take when creating vectors. Instead of writing a whole sequence of numbers by hand, you can use the seq(<start>, <finish>, <step>) command. For example:\n\n# the step default is 1, so you can miss it from seq(1,10,1)\nseq(1,10)   == c(1,2,3,4,5,6,7,8,9,10)\nseq(1,10,2) == c(1,3,5,7,9)\n\nThis allows for some pretty short ways of solving quite complex problems, for example if you wanted to know the sum of all the multiples of 3 and 5 below 1000, you could write it like this:\n\n# the unique() command gives you the unique items in a vector\nsum(unique(c(seq(3, 999, 3), seq(5, 999, 5))))\n\nAnother shortcut is writing T, F, or 1, 0 instead of the whole words TRUE, FALSE:\n\nc(T, F) == c(1, 0) == c(TRUE, FALSE)\n\n\n\n\n2.5.2 Questions\n\n\nCan you spot the four problems with this code:\n\n\nnums <- v(1,2,\"3\",4,7,2,2)\nsum(nums)\nmean(nums)\n# return a vector of all numbers greater than 2\nnums(nums >= 2)\n\n\nanswernums <- c(1,2,3,4,7,2,2) \n#1 a vector is declared using c(), not v()\n#2 3 should be numeric, so no need for speech marks\n# (though technically R would do this conversion for you!)\n\nsum(nums)\nmean(nums)\n# return a vector of all numbers greater than 2\nnums[nums >= 2] #3 to pick items from another vector, use square brackets\n\n\n\nCreate a vector to store the number of glasses of water you have drunk for each day in the last 7 days. Work out:\n\nthe average number of glasses for the week,\nthe total number of glasses,\nthe number of days where you drank less than 2 glasses (feel free to replace water with your own tipple: wine, coffee, tea, coke, etc.)\n\n\n\n\nanswerglasses <- c(6,1,3,2,3,0)\nmean(glasses)\nsum(glasses)\nsum(glasses < 2)\n\n\n\nUsing the vectors below, create a program that will find out the average grade for females taking English:\n\n\nenglish_grade <- c(8,5,3,2,3,6,9)\ngenders <- c(\"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\")\n\n\nanswerenglish_grade <- c(8,5,3,2,3,6,9)\ngenders <- c(\"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\")\nmean(english_grade[genders == \"F\"])\n\n\n\n\n2.5.3 Summary questions\nNow you have covered the basics of R, it’s time for some questions to check your understanding. These questions will cover all the material you have read so far and don’t be worried if you need to go back and check something. Exemplar answers are provided, but don’t worry if your solution looks a little different, there are often multiple ways to achieve the same outcome.\n\n\nDescribe three datatypes that you can use in your program?\n\n\nanswerprint(\"numeric for numbers\")\nprint(\"character for words/strings\")\nprint(\"logical for boolean values\")\n\n\n\nWhat are two reasons that you might use comments?\n\n\nanswer# to make your code more understandable\n# to disable bits of code that you might want to reenable later\n\n\n\n\nWhich object names are valid?\n\nmy_name\nyour name\nour-name\nTHYname\n\n\n\n\nanswer# my_name - VALID\n# your name - INVALID use of space\n# our-name - INVALID use of hyphen\n# THYname - VALID\n\n\n\nCan you spot the four errors in this code:\n\n\nstu1 <- 12\n2stu <- 13\nstu3 <- \"15\"\n\n# now work out the average of the ages\navg < - (Stu1 + stu2 + stu3) / 3\nprint(avg)\n\n\nanswerstu1 <- 12\nstu2 <- 13 #1 2stu to stu2, cannot start name with a number\nstu3 <- 15 #2 no need for speech marks on \"15\"\n\n# now work out the average of the ages\navg <- (stu1 + stu2 + stu3) / 3 #3 broken arrow < - #4 capital letter on Stu1\nprint(avg)\n\n\n\n[Extension] Calculate the number of seconds since 1970.\n\n\nanswerthis_year <- 2022\nfocus_year <- 1970\n\n(this_year - focus_year) * 365 * 24 * 60 * 60"
  },
  {
    "objectID": "index.html#packages-and-libraries",
    "href": "index.html#packages-and-libraries",
    "title": "Questions and Answers",
    "section": "\n2.6 Packages and libraries",
    "text": "2.6 Packages and libraries\nR comes with some excellent statistical tools, but often you will need to supplement them with packages5 . Packages contain functionality that isn’t built into R by default, but you can choose to load or install them to meet the needs of your tasks. For example you have code packages to deal with SPSS data, and other packages to run machine learning algorithms. Nearly all R packages are free to use!\n\n2.6.1 Installing and loading packages\nTo install a package you can use the package tab in the bottom right-hand panel of RStudio and follow the steps from Section 2.2.3. Alternatively you can install things by typing:\n\ninstall.packages(\"tidyverse\")\n\nNote that the instruction is to install packages, you can pass a vector of package names to install multiple packages at the same time:\n\ninstall.packages(c(\"tidyverse\",\"readxl\",\"haven\"))\n\nOnce a package is installed it doesn’t mean that you can use it, yet. You will need to load the package. To do this you need to use the library(<package_name>) command, for example:\n\nlibrary(tidyverse)\n\n\n\n\n\n\n\nImportant\n\n\n\nSome packages might use the same function names as other packages, for example select might do different things depending on which package you loaded last. As a rule of thumb, when you start RStudio afresh, make sure that you load the tidyverse package after you have loaded all your other packages. To read more about this problem see Section 14.1"
  },
  {
    "objectID": "index.html#the-tidyverse",
    "href": "index.html#the-tidyverse",
    "title": "Questions and Answers",
    "section": "\n2.7 The tidyverse",
    "text": "2.7 The tidyverse\nThis course focuses on using the tidyverse; a free collection of programming packages that will allow you to write code that imports data, tidys it, transforms it into useful datasets, visualises findings, creates statistical models and communicates findings to others data using a standardised set of commands.\n\n\nData science workflow - RStudio\n\n\nFor many people the tidyverse is the main reason that they use R. The tidyverse is used widely in government, academia, NGOs and industry, notable examples include the Financial Times and the BBC. Code in the tidyverse can be (relatively) easily understood by others and you, when you come back to a project after several months.\n\n\n\n\n# load the tidyverse packages\nlibrary(tidyverse)\n\n# download Covid data from website\ndeaths <- read.csv(\"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/excess_mortality/excess_mortality.csv\")\n\ndeaths <- deaths %>% \n     filter(location %in% \n              c(\"United States\", \"United Kingdom\", \n                \"Sweden\", \"Germany\")) %>%\n  mutate(date = as.Date(date))\n\nggplot(data=deaths) +\n  geom_line(aes(x = date, \n                y = excess_per_million_proj_all_ages, \n                colour=location)) +\n  theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\n\nTry this out\n\n\n\nThe code above transforms data and converts it into a graph. It doesn’t have any comments, but you should hopefully be able to understand what a lot of the code does by just reading it. Can you guess what each line does? Try running the code by selecting parts of it and pressing control | command and Enter"
  },
  {
    "objectID": "index.html#loading-data",
    "href": "index.html#loading-data",
    "title": "Questions and Answers",
    "section": "\n2.8 Loading data",
    "text": "2.8 Loading data\nWe can’t do much with R without loading data from elsewhere. Data will come in many formats and R should be able to deal with all of them. Some of the datasets you access will be a few rows and columns; others, like the ones we are going to use on this course, might run into hundreds of thousands or even millions of rows and hundreds or thousands of columns. Depending on the format you are using, you might need to use specific packages. A few of the data file types you might meet are described below:\n\n\n\n\n\n\nFile type\nDescription\n\n\n\nComma separated values [.csv]\nAs it says in the name, .csv files store data by separating data items with commas. They are a common way of transferring data and can be easily created and read by Excel, Google spreadsheets and text editors (in addition to R). CSVs aren’t compressed so will generally be larger than other file types. They don’t store information on the types of data stored in the file so you might find yourself having to specify that a date column is a date, rather than a string of text. You can read and write csv files without the need to load any packages, but if you do use readr you might find things go much faster.\n\n\nExcel [.xls | .xlsx | .xlsxm]\nExcel files store data in a compressed custom format. This means files will generally be smaller than CSVs and will also contain information on the types of data stored in different columns. R can read and write these files using the openxlsx package, but you can also use the tidyverse’s readxl for reading, and writexl for writing for excel formats.\n\n\nR Data [.rds]\nR has it’s own data format, .rds. Saving to this format means that you will make perfect copies of your R data, including data types and factors. When you load rds files they will look exactly the same as when you saved them. Data can be highly compressed and it’s one of the fastest formats for getting data into R. You can read and write rds files without the need to load any packages, but using the functions in readr might speed things up a bit. You won’t be able to look at .rds files in other programs such as excel\n\n\nSPSS [.sav]\nSPSS is a common analysis tool in the world of social science. The native format for SPSS data is .sav. These files are compressed and include information on column labels and column datatypes. You will need either the haven or foreign packages to read data into R. Once you have loaded the .sav you will probably want to convert the data into a format that is more suitable for R, normally this will involve converting columns into factors. We cover factors in more detail below.\n\n\nStata [.dta]\n\nhaven or foreign packages to read data into R\n\n\nSAS [.sas]\n\nhaven or foreign packages to read data into R\n\n\nStructured Query Language [.sql]\na common format for data stored in large databases. Normally SQL code would be used to query these, you can use the tidyverse to help construct SQL this through the package dbplyr which will convert your tidyverse pipe code into SQL. R can be set up to communicate directly with databases using the DBI package.\n\n\nJSON\nA popular format for sharing data on the web. You can use jsonlite and rjson to access this type of data\n\n\n\nFor this course we will be looking at .csv, excel and .rds files.\n\n2.8.1 Dataframes\nLoading datasets into R will normally store them as dataframes (also known as tibbles when using the tidyverse). Dataframes are the equivalent of tables in a spreadsheet, with rows, columns and datatypes. First we need to get some data into R so we can start analysing them.\n\n\n\n\n\n\nTip\n\n\n\nCore to the tidyverse is the idea of tidy data, a rule of thumb for creating datasets that can be easily manipulated, modeled and presented. Tidy data are datasets where each variable is a column and each observation a row.\nThis data isn’t tidy data as each row has contains multiple exam results (observations):\n\n\nID\nExam 1\nGrade 1\nExam 2\nGrade 2\n\n\n\nR2341\nEnglish\n4\nMaths\n5\n\n\nR8842\nEnglish\n5\n\n\n\n\n\nThis dataframe is tidy data as each student has one entry for each exam:\n\n\nID\nExam\nGrade\n\n\n\nR2341\nEnglish\n4\n\n\nR2341\nMaths\n5\n\n\nR8842\nEnglish\n5\n\n\n\n\n\n\n\n\nWe can load large datatables into R by either providing the online web address, or by loading it from a local file directory on your hard drive. Both methods are covered below:\n\n2.8.2 Loading data from the web\nTo download files from the web we need another package, openxlsx, which you need to install before you load it (see: Section 2.2.3, or use line 1 below). The code shown will download the files from an online Google drive directly into objects in R using read.xlsx(<file_web_address>, <sheet_name>):\n\n\n\n\n\n\nTip\n\n\n\nTo convert data on your google drive into a link that works in R, you can use the following website: https://sites.google.com/site/gdocs2direct/. Note that not all read/load commands in R will work with web addresses and some will require you have to copies of the datasets on your disk drive. Additionally, downloading large datasets from the web directly into R can be very slow, loading the dataset from your harddrive will nearly always be much faster.\n\n\n\ninstall.packages(\"openxlsx\")\nlibrary(openxlsx)\n\nresults <- read.xlsx(\"https://drive.google.com/uc?export=download&id=1tp9xe3dS__eg7RrXf0T_oMxcrz_TbMdM\",\n                      sheet=\"Results\")\nschools <- read.xlsx(\"https://drive.google.com/uc?export=download&id=1tp9xe3dS__eg7RrXf0T_oMxcrz_TbMdM\",\n                      sheet=\"Schools\")\n\n\n2.8.3 Loading data from your computer\nDownloading files directly from web addresses can be slow and you might want to prefer to use files saved to your computer’s hard drive. You can do this by following the steps below:\nDownload the PISA_student_2018.rds file from here and save it to your computer where your R code file is.\nCopy the location of the file (see next step for help)\n\n\nTo find the location of a file in Windows do the following:\n\n\nNavigate to the location of the file in Windows Explorer:\n\n\n\nClick on the address bar\n\n\nCopy the location\n\n\n\nTo find the location of a file in Mac OSX do the following:\n\nOpen Finder\nNavigate to the folder where you saved the Excel file\n\nRight click on the folder where the file is stored and click to open the menu. Then press the option button and select Copy <name of file> as Pathname\n\n\nAlternatively, follow this\n\n\n\nTo load the data into R we need to use the read_excel(<file_location>, <sheet_name>) command, specifying the location and name of the file we are loading, and as we are reading an Excel file, we need to specify the sheet name within the Excel file. See the following code:\n\n# load the basic tidyverse libraries and readxl\n# readxl is for reading and writing Excel files \n# and not loaded by the tidyverse by default\nlibrary(tidyverse)\nlibrary(readxl)\n\n# note that we need to add /dfe_data.xlsx to the end of the file location\nresults <- read_excel(\"c:/Users/Peter/Google Drive/Kings/R intro/code/dfe_data.xlsx\", \"Results\")\nschools <- read_excel(\"c:/Users/Peter/Google Drive/Kings/R intro/code/dfe_data.xlsx\", \"Schools\")\n\n\n2.8.4 Setting working directories\nUsing the setwd(<location>) you can specify where R will look by default for any datasets. In the example below, the dfe_data.xlsx will have been downloaded and stored in C:/Users/Peter/code. By running setwd(\"C:/Users/Peter/code\") R will always look in that location when trying to load files, meaning that read_excel(\"dfe_data.xlsx\", \"Results\") is actually the same as read_excel(\"C:/Users/Peter/code/dfe_data.xlsx\", \"Results\")\n\n# context: setup\n\n# load the basic tidyverse libraries and readxl\n# readxl is for reading and writing Excel files \n# and not loaded by the tidyverse by default\nlibrary(tidyverse)\nlibrary(readxl)\n\n# set the working directory to be where your data is stored\n# note that you need to convert the backslashes \\ in the address to forwardslashes /\nsetwd(\"C:/Users/Peter/code\")\n\n# then load the Results and Schools sheets from dfe_data.xlsx\nresults <- read_excel(\"dfe_data.xlsx\", \"Results\")\nschools <- read_excel(\"dfe_data.xlsx\", \"Schools\")\n\nTo work out what your current working directory is, you can use getwd().\n\n2.8.5 Proper addresses\nYou might have found that you get an error if you don’t convert your backslashes \\ into forwardslashes /. It’s common mistake and very annoying. In most programming languages a backslash signifies the start of a special command, for example \\n signifies a newline.\nWith R there are three ways to get around the problem of backslashes in file locations, for the location:\"C:\\myfolder\\\" we could:\n\nreplace them with forwardslashes (as shown above):\"C:/myfolder/\"\n\nreplace them with double backslashes (the special character specified by two backslashes is one backslash!):\"C:\\\\myfolder\\\\\"\n\nuse the inbuilt R command to deal with filenames: r\"[C:\\myfolder\\]\"\n\n\n2.8.6 Dealing with .rds files\nFor the majority of this workbook you will be using a cutdown version of the PISA_2018 student table. This dataset is huge and we have loaded it into R, selected fields we think are useful, converted column types to work with R and saved in the standard R format. .rds files are quick to load and small in size. To load an .rds file you can use the read_rds(<location>) command from the tidyverse.\n\nlibrary(tidyverse)\nPISA_2018 <- read_rds(\"<yourfolder>/pisa_student_2018.rds\")\n\nIf you want to save out any of your findings, you can use write_rds(<object>, <location>, <compression>), where object is the table you are working on, location is where you want to save it, and compression is specifying whether you want to save space by making it smaller on your hard disk, but slower to load. Compression can be the value: “none” for no compression and “bz2” for compression.\n\nlibrary(tidyverse)\nPISA_2018 <- write_rds(PISA_2018 %>% filter(CNT==\"France\"),\n                      \"<yourfolder>/pisa_france_2018.rds\",\n                      \"none\")\n\n\n2.8.7 Exploring data\nNow that we have loaded the PISA_2018 dataset we can start to explore it.\nYou can check that the tables have loaded correctly by typing the object name and ‘running’ the line (control|command and Enter)\n\nPISA_2018\n\n# A tibble: 612,004 × 204\n   CNT     OECD  ISCEDL   ISCEDD ISCEDO PROGN WVARS…¹ COBN_F COBN_M COBN_S GRADE\n   <fct>   <fct> <fct>    <fct>  <fct>  <fct>   <dbl> <fct>  <fct>  <fct>  <fct>\n 1 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 2 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 3 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 4 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 5 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 6 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 7 Albania No    ISCED l… C      Vocat… Alba…       3 Missi… Missi… Missi… 0    \n 8 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 9 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n10 Albania No    ISCED l… C      Vocat… Alba…       3 Missi… Missi… Missi… 0    \n# … with 611,994 more rows, 193 more variables: SUBNATIO <fct>, STRATUM <fct>,\n#   ESCS <dbl>, LANGN <fct>, LMINS <fct>, OCOD1 <fct>, OCOD2 <fct>,\n#   REPEAT <fct>, CNTRYID <fct>, CNTSCHID <dbl>, CNTSTUID <dbl>, NatCen <fct>,\n#   ADMINMODE <fct>, LANGTEST_QQQ <fct>, LANGTEST_COG <fct>, BOOKID <fct>,\n#   ST001D01T <fct>, ST003D02T <fct>, ST003D03T <fct>, ST004D01T <fct>,\n#   ST005Q01TA <fct>, ST007Q01TA <fct>, ST011Q01TA <fct>, ST011Q02TA <fct>,\n#   ST011Q03TA <fct>, ST011Q04TA <fct>, ST011Q05TA <fct>, ST011Q06TA <fct>, …\n\n\nWe can see from this that the tibble (another word for dataframe, basically a spreadsheet table) is 612004 rows, with 204 columns 6. This is data for all the students from around the world that took part in PISA 2018. The actual PISA dataset has many more columns than this, but for the examples here we have selected 204 of the more interesting data variables. The column names might seem rather confusing and you might want to refer to the PISA 2018 code book to find out what everything means.\nThe data shown in the console window is only the top few rows and first few columns. To see the whole table click on the Environment panel and the table icon  to explore each table:\nTODO: insert images here\nAlternatively, you can also hold down command|control and click on the table name in your R Script to view the table. You can also type view(<table_name>).\n\n\n\n\n\n\nNote\n\n\n\nTo learn more about loading data from in other formats, e.g. SPSS and STATA, look at the tidyverse documentation for haven.\n\n\nThe PISA_2018 dataframe is made up of multiple columns, with each column acting like a vector, which means each column stores values of only one datatype. If we look at the first four columns of the schools table, you can see the CNTSTUID, ESCS and PV1MATH columns are <dbl> (numeric) and the other three columns are of <fctr> (factor), a special datatype in R that helps store categorical and ordinal variables, see Section 2.9 for more information on how factors work.\n\n\n# A tibble: 5 × 5\n  CNTSTUID ST004D01T CNT       ESCS PV1MATH\n     <dbl> <fct>     <fct>    <dbl>   <dbl>\n1   800251 Male      Albania  0.675    490.\n2   800402 Male      Albania -0.757    462.\n3   801902 Female    Albania -2.51     407.\n4   803546 Male      Albania -3.18     483.\n5   804776 Male      Albania -1.76     460.\n\n\n\n\n\n\n\n\nNote\n\n\n\nVectors are data structures that bring together one or more data elements of the same datatype. E.g. we might have a numeric vector recording the grades of a class, or a character vector storing the gender of a set of students. To define a vector we use c(item, item, ...), where c stands for combine. Vectors are very important to R, even declaring a single object, x <- 6, is creating a vector of size one. To find out more about vectors see: Section 2.5.1\n\n\nWe can find out some general information about the table we have loaded. nrow and ncol tell you about the dimensions of the table\n\nnrow(PISA_2018)  # how many rows are in the results table\n\n[1] 612004\n\nncol(PISA_2018)  # how many columns are in the results table\n\n[1] 204\n\n\nIf we want to know the names of the columns we can use the names() command that returns a vector. This can be a little confusing as it’ll return the names used in the dataframe, which can be hard to interpret, e.g. ST004D01T is PISA’s way of encoding gender. You might find the labels in the view of the table available through view(PISA_2018) and the Environment panel easier to navigate:\n\nnames(PISA_2018) # the column names of a table\n\n [1] \"CNT\"          \"OECD\"         \"ISCEDL\"       \"ISCEDD\"       \"ISCEDO\"      \n [6] \"PROGN\"        \"WVARSTRR\"     \"COBN_F\"       \"COBN_M\"       \"COBN_S\"      \n[11] \"GRADE\"        \"SUBNATIO\"     \"STRATUM\"      \"ESCS\"         \"LANGN\"       \n[16] \"LMINS\"        \"OCOD1\"        \"OCOD2\"        \"REPEAT\"       \"CNTRYID\"     \n[21] \"CNTSCHID\"     \"CNTSTUID\"     \"NatCen\"       \"ADMINMODE\"    \"LANGTEST_QQQ\"\n[26] \"LANGTEST_COG\" \"BOOKID\"       \"ST001D01T\"    \"ST003D02T\"    \"ST003D03T\"   \n[31] \"ST004D01T\"    \"ST005Q01TA\"   \"ST007Q01TA\"   \"ST011Q01TA\"   \"ST011Q02TA\"  \n[36] \"ST011Q03TA\"   \"ST011Q04TA\"   \"ST011Q05TA\"   \"ST011Q06TA\"   \"ST011Q07TA\"  \n [ reached getOption(\"max.print\") -- omitted 164 entries ]\n\n\nAs mentioned, the columns in the tables are very much like a collection of vectors, to access these columns we can put a $ [dollar sign] after the name of a table. This allows us to see all the columns that table has, using the up and down arrows to select, press the Tab key to complete:\n\n\nPISA_2018$ST004D01T\n\n [1] Male   Male   Female Male   Male   Female Female Male   Female Female\n[11] Female Female Female Female Male   Female Male   Male   Male   Male  \n[21] Male   Male   Female Male   Male   Female Male   Female Male   Male  \n[31] Female Female Female Female Female Male   Male   Male   Male   Female\n [ reached getOption(\"max.print\") -- omitted 611964 entries ]\nattr(,\"label\")\n[1] Student (Standardized) Gender\nLevels: Female Male Valid Skip Not Applicable Invalid No Response\n\n\n\n\n\nWe can apply functions to the returned column/vector, for example: sum, mean, median, max, min, sd, round, unique, summary, length. To find all the different/unique values contained in a column we can write:\n\nunique(PISA_2018$CNT) # the unique values in this column\n\n [1] Albania                United Arab Emirates   Argentina             \n [4] Australia              Austria                Belgium               \n [7] Bulgaria               Bosnia and Herzegovina Belarus               \n[10] Brazil                 Brunei Darussalam      Canada                \n[13] Switzerland            Chile                  Colombia              \n[16] Costa Rica             Czech Republic         Germany               \n[19] Denmark                Dominican Republic     Spain                 \n[22] Estonia                Finland                France                \n[25] United Kingdom         Georgia                Greece                \n[28] Hong Kong              Croatia                Hungary               \n[31] Indonesia              Ireland                Iceland               \n[34] Israel                 Italy                  Jordan                \n[37] Japan                  Kazakhstan             Korea                 \n[40] Kosovo                \n [ reached getOption(\"max.print\") -- omitted 40 entries ]\n82 Levels: Albania United Arab Emirates Argentina Australia Austria ... Vietnam\n\n\nWe can also combine commands, with length(<vector>) telling you how many items are in the unique(PISA_2018$CNT) command\n\nlength(unique(PISA_2018$CNT)) # tells you the number of countries in PISA 2018\n\n[1] 80\n\n\nYou might meet errors when you try and run some of the commands because a field has missing data, recorded as NA. In the case below it doesn’t know what to do with the NA values in PV1MATH, so it gives up and returns NA:\n\nmax(PISA_2018$ESCS) # max poverty value for all students\n\n[1] NA\n\n\nYou can see the NAs by just loking at this column:\n\nPISA_2018$ESCS # NAs present in data\n\n [1]  0.6747 -0.7566 -2.5112 -3.1843 -1.7557 -1.4855      NA -3.2481 -1.7174\n[10]      NA -1.5617 -1.9952 -1.6790 -1.1337      NA      NA -1.0919 -1.2391\n[19] -0.1641 -0.4510 -0.9622 -0.8303 -1.8772 -1.2963 -1.4784 -2.3759 -0.8440\n[28] -1.2251      NA -2.4655 -1.2018 -0.4426 -1.4634 -2.1813 -1.9087 -1.7194\n[37] -2.7486 -2.0457 -1.8321 -1.8647\n [ reached getOption(\"max.print\") -- omitted 611964 entries ]\nattr(,\"label\")\n[1] \"Index of economic, social and cultural status\"\n\n\nTo get around this you can tell R to remove/ignore the NA values when performing maths calculations:\n\nmax(PISA_2018$ESCS, na.rm = TRUE) # max maths grade for all students\n\n[1] 4.2051\n\n\n\n\n\n\n\n\nTip\n\n\n\nR’s inbuilt mode function doesn’t calculate the mathematical mode, instead it tells you what type of data you are dealing with. You can work out the mode of data by using the modeest package:\n\nlibrary(modeest)\nmlv(PISA_2018$PV1MATH, method = \"mfv\", na.rm = TRUE)\n\n[1] 455.767\n\n\nthere is more discussion on how to use modes in R here\n\n\nCalculations might also be upset when you try to perform maths on a column that is stored as another datatype. For example if you wanted to work out the mean common number of minutes spent learning the language that the PISA test was sat in, e.g. number of hours of weekly English lessons in England:\n\nmean(PISA_2018$LMINS)\n\nWarning in mean.default(PISA_2018$LMINS): argument is not numeric or logical:\nreturning NA\n\n\n[1] NA\n\n\nLooking at the structure of this column, we can see it is stored as a factor, not as a numeric\n\nstr(PISA_2018$LMINS)\n\n Factor w/ 336 levels \"0\",\"10\",\"15\",..: 38 81 38 38 150 66 NA NA 81 NA ...\n - attr(*, \"label\")= chr \"Learning time (minutes per week) - <test language>\"\n\n\nSo we need to change the type of the column to make it work with the mean command, changing it to as.numeric(<column>) for the calculation, for more details on datatypes, see Section 2.5.\n\n# this isn't ideal for proper analysis as you will need to remove all the \"No Response\" data\nmean(as.numeric(PISA_2018$LMINS), na.rm = TRUE)\n\n[1] 91.22474\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo get a good overview of what a table contains, you can use the str(<table_name>) and summary(<table_name>) commands."
  },
  {
    "objectID": "index.html#sec-factors",
    "href": "index.html#sec-factors",
    "title": "Questions and Answers",
    "section": "\n2.9 Factors and statistical data types",
    "text": "2.9 Factors and statistical data types\nThe types of variable will heavily influence what statistical analysis you can perform. R is there to help by assigning datatypes to each field. We have different sorts of data that can be stored:\n\n\n\nCategorical - data that can be divided into groups or categories\n\n\nNominal - categorical data where the order isn’t important, e.g. gender, or colours\n\nOrdinal - categorical data that may have order or ranking, e.g. exam grades (A, B, C, D) or lickert scales (strongly agree, agree, disgaree, strongly disagree)\n\n\n\nNumeric - data that consists of numbers\n\n\nContinuous - numeric data that can take any value within a given range, e.g. height (178cm, 134.54cm)\n\nDiscrete - numeric data that can take only certain values within a range, e.g. number of children in a family (0,1,2,3,4,5)\n\n\n\nR can support these by changing the datatype as we saw earlier to a numeric type:\n\nPISA_2018 %>% \n  summarise(lmins_mean = \n              mean(as.numeric(LMINS), na.rm=TRUE))\n\n# A tibble: 1 × 1\n  lmins_mean\n       <dbl>\n1       91.2\n\n\nBut here we are going to look at how R handles factors. Factors have two parts, levels and codes. levels are what you see when you view a table column, codes are an underlying order to the data. Factors allow you to store data that has a known set of values taht you might want to display in an order other than alphabetical. For example, if we look at the month field ST003D02T using the levels(<field>) command:\n\nlevels(PISA_2018$ST003D02T)\n\n [1] \"January\"        \"February\"       \"March\"          \"April\"         \n [5] \"May\"            \"June\"           \"July\"           \"August\"        \n [9] \"September\"      \"October\"        \"November\"       \"December\"      \n[13] \"Valid Skip\"     \"Not Applicable\" \"Invalid\"        \"No Response\"   \n\n\nWe can see that the months of the year are there along with other possible levels. With this particular dataset, we have set all other levels as NA.\nCodes are the underlying numbers/order for each level, in this case 1 = January, 2 = February, etc.\n\nas.numeric(PISA_2018$ST003D02T)\n\n [1]  2  7  4  4  3  2  7  8  3  7 12  1 12  6  3 12  3  6  8 12  7  8  8  9 10\n[26] 11  6  4  9  4  1  2  9  5 12  5  1  2 10  9\n [ reached getOption(\"max.print\") -- omitted 611964 entries ]\n\n\nHow can this be useful? A good example is how plots are made, they will use the codes to give an order to the display of columns, in the plot below, February (2) comes before March (3), even though there were more students born in March:\n\ngrph_data <- PISA_2018 %>% \n         group_by(ST003D02T) %>% \n         summarise(n=n())\n\nggplot(data=grph_data, aes(x=ST003D02T, y=n)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nTo re-order the columns to match the number of students, we can either try to do this manually, which is rather cumbersome:\n\nmy_levels <- c(\"July\", \"September\", \"January\", \"March\", \"February\",\"April\", \"May\", \"June\", \"August\", \"October\", \"November\", \"December\", \"Valid Skip\", \"Not Applicable\", \"Invalid\", \"No Response\")\n\ngrph_data$ST003D02T <- factor(grph_data$ST003D02T, levels=my_levels)\n\nggplot(data=grph_data, aes(x=ST003D02T, y=n)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nOr get R to do this for us:\n\n# get the levels in order and pull/create a vector of them\nmy_levels <- grph_data %>% arrange(desc(n)) %>% pull(ST003D02T)\n\n# reassign the re-ordered levels to the dataframe column\ngrph_data$ST003D02T <- factor(grph_data$ST003D02T, levels=my_levels)\n\nggplot(data=grph_data, aes(x=ST003D02T, y=n)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nTo learn a lot more about factors, see Hadleys chapter"
  },
  {
    "objectID": "index.html#piping",
    "href": "index.html#piping",
    "title": "Questions and Answers",
    "section": "\n2.10 Piping",
    "text": "2.10 Piping\nPiping allows us to break down complex tasks into manageable chunks that can be written and tested one after another. There are several powerful commands in the tidyverse as part of the dplyr package that can help us group, filter, select, mutate and summarise datasets. With this small set of commands we can use piping to convert massive datasets into simple and useful results.\nUsing the pipe %>% command, we can feed the results from one command into the next command making for reusable and easy to read code.\n\n\nhow piping works\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe pipe command we are using %>% is from the magrittr package which is installed alongside the tidyverse. Recently R introduced another pipe |> which offers very similar functionality and tutorials online might use either. The examples below use the %>% pipe.\n\n\nLet’s look at an example of using the pipe on the PISA_2018 table to calculate the best performing OECD countries for maths by gender:\n\nPISA_2018 %>% \n  filter(OECD == \"Yes\") %>%\n  group_by(CNT, ST004D01T) %>% \n  summarise(mean_maths = mean(PV1MATH, na.rm=TRUE),\n            sd_maths = sd(PV1MATH, na.rm=TRUE),\n            students = n()) %>%\n  filter(!is.na(ST004D01T)) %>%\n  arrange(desc(mean_maths))\n\n`summarise()` has grouped output by 'CNT'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 74 × 5\n# Groups:   CNT [37]\n   CNT            ST004D01T mean_maths sd_maths students\n   <fct>          <fct>          <dbl>    <dbl>    <int>\n 1 Japan          Male            533.     90.5     2989\n 2 Korea          Male            530.    102.      3459\n 3 Estonia        Male            528.     85.0     2665\n 4 Japan          Female          523.     82.2     3120\n 5 Korea          Female          523.     96.0     3191\n 6 Switzerland    Male            520.     92.7     3033\n 7 Estonia        Female          519.     76.0     2651\n 8 Czech Republic Male            518.     98.0     3501\n 9 Belgium        Male            518.     95.9     4204\n10 Poland         Male            517.     91.8     2768\n# … with 64 more rows\n\n\n\nline 1 passes the whole PISA_2018 dataset and pipes it into the next line %>%\n\nline 2 filters out any results that are from non-OECD countries by finding all the rows where OECD equals == “Yes”, this is then piped to the next line\nline 3 groups the data by country CNT and by student gender ST004D01T, this is then piped to the next line\nline 4-6 the summarise command performs a calculation on the country and gender groupings returning three new columns, each command on a new line and separated by a comma: the mean value for maths mean_maths, the standard deviation sd_maths and a column telling us how many students were in each grouping using the n() which returns the number of rows in a group. These new columns and the grouping columns are then piped to the next line\nline 7 filters out any gender ST004D01T that is NA. First is finds all the students that have NA as their gender by using is.na(ST004D01T), then is NOTs/flips the result using the exclamation mark !, giving those students who don’t have their gender set to NA. The filtered data is then piped to the next line\nline 8, finally we arrange / sort the results in descending order by the mean_maths column. The default for arrange is ascending order, leave out the desc(  ) for the numbers to be ordered in the opposite way.\n\nMales get a slightly better maths score than Females for this PV1MATH score, other scores are available, please read Section 13.5.1 to find out more about the limitations of using this value.\n\n\n\n\n\n\nNote\n\n\n\nwe met the assignment command earlier <-. Within the tidyverse commands we use the equals sign instead =.\n\n\nThe commands we have just used come from a package within the tidyverse called dplyr, let’s take a look at what they do:\n\n\n\n\n\n\n\ncommand\npurpose\nexample\n\n\n\nselect\nreduce the dataframe to the fields that you specify (and any other grouping fields you might be using)\nselect(<field>, <field>, <field>)\n\n\nfilter\nget rid of rows that don’t meet one or more comparisons\nfilter(<field> <comparison>)\n\n\ngroup\n\ngroup_by(<field>, <field>))\n\n\nmutate\nadd new fields or change current value in current fields\nmutate(<new_field> = <field> / 2)\n\n\nsummarise\n\nsummarise(<new_field> = max(<field>))\n\n\narrange\n\narrange(desc(<field>))\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want to explore more of the functions of dplyr, take a look at the helpsheet\n\n\n\nAdjust the code above to find out the lowest performing countries for reading PV1READ by gender that are not in the OECD\n\nanswerPISA_2018 %>% \n  filter(OECD == \"No\") %>%\n  group_by(CNT, ST004D01T) %>% \n  summarise(mean_read = mean(PV1READ, na.rm=TRUE),\n            sd_read = sd(PV1READ, na.rm=TRUE),\n            students = n()) %>%\n  filter(!is.na(ST004D01T)) %>%\n  arrange(mean_read)\n\n\n\n\n2.10.1 select\nThe PISA_2018 dataset has far too many fields, to reduce the number of fields to focus on just a few of them we can use select\n\nPISA_2018 %>% select(CNT,ESCS, ST004D01T, ST003D02T)\n\n# A tibble: 612,004 × 4\n   CNT       ESCS ST004D01T ST003D02T\n   <fct>    <dbl> <fct>     <fct>    \n 1 Albania  0.675 Male      February \n 2 Albania -0.757 Male      July     \n 3 Albania -2.51  Female    April    \n 4 Albania -3.18  Male      April    \n 5 Albania -1.76  Male      March    \n 6 Albania -1.49  Female    February \n 7 Albania NA     Female    July     \n 8 Albania -3.25  Male      August   \n 9 Albania -1.72  Female    March    \n10 Albania NA     Female    July     \n# … with 611,994 more rows\n\n\nYou might also be in the situation where you want to select everything but one or two fields, you can do this with the negative signal -:\n\nPISA_2018 %>% select(-CNT, -OECD)\n\n# A tibble: 612,004 × 202\n   ISCEDL ISCEDD ISCEDO PROGN WVARS…¹ COBN_F COBN_M COBN_S GRADE SUBNA…² STRATUM\n   <fct>  <fct>  <fct>  <fct>   <dbl> <fct>  <fct>  <fct>  <fct> <fct>   <fct>  \n 1 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 2 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 3 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 4 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 5 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 6 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 7 ISCED… C      Vocat… Alba…       3 Missi… Missi… Missi… 0     Albania ALB - …\n 8 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n 9 ISCED… C      Vocat… Alba…       3 Alban… Alban… Alban… 0     Albania ALB - …\n10 ISCED… C      Vocat… Alba…       3 Missi… Missi… Missi… 0     Albania ALB - …\n# … with 611,994 more rows, 191 more variables: ESCS <dbl>, LANGN <fct>,\n#   LMINS <fct>, OCOD1 <fct>, OCOD2 <fct>, REPEAT <fct>, CNTRYID <fct>,\n#   CNTSCHID <dbl>, CNTSTUID <dbl>, NatCen <fct>, ADMINMODE <fct>,\n#   LANGTEST_QQQ <fct>, LANGTEST_COG <fct>, BOOKID <fct>, ST001D01T <fct>,\n#   ST003D02T <fct>, ST003D03T <fct>, ST004D01T <fct>, ST005Q01TA <fct>,\n#   ST007Q01TA <fct>, ST011Q01TA <fct>, ST011Q02TA <fct>, ST011Q03TA <fct>,\n#   ST011Q04TA <fct>, ST011Q05TA <fct>, ST011Q06TA <fct>, ST011Q07TA <fct>, …\n\n\nYou might find that you have a vector of column names that you want to select, to do this, we can use the any_of command:\n\nmy_fields <- c(\"CNTSTUID\", \"CNTSCHID\", \"ST004D01T\")\nPISA_2018 %>% select(any_of(my_fields))\n\n# A tibble: 612,004 × 3\n   CNTSTUID CNTSCHID ST004D01T\n      <dbl>    <dbl> <fct>    \n 1   800251   800002 Male     \n 2   800402   800002 Male     \n 3   801902   800002 Female   \n 4   803546   800002 Male     \n 5   804776   800002 Male     \n 6   804825   800002 Female   \n 7   804983   800002 Female   \n 8   805287   800002 Male     \n 9   805601   800002 Female   \n10   806295   800002 Female   \n# … with 611,994 more rows\n\n\nWith hundreds of fields, you might want to focus on fields whose names match a certain pattern, to do this you can use starts_with, ends_with, contains:\n\nPISA_2018 %>% select(ends_with(\"NA\"))\n\n# A tibble: 612,004 × 19\n   ST011Q16NA ST012Q05NA ST012…¹ ST012…² ST125…³ ST060…⁴ ST061…⁵ IC009…⁶ IC009…⁷\n   <fct>      <fct>      <fct>   <fct>   <fct>     <dbl> <fct>   <fct>   <fct>  \n 1 Yes        <NA>       One     One     6 year…      31 45      Yes, a… No     \n 2 Yes        Three or … One     None    4 years      37 45      No      Yes, b…\n 3 No         One        None    None    4 years      NA 45      Yes, a… Yes, a…\n 4 No         <NA>       None    One     1 year…      31 45      Yes, a… No     \n 5 No         One        One     None    3 years      80 100     Yes, a… Yes, a…\n 6 No         Three or … One     None    6 year…      24 25      Yes, a… Yes, a…\n 7 <NA>       <NA>       <NA>    <NA>    <NA>         NA <NA>    <NA>    <NA>   \n 8 No         None       None    None    1 year…      NA 45      <NA>    <NA>   \n 9 Yes        Three or … One     One     4 years      36 45      Yes, a… Yes, a…\n10 <NA>       <NA>       <NA>    <NA>    <NA>         NA <NA>    <NA>    <NA>   \n# … with 611,994 more rows, 10 more variables: IC009Q07NA <fct>,\n#   IC009Q10NA <fct>, IC009Q11NA <fct>, IC008Q07NA <fct>, IC008Q13NA <fct>,\n#   IC010Q02NA <fct>, IC010Q05NA <fct>, IC010Q06NA <fct>, IC010Q09NA <fct>,\n#   IC010Q10NA <fct>, and abbreviated variable names ¹​ST012Q06NA, ²​ST012Q09NA,\n#   ³​ST125Q01NA, ⁴​ST060Q01NA, ⁵​ST061Q01NA, ⁶​IC009Q05NA, ⁷​IC009Q06NA\n\n\n\n\nSpot the three errors with the following select statement\n\n\nPISA_2018 \n  select(CNT BELONG) %>%\n\n\nanswerPISA_2018 %>%  #1 missing pipe\n  select(CNT BELONG) #2 no comma between column names, #3 stray pipe on end\n\n\n\nWrite a select statement to display the month and year of birth and the gender of each student.\n\n\nanswerPISA_2018 %>% \n  select(ST003D02T, ST003D03T, ST004D01T)\n\n\n\nWrite a select statement to show all the fields that are to do with digital skills, e.g. IC150Q01HA\n\n\n\nanswerPISA_2018 %>% \n  select(starts_with(\"IC15\"))\n\n\n\n[EXTENSION] Adjust the answer to Q3 so that you select the gender and the ID of each student\n\n\nanswerPISA_2018 %>% \n  select(\"CNTSTUID\",\"ST004D01T\", starts_with(\"IC15\"))\n\n\n\n\n2.10.2 filter\nNot only does the PISA_2018 dataset have a huge number of columns, it has hundred of thousands of rows. We want to filter this down to the students that we are interested in, i.e. filter out data that isn’t useful for our analysis. If we only wanted the results that were boys, we could do the following:\n\nPISA_2018 %>% \n  select(CNT,ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\")\n\n# A tibble: 307,044 × 5\n   CNT       ESCS ST004D01T ST003D02T PV1MATH\n   <fct>    <dbl> <fct>     <fct>       <dbl>\n 1 Albania  0.675 Male      February     490.\n 2 Albania -0.757 Male      July         462.\n 3 Albania -3.18  Male      April        483.\n 4 Albania -1.76  Male      March        460.\n 5 Albania -3.25  Male      August       441.\n 6 Albania NA     Male      March        280.\n 7 Albania -1.09  Male      March        523.\n 8 Albania -1.24  Male      June         314.\n 9 Albania -0.164 Male      August       428.\n10 Albania -0.451 Male      December     369.\n# … with 307,034 more rows\n\n\nWe can combine filter commands to look for Males born in September and where the PV1MATH figure is greater than 750. We can list multiple criteria in the filter by separating the criteria with commas, using commas mean that all of these criteria need to be true for a row to be returned. A comma in a filter is the equivalent of an AND, :\n\nPISA_2018 %>% \n  select(CNT,ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\",\n         ST003D02T == \"September\",\n         PV1MATH > 750)\n\n# A tibble: 56 × 5\n   CNT                    ESCS ST004D01T ST003D02T PV1MATH\n   <fct>                 <dbl> <fct>     <fct>       <dbl>\n 1 United Arab Emirates  0.861 Male      September    760.\n 2 Belgium               0.887 Male      September    751.\n 3 Bulgaria             -0.160 Male      September    752.\n 4 Canada                1.38  Male      September    751.\n 5 Canada                1.16  Male      September    760.\n 6 Canada                0.760 Male      September    770.\n 7 Switzerland           0.814 Male      September    783.\n 8 Germany               0.740 Male      September    762.\n 9 Spain                 1.46  Male      September    787.\n10 Estonia               0.897 Male      September    752.\n# … with 46 more rows\n\n\nyou can also write it as an ampersand &\n\nPISA_2018 %>% \n  select(CNT,ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\" &\n         ST003D02T == \"September\" &\n         PV1MATH > 750)\n\n\n\n\n\n\n\nImportant\n\n\n\nRemember to include the == sign when looking to filter on equality; !=, >=, < etc also work.\nRemember matching is case sensitive, “june” != “June”\n\n\nRather than just looking at September born students, we want to find all the students born in the Autumn term. But if we add a couple more criteria on ST003D02T nothing is returned! The reason is R is looking for inidividual students born in September AND October AND November AND December. As a student can only have one birth month there are no students that meet this criteria. We need to use OR :\n\nPISA_2018 %>% \n  select(CNT,ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\",\n         ST003D02T == \"September\",\n         ST003D02T == \"October\",\n         ST003D02T == \"November\",\n         ST003D02T == \"December\",\n         PV1MATH > 750)\n\n# A tibble: 0 × 5\n# … with 5 variables: CNT <fct>, ESCS <dbl>, ST004D01T <fct>, ST003D02T <fct>,\n#   PV1MATH <dbl>\n\n\nTo create an OR in a filter we use the bar | character, the below looks for all students who are “Male” AND were born in “September” OR “October” OR “November” OR “December”, AND have a PV1MATH > 750.\n\nPISA_2018 %>% \n  select(CNT,ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\",\n         (ST003D02T == \"September\" | ST003D02T == \"October\" | ST003D02T == \"November\" | ST003D02T == \"December\"),\n         PV1MATH > 750)\n\n# A tibble: 175 × 5\n   CNT                     ESCS ST004D01T ST003D02T PV1MATH\n   <fct>                  <dbl> <fct>     <fct>       <dbl>\n 1 Albania               0.539  Male      October      789.\n 2 United Arab Emirates  0.861  Male      September    760.\n 3 United Arab Emirates  0.813  Male      October      753.\n 4 United Arab Emirates  0.953  Male      November     766.\n 5 United Arab Emirates  0.930  Male      November     773.\n 6 United Arab Emirates  1.44   Male      October      752.\n 7 Australia             1.73   Male      December     756.\n 8 Australia            -0.0537 Male      October      827.\n 9 Australia             1.18   Male      November     758.\n10 Australia             1.13   Male      October      757.\n# … with 165 more rows\n\n\nIt’s neater, maybe, to use the %in% command, which checks to see if the value in a column is present in a vector, this can mimic the OR command:\n\nPISA_2018 %>% \n  select(CNT, ESCS, ST004D01T, ST003D02T, PV1MATH) %>%\n  filter(ST004D01T == \"Male\",\n         ST003D02T %in% c(\"September\", \"October\", \"November\", \"December\"),\n         PV1MATH > 750)\n\n\n\n\n\n\n\nTip\n\n\n\nWhen building filters you need to know the range of values that a column can take, we can do this in several ways:\n\n# show the possible levels\nlevels(PISA_2018$ST013Q01TA)\n\n [1] \"0-10 books\"          \"11-25 books\"         \"26-100 books\"       \n [4] \"101-200 books\"       \"201-500 books\"       \"More than 500 books\"\n [7] \"Valid Skip\"          \"Not Applicable\"      \"Invalid\"            \n[10] \"No Response\"        \n\n# show the actual unique values in a field\nunique(PISA_2018$ST013Q01TA)\n\n[1] 0-10 books          11-25 books         <NA>               \n[4] 26-100 books        101-200 books       More than 500 books\n[7] 201-500 books      \n10 Levels: 0-10 books 11-25 books 26-100 books 101-200 books ... No Response\n\n# You might also want to read the label of a field\nattr(PISA_2018$ST013Q01TA, \"label\")\n\n[1] \"How many books are there in your home?\"\n\n\n\n\n\n\nSpot the three errors with the following select statement\n\n\nPISA_2018 %>% \n  select(CNT) %>%\n  filter(CNT in c(\"France\", \"belgium\")\n         ESCS < 0)\n\n\nanswerPISA_2018 %>% \n  select(CNT, ESCS) %>% #1 you have ESCS in the filter, it needs to be in the select as well\n  filter(CNT %in% c(\"France\", \"Belgium\"), #2 Belgium needs a capital letter\n                                          #3 the %in% command needs percentages\n                                          #4 you need a comma (or &) at the end of the line\n         ESCS < 0)\n\n\n\nWrite a filter to create a dataframe for the number of Female students with reading PV1READ scores lower than 400 in the “United Kingdom”, store the result as read_low_female, repeat but for Male students and store as read_low_male. Use nrow() to work out if there are more males or females with a low reading score in the UK\n\n\nanswerread_low_female <- PISA_2018 %>% \n  filter(CNT == \"United Kingdom\",\n         PV1READ < 400,\n         ST004D01T == \"Female\")\n\nread_low_male <- PISA_2018 %>% \n  filter(CNT == \"United Kingdom\",\n         PV1READ < 400,\n         ST004D01T == \"Male\")\n\nnrow(read_low_female)\nnrow(read_low_male)\n\n# You could also pipe the whole dataframe into nrow()\nPISA_2018 %>% \n  filter(CNT == \"United Kingdom\",\n         PV1READ < 400,\n         ST004D01T == \"Female\") %>% \n  nrow()\n\n\n\nHow many students in the United Kingdom had no television ST012Q01TA OR no connection to the internet ST011Q06TA.\n\n\nanswerPISA_2018 %>% filter(CNT == \"United Kingdom\", \n                     ST011Q06TA == \"No\" |\n                     ST012Q01TA == \"None\")\n\n\n\nWhich countr[y|ies] had students with NA for Gender?\n\n\nanswerPISA_2018 %>% \n  filter(is.na(ST004D01T)) %>%\n  select(CNT)\n\n\n\n\n2.10.3 renaming columns\nVery often when dealing with datasets such as PISA or TIMSS, the column names can be very confusing without a reference key, e.g. ST004D01T, BCBG10B and BCBG11. To rename columns in the tidyverse we use the rename(<new_name> = <old_name>) command. For example, if you wanted to rename the rather confusing student column for gender, also known as ST004D01T, and the column for having a dictionary at home, also known as ST011Q12TA, you could use:\n\nPISA_2018 %>%\n  rename(gender = ST004D01T,\n         dictionary = ST011Q12TA) %>%\n  select(CNT, gender, dictionary) %>% summary()\n\n                   CNT                    gender                dictionary    \n Spain               : 35943   Female        :304958   Yes           :524311  \n Canada              : 22653   Male          :307044   No            : 66730  \n Kazakhstan          : 19507   Valid Skip    :     0   Valid Skip    :     0  \n United Arab Emirates: 19277   Not Applicable:     0   Not Applicable:     0  \n Australia           : 14273   Invalid       :     0   Invalid       :     0  \n Qatar               : 13828   No Response   :     0   No Response   :     0  \n (Other)             :486523   NA's          :     2   NA's          : 20963  \n\n\nIf you want to change the name of the column so that it stays when you need to perform another calculation, remember to assign the renamed dataframe back to the original dataframe:\n\nPISA_2018 <- PISA_2018 %>%\n    rename(gender = ST004D01T,\n           dictionary = ST011Q12TA)\n\n\n2.10.4 group_by and summarise\nnumbers of students without internet in each country, by poverty indicator\n\nPISA_2018 \n\n# A tibble: 612,004 × 204\n   CNT     OECD  ISCEDL   ISCEDD ISCEDO PROGN WVARS…¹ COBN_F COBN_M COBN_S GRADE\n   <fct>   <fct> <fct>    <fct>  <fct>  <fct>   <dbl> <fct>  <fct>  <fct>  <fct>\n 1 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 2 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 3 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 4 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 5 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 6 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 7 Albania No    ISCED l… C      Vocat… Alba…       3 Missi… Missi… Missi… 0    \n 8 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n 9 Albania No    ISCED l… C      Vocat… Alba…       3 Alban… Alban… Alban… 0    \n10 Albania No    ISCED l… C      Vocat… Alba…       3 Missi… Missi… Missi… 0    \n# … with 611,994 more rows, 193 more variables: SUBNATIO <fct>, STRATUM <fct>,\n#   ESCS <dbl>, LANGN <fct>, LMINS <fct>, OCOD1 <fct>, OCOD2 <fct>,\n#   REPEAT <fct>, CNTRYID <fct>, CNTSCHID <dbl>, CNTSTUID <dbl>, NatCen <fct>,\n#   ADMINMODE <fct>, LANGTEST_QQQ <fct>, LANGTEST_COG <fct>, BOOKID <fct>,\n#   ST001D01T <fct>, ST003D02T <fct>, ST003D03T <fct>, ST004D01T <fct>,\n#   ST005Q01TA <fct>, ST007Q01TA <fct>, ST011Q01TA <fct>, ST011Q02TA <fct>,\n#   ST011Q03TA <fct>, ST011Q04TA <fct>, ST011Q05TA <fct>, ST011Q06TA <fct>, …\n\n\nWe know that the evidence strongly indicates that repeating a year is not good for student progress, but how do countries around the world differ in terms of the percentage of their students who repeat a year? Which countries have the most students repeating a year?\n\nPISA_2018 %>%\n  filter(!is.na(REPEAT)) %>%\n  group_by(CNT) %>%\n  mutate(total = n()) %>%\n  group_by(CNT, REPEAT) %>%\n  summarise(n = n(),\n            per = n / max(total))\n\n`summarise()` has grouped output by 'CNT'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 154 × 4\n# Groups:   CNT [77]\n   CNT                  REPEAT                      n    per\n   <fct>                <fct>                   <int>  <dbl>\n 1 Albania              Did not repeat a  grade  6076 0.970 \n 2 Albania              Repeated a  grade         190 0.0303\n 3 United Arab Emirates Did not repeat a  grade 16257 0.874 \n 4 United Arab Emirates Repeated a  grade        2342 0.126 \n 5 Argentina            Did not repeat a  grade  9040 0.773 \n 6 Argentina            Repeated a  grade        2662 0.227 \n 7 Australia            Did not repeat a  grade 12026 0.937 \n 8 Australia            Repeated a  grade         804 0.0627\n 9 Austria              Did not repeat a  grade  5771 0.867 \n10 Austria              Repeated a  grade         889 0.133 \n# … with 144 more rows\n\n\nESCS linked to REPEAT\nmax, min, mean, mode na.rm = TRUE\n\n2.10.5 mutate\n\nPISA_2018 %>%\n  mutate(PV1_total = PV1MATH + PV1SCIE + PV1READ) %>%\n  select(CNT, ESCS, PV1_total) %>%\n  mutate(PV1_mean = PV1_total/3)\n\n# A tibble: 612,004 × 4\n   CNT       ESCS PV1_total PV1_mean\n   <fct>    <dbl>     <dbl>    <dbl>\n 1 Albania  0.675     1311.     437.\n 2 Albania -0.757     1319.     440.\n 3 Albania -2.51      1158.     386.\n 4 Albania -3.18      1424.     475.\n 5 Albania -1.76      1094.     365.\n 6 Albania -1.49      1004.     335.\n 7 Albania NA         1311.     437.\n 8 Albania -3.25      1104.     368.\n 9 Albania -1.72      1268.     423.\n10 Albania NA         1213.     404.\n# … with 611,994 more rows\n\n\n\nPISA_2018 %>%\n  mutate(PV1READ_high = ifelse(PV1READ > 600, TRUE, FALSE)) %>%\n  select(CNT, ESCS, PV1READ, PV1READ_high)\n\n# A tibble: 612,004 × 4\n   CNT       ESCS PV1READ PV1READ_high\n   <fct>    <dbl>   <dbl> <lgl>       \n 1 Albania  0.675    376. FALSE       \n 2 Albania -0.757    434. FALSE       \n 3 Albania -2.51     359. FALSE       \n 4 Albania -3.18     425. FALSE       \n 5 Albania -1.76     306. FALSE       \n 6 Albania -1.49     352. FALSE       \n 7 Albania NA        413. FALSE       \n 8 Albania -3.25     271. FALSE       \n 9 Albania -1.72     373. FALSE       \n10 Albania NA        412. FALSE       \n# … with 611,994 more rows\n\n\nREPEAT - repeat a grade\npaste ifelse\n\n2.10.6 arrange\nThe results returned by pipes can be huge, so it’s a good idea to store them in objects and explore them in the Environment window where you can sort and search within the output. There might also be times when you want to order/arrange the outputs in a particular way. We can do this quite easily in the tidyverse by using the arrange(<column_name>) function. In the example below we are arranging the output by the descending value of the #####\n\n2.10.7 unique / distinct\n\n2.10.8 saving data"
  },
  {
    "objectID": "index.html#seminar-questions",
    "href": "index.html#seminar-questions",
    "title": "Questions and Answers",
    "section": "\n2.11 Seminar questions",
    "text": "2.11 Seminar questions\nTo check your understanding of this section you will be attempting to analyse a subset of the TIMSS 2019 Grade 8 school questionnaire. This dataset includes data on school locations, facilities, student demographics and teachers.\nYou can access the cut down TIMSS school dataset as an Excel file here. Load it into an object called TIMSS. For help on loading data see ?@sec-loading:\n\n# How to load TIMSS provider data into R\nlibrary(readxl)\nTIMSS <- read_excel(\"C:/Users/Peter/Google Drive/Kings/R intro/code/TIMSS.xlsx\", \"school_data\")\n\n## OR ##\n\nlibrary(openxlsx)\nTIMSS <- read.xlsx(\"https://drive.google.com/uc?export=download&id=1Sgyw1tLbPGsl4HeyhpNGLhJwTNIriE-B\", \"school_data\")\n\nTake a look at the data using the Environment panel, it’s rather confusing as Excel doesn’t store the full question names. This data originally comes from SPSS and it is possible to load SPSS into R to look at the names, but here we have a cut down dataset and you might want to do some renaming to make the table a little more manageable (see ?@sec-renaming).\nYou can find more details on the question mappings in the TIMSS context document, pages 308-311.\nPlease attempt the following questions:\n\n\nWork out how many schools are in stored in TIMSS for each country CNTRY.\n\n\n\n\n\nOnly for those headteachers that have a masters or equivalent degree qualification (BCBG21B), what is the average number of years they have been in their school (BCBG19)?\n\n\n\n\n\nFor the students in each country: What is the mean and median instructional time in hours, in a typical school day? Can you arrange the results so we find the hardest working country? You need to use BCBG06B, and hint, this column might not be as.numeric() just yet. (You might want to use mutate and Section 2.5 to help you)\n\n\n\n\n\nFor each country, what percentage of their schools have students with a Very high desire to do well in school (BCBG14I)? One of the countries is missing, why?\n\n\n\n\n\nSave the results of one of the above questions using write_csv().\n[EXTENSION] explore the data for “To what degree is each of the following a problem among  students in your school?” BCBG16E - Profanity; BCBG16J - Intimidation or verbal abuse of teachers or staff"
  },
  {
    "objectID": "index.html#sec-graphing",
    "href": "index.html#sec-graphing",
    "title": "Questions and Answers",
    "section": "\n3.1 Introduction to graphing in R",
    "text": "3.1 Introduction to graphing in R\nThe tidyverse includes the incredibly powerful ggplot2 package. This package is pretty much the industry standard for making graphs for publication. ggplot2 is built on the grammar of graphics where you build graphs by specifying underlying attributes and layering geometric objects on top of each other. In the diagram below you can see how a graph is built from geometric objects (the things that are plotted such as points and bars) a scale, and plot annotations (e.g. a key, title etc). You can then apply faceting to the graph to automatically split one graph into multiple plots, allowing you to easily compare different groupings.\n\n\nadapted from A Layered Grammar of Graphics, Wickham, 2010\n\n\nThe basic structure of ggplot code is to combine different graphing elements through the use of the + operator. To demonstrate this, let’s look at the relationship between the percentage of males in a school and the percentage of the school taking computer science:\n\n# wrangle our data\ngraph_data <- PISA_2018 %>% \n  filter(CNT %in% c(\"France\", \"United Kingdom\"))\n\n# display a graph of the results\nggplot(data=graph_data, \n       aes(x=ESCS, y=PV1MATH, colour=ST004D01T)) +\n  geom_point() +\n  geom_smooth(method='lm') +\n  facet_wrap(. ~ CNT) +\n  ggtitle(\"Comparison of poverty and Maths result, by gender and country\")\n\n\n\n\nHopefully you can work out what lines 1-3 do from the previous chapter, let’s focus on the ggplot commands:\n\n6-7 these lines set up the ggplot giving it the table object graph_data as its data input and setting up the aesthetics for the rest of the graph elements using columns from graph_data. The aes(<attribute>, <attribute>, ...) command allows us to specify aesthetic elements of the graph that will change dependent on the dataset we use. x=ESCS and y=PV1MATH define the x and y coordinates, defining aes() inside ggplot() means we will pass down these values to subsequent geometric objects so we don’t have to define these x and y axis items again and again.\n8 using the data and aes values defined on lines 6-7, geom_point uses the x and y values defined on line 19 to draw a point for each school in our dataset. There are lots of different parameters we could give geom_point e.g. specifying size and shape, but here we are content with using the defaults.\n9 we add another geometric object on top of the points, this time we add a line of best fit geom_smooth, again this geometric object uses the values specified on lines 6-7, and we define the method as lm, to calculate a linear model line of best fit.\n10 next we use facet_wrap(. ~ CNT) to create a graph for each group of CNT in the dataset, i.e. a graph for each country defined on line 3.\n11 finally we customise the title of the graph, ggtitle, ready for display."
  },
  {
    "objectID": "index.html#geoms",
    "href": "index.html#geoms",
    "title": "Questions and Answers",
    "section": "\n3.2 Geoms",
    "text": "3.2 Geoms\nThere are about 40 different geometric objects in ggplot, allowing you to create almost any sort of graph. We will be exploring a few of them in detail, but if you want to explore others, please follow some of the links below:\n\n\ngeom_bar for creating bar charts and histograms\n\ngeom_point for plotting single points\n\ngeom_line for connecting points together and showing trends\n\ngeom_text for adding text labels to data points\n\ngeom_boxplot for representing the range of data\n\ngeom_hex for creating heat maps\n\ngeom_map for adding geographic maps\n\ngeom_smooth for adding lines of best fit\n\n\n3.2.1 geom_point\nRather unsurprisingly, geom_point allows us to plot a layer of points using x and y coordinates. The below example shows how we can specify within the ggplot function data=school_plot_data. We then define the aesthetic attributes of the graph, passing the x x=NumberOfBoys and y y=NumberOfGirls values.\n\n# to make things a little faster we are going to focus on open secondary schools\n# plotting 40k+ data points can be slow\nschool_plot_data <- PISA_2018 %>% \n  group_by(OECD, CNT) %>%\n  summarise(mean_maths = mean(PV1MATH),\n            mean_read = mean(PV1READ),\n            sz = n())\n\nggplot(data=school_plot_data, \n       aes(x=mean_maths, y=mean_read)) +\n  geom_point(aes(size=sz, colour=OECD), alpha = 0.6)\n\n\n\n\nTODO: describe the code above\n\n\n\n\n\n\nImportant\n\n\n\nSwitching between the pipes and ggplot can get rather confusing. A very common mistake in using ggplot is to try and link together the geom_ elements with a pipe command %>% rather than the +.\n\n\n\n3.2.2 Questions\n\n\nSpot the three errors in this graph code\n\n\nggplot(adta=diamonds, x=depth, y=price) +\n  geom_point()\n  ggtitle(\"diamond graph\")\n\n\nanswer# 1-data not adta, 2-x and y need to be inside aes\nggplot(data=diamonds, aes(x=depth, y=price)) +\n  geom_point() + #3 missing +\n  ggtitle(\"diamond graph\")\n\n\n\nUsing the PISA_2018 dataset, plot a graph for students from Norway to help you work out whether there is a relationship between poverty ESCS and maths grade PV1MATH. Colour each point with the gender of the student. Give the graph sensible x and y labels (e.g. xlab).\n\n\nanswergraph_data <- PISA_2018 %>% filter(CNT == \"Norway\")\n\nggplot(graph_data,\n       aes(x=ESCS,\n           y=PV1MATH)) +\n  geom_point(aes(colour=ST004D01T)) +\n  xlab(\"\") +\n  ylab(\"\")\n\n\n\n\n\nUsing the PISA_2018 dataset for each country CNT, create a graph to explore how the median of the sense of school belonging BELONG relates to the median of the disciplinary climate in the school DISCLIMA, adjust the colour of each point to reflect the mean wealth of students in each country ESCS.\n\nHINT: You’ll need create a new dataframe with summarised variables for median_belong, median_discipline and mean_wealth.\n\nanswer dataframegraph_data <- PISA_2018 %>%\n  group_by(OECD, CNT) %>%\n  summarise(median_belong = median(BELONG, na.rm=TRUE),\n            median_discipline = median(DISCLIMA, na.rm=TRUE),\n            mean_wealth = mean(ESCS, na.rm=TRUE))\n\n\nHINT: To make your colours stand out more, add + scale_color_gradientn(colours = rainbow(3)) to the end of your plot.\n\nanswer graph# display a graph of the results\nggplot(data=graph_data, \n       aes(x=median_belong, \n           y=median_discipline)) +\n  geom_point(aes(colour = mean_wealth)) + \n  scale_color_gradientn(colours = rainbow(3))\n\n\n\n\n\n\n3.2.3 Recoding data (ifelse)\nOften we want to plot values in groupings that don’t yet exist, for example might want to give all schools over a certain size a different colour from others schools. To do this we need to look at how we can recode values. A common way to recode values is through an if statement:\n\nifelse(<statement(s)>, <value_if_true>, <value_if_false>)\n\nifelse allow us to recode the data. In the example below, we are going to add a new column to the schools table (using mutate) noting whether a school is a grammar school or not. A school is a grammar school if it is not an Independent school and it is selective in its admissions policy, either of these two criteria being false will mean that the school is not a grammar school.\nYou can see how the above logic is is implemented in an R ifelse statement on lines 4-8.\n\nplot_data <- schools %>% \n  filter(Open==\"Open\", \n         Phase==\"Secondary\") %>%\n  mutate(sch_type = \n           ifelse(EstablishmentGroup != \"Independent schools\" & \n                    AdmissionsPolicy==\"Selective\",\n                  \"GRAMMAR\",\n                  \"NOT GRAMMAR\")) %>%\n  arrange(desc(sch_type))\n\n\n4 uses mutate to create a new column in the schools table called sch_type, this will be given the value of the ifelse statement calculation for each line.\n5 - 6 the if statement to be evaluated as either true or false has two parts, separated by the ampersand symbol & instead of the word and (as we have seen above, or is implemented using a bar |).\n7 “GRAMMAR” will be returned if the statements on line 5 and 6 are both TRUE\n\n8 “NOT GRAMMAR” will be returned if the combined statements on line 5 and 6 are FALSE, i.e. else the values on line 5 and 6 are true\n\nAdditionally, on line 9 we arrange the results, which means you can explore the details of the 163 grammar schools using the Environment panel, how you use arrange also changes the order in which the points will be plotted, allowing you to plot the grammar schools on top of other school types to make them stand out.\n\n\n\n\n\n\nTip\n\n\n\nIt’s possible to nest our ifelse statements, for example we might want to give a little more information on the school type:\n\nplot_data <- schools %>% \n  filter(Open==\"Open\") %>%\n  mutate(sch_type = \n           ifelse(grepl(\"Special\", EstablishmentGroup), \"Special\",\n                  ifelse(EstablishmentGroup == \"Independent schools\", \"Independent\",\n                         ifelse(AdmissionsPolicy==\"Selective\", \n                                \"Grammar\", \"Comprehensive\"))))\n\n\n\nNow we have recoded the data to display whether a school is a grammar school or not, we can plot this dataset onto the graph:\n\nggplot(data=plot_data) +\n  geom_point(aes(x=Easting, y=Northing, \n                 size = NumberOfBoys+NumberOfGirls,\n                 colour=sch_type),\n                 alpha=0.4)\n\n\n1 we pass the custom table plot_data to the ggplot command, this means this data will be available in subsequent geom_\n\n2 we define the x and y aestheic values here for the geom_points, we could have done this on line one, but this shows that this can be done separately for each geom_\n\n3 size is also inside aes() and takes the NumberOfBoys+NumberOfGirls as a parameter, i.e. the population of the school will change the size of the points on the graph\n4 colour is also inside aes() and takes the newly coded sch_type values, this means that grammar schools will be a different colour from non-grammar schools\n5 to stop the schools blotting each other out, we set the alpha (transparency) of each point to 0.4. This is done outside the aes as we want all points to have the same transparency.\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you define the colour, size and alpha attributes outside the aes() function, you will hard code the values and they won’t change when your dataset changes. Placing these attributes inside aes allows them to be dynamically changed by your dataset values\n\n\n\n3.2.4 Questions\n\n\nUsing the TIMSS dataset, and only using schools from England, Finland and USA, plot to see how the number of computers BCBG07 is related to the Instruction Affected Resource Shortage (Mathematics) BCBGMRS. colour the points in using the country CNTRY.\n\n\n\n\n\nUsing ifelse, add a column to TIMSS called region, recode “NOR”, “SWE” and “FIN” to be “Nordic” and everyone else “RestOfWorld”.\n\n\n\n\n\nUsing the dataset from Q2, Count the number of schools in each of the two regions and the median number of taught hours BCDGTIHY.\n\n\n\n\n\nUsing the data from Q2 (take a look at the answers if you couldn’t work it out), plot a graph of:\n\nschool’s teaching time per year BCDGTIHY against the behavioural issues that they have BCBGDAS.\n\ncolour the points to show the difference between “Nordic” and “RestOfWorld” schools.\nProvide sensible labels for the x and y axis\nchange the alpha of each point so schools don’t blot each other out\nadd a line of best fit to see how the two axis are related\n\n\n\n\n\n\n\n\n3.2.5 geom_bar\nThe geom_bar function is versatile, allowing the creation of bar, multiple bar, stacked bar charts and histograms. This first example shows how we can use bar charts to represent the quality ratings given by the Office of Standards in Education (Ofsted) to schools in different parts of the country:\n\nplot_schools <- schools %>% \n  filter(Open == \"Open\",\n         Region != \"Not Applicable\",\n         OfstedRating %in% c(\"Outstanding\", \"Good\", \"Requires improvement\", \"Inadequate\"))\n\nggplot(data = plot_schools, \n       aes(x=Region)) + \n  geom_bar()\n\n\n\n1 to 3 gets the schools dataset and filters it to only include schools that are Open, which are in recognised Region.\n4 filters only those rows containing the OfstedRating listed, removing any NA or other values.\n6 to 7 we pass the plot_schools dataset created on lines 1 to 4 to ggplot and set the x axis to the be the Region. Note, we don’t set the y axis, as geom_bar will calculate this for us\n8 we pass the plot_schools and x=Region to geom_bar, which counts the number of rows (schools) in each Region and creates a bar of that height.\n\nThe graph above gives us a feel for the data, but it doesn’t tell us the Ofsted ratings for each Region and the a axis labels are a mess. We need to add a fill to the geom_bar and adjust the theme:\n\nggplot(data = plot_schools, \n       aes(x=Region)) + \n  geom_bar(aes(fill=OfstedRating)) + \n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n3 using the fill attribute aes(fill=OfstedRating) will create a stacked and coloured bar to show the number of schools gaining each OftstedRating in each Region\n\n4 the theme function and axis.text.x adjust the x axis labels, rotating them 90 degrees\n\nWe can now make rough comparisons between the different number of each Ofsted rating. But it remains hard to compare the percentage split. For example the number of Good and Outstanding schools in London is hard to compare with the North East, as the total number of schools in the North East is much smaller than the number of schools in London. Additionally, the order of the bars seems random, we want to have Outstanding at the top and Inadequate at the bottom, not next to each other:\n\nggplot(data = plot_schools, \n       aes(x=Region)) + \n  geom_bar(aes(fill=factor(OfstedRating, \n                           levels = c(\"Outstanding\", \"Good\", \"Requires improvement\", \"Inadequate\"))),\n           position=\"fill\") + \n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  scale_fill_discrete(name = \"Ofsted Ratings\")\n\n\n3 to 4 converts OfstedRating from the character datatype to a factor. Factors allow us to categorise the data we store, limiting the number of values a column can hold, in this case we are limiting it to the levels specified, with the order given to levels specifying the order that this column’s data will be displayed in graphs.\n5 position tells ggplot what to do when a bar on the x axis is made up of multiple elements, in this case position=\"fill\" will take each x axis bar grouping and work out the fractional value of each Ofsted rating for each Region.\n7 when we created the factor on lines 3-4 to pass to the fill command, it also created a really inconvenient title for the graph legend: factor(OfstedRating, levels = c(“Outstanding”, “Good”, “Requires improvement”, “Inadequate”)). scale_fill_discrete let’s us provide a more sensible title for the key.\n\nWe might also want to look at this graph on a Region by Region basis, at the moment it’s very hard to tell if the East Midlands have more schools that are Outstanding, or more schools that Require improvement. To do compare the bars in each x axis group we can use the position command, setting it to position=\"dodge\":\n\nggplot(data = plot_schools, \n       aes(x=Region)) + \n  geom_bar(aes(fill=factor(OfstedRating, \n                           levels = c(\"Outstanding\", \"Good\", \"Requires improvement\", \"Inadequate\"))),\n           position=\"dodge\") + \n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  scale_fill_discrete(name = \"Ofsted Ratings\")\n\n\n3.2.5.1 Raising the bars yourself\nggplot can do a lot of the hard work when putting together bar charts, but there might also be times when you want to use pipes to calculate summary values that you then want plot. That is, you want to specify the heights of the bars yourself. To do this we will specify the y axis in the aes and use stat=\"indentity\" to tell ggplot that’s what we’re doing. Take the example where you want to find the overall percentages of each grade given to the four single sciences in one year (can we say one is harder than another?):\n\nplot_data <- results %>%\n  filter(Description %in% c(\"Physics\", \"Biology\", \"Chemistry\", \"Computer Studies/Computing\"),\n         Qualification == \"GCSE (9-1) Full Course\") %>%\n  group_by(Description, Grade) %>%\n  summarise(total_grade = sum(Entries, na.rm=TRUE)) %>%\n  mutate(total_entries = max(total_grade, na.rm=TRUE),\n         per_entries = total_grade/total_entries) %>%\n  filter(Grade != \"Total number entered\")\n\nggplot(data=plot_data, aes(x=Grade, y=per_entries)) +\n  geom_bar(aes(fill=Description), \n           position=\"dodge\",\n           stat=\"identity\")\n\n\n1 to 8 creates a dataframe plot_data that calculates the percentage of entries for each science subject achieving each grade, this is called per_entries\n\n10 as we are setting the heights of the bars ourselves, we need to give the ggplot aes command a y value, in this case y=per_entries\n\n11 the geom_bar is given a fill value of Description, this will allow us to see the plots of different subjects\n12 we use position=\"dodge\" as we want the perctange grades of each subject to be next to each other so we can look for differences in heights\n13 stat=\"identity\" tells geom_bar that you have defined your own bar heights in the y attribute and not to count the number of rows.\n\n3.2.6 Questions\n\n\nCan you spot the 4 errors in this code.\n\n\n\n\n\n\n\n\nCreate a bar chart showing the total number of open Independent schools for each Gender\n\n\n\n\n\nUsing the TIMSS dataset:\n\n\nfilter to only look at the USA and ENG\nmake a graph to show the overall picture of Parental expectations for student achievement (BCBG14G).\nMake the x axis a factor so the graph makes sense\n\nfill the bars in to show how many schools each bar came from each country\n\nposition bars so they aren’t stacked on top of each other\n\n\n\n\n\n\n\nRepeat Q3, but this time work out the percentage of responses for each option in BCBG14G by country. Display a graph showing this “indentity”.\n\n\n\n\n\n[Extension] Explore other patterns in: “Teachers’ ability to inspire students” BCBG14D and “Parental expectations for student achievement” BCBG14G\n\n\n\n\n3.2.7 geom_text\nTODO: if time"
  },
  {
    "objectID": "index.html#faceting",
    "href": "index.html#faceting",
    "title": "Questions and Answers",
    "section": "\n3.3 Faceting",
    "text": "3.3 Faceting\nFaceting allows you to easily create multiple graphs from one dataset and one graph definition by splitting the data on different factors. By defining\nfacet_wrap(<factor_to_split> ~ .)\nLet’s return to grammar school dataset from Section 3.2.3, we can easily plot this to show the relationship between poverty and school size, showing that grammar schools tend to serve quite affluent cohorts and that larger secondary schools tend to serve poorer cohorts:\n\nplot_data <- schools %>% \n  filter(Open==\"Open\", \n         Phase==\"Secondary\") %>%\n  mutate(sch_type = \n           ifelse(EstablishmentGroup != \"Independent schools\" & \n                    AdmissionsPolicy==\"Selective\",\n                  \"GRAMMAR\",\n                  \"NOT GRAMMAR\")) %>%\n  arrange(desc(sch_type))\n\nggplot(data=plot_data, aes(x=FSM, y=NumberOfBoys + NumberOfGirls)) + \n  geom_point(aes(colour=sch_type)) +\n  geom_smooth(method =\"lm\") +\n  theme(legend.position=\"bottom\")\n\nWhat isn’t clear about the above is how this changes on a regional basis. We might be tempted to filter on each region and create separate charts for each regional name. But this would take a considerable amount of time and effort. Another way to do this is using facet_wrap(Region ~ .). The below example uses the Region column to create the same chart for each Region, only using the data that is recorded as being in that region:\n\nggplot(data=plot_data, aes(x=FSM, y=NumberOfBoys + NumberOfGirls)) + \n  geom_point(aes(colour=sch_type)) +\n  geom_smooth(method =\"lm\") +\n  theme(legend.position=\"bottom\") +\n  facet_wrap(Region ~ .)"
  },
  {
    "objectID": "index.html#exporting-plots",
    "href": "index.html#exporting-plots",
    "title": "Questions and Answers",
    "section": "\n3.4 Exporting plots",
    "text": "3.4 Exporting plots\nggplot can export data in a variety of formats suitable for printing, publication and the web. Once you have created a graph and stored it in an object, the command to save the graph to your hard drive is:\nggsave(<file_name_and_extension>, <object_name>)\n\nggsave(\"poverty_size.pdf\", graph_poverty_size)\n\nIf you want to change the output format, just change the extension of the file you are saving:\n\n“poverty_size.pdf” perfect for publication and printing, large size\n“poverty_size.svg” the same as pdf, also suitable for putting on webpages\n“poverty_size.png” smaller file size, suitable for websites and presentations\n“poverty_size.jpg” same as the png"
  },
  {
    "objectID": "index.html#discussion-activity",
    "href": "index.html#discussion-activity",
    "title": "Questions and Answers",
    "section": "\n3.5 Discussion activity",
    "text": "3.5 Discussion activity\nBased on Davis (2013) Link to chapter\n\nConsider how and why we think of things as being ‘normal’ (or not). Some suggested questions are: What were your immediate thoughts on reading this paper?\nIn what ways have you yourself been aware of being compared to norms or ideals? How do you feel about that? As an education professional, have you made comparisons between individual students and expected norms or averages? Between groups of students? When and how was this useful? When and how was this problematic?"
  },
  {
    "objectID": "index.html#statistics",
    "href": "index.html#statistics",
    "title": "Questions and Answers",
    "section": "\n3.6 Statistics",
    "text": "3.6 Statistics\nUsing the following .csv data set and the read.csv command: DfE_SEN_School_Level\n\nLoading the data# Descriptive Statistics using the DfE SEN School Level Data\n\nlibrary(\"tidyverse\")\nloc<-\"<your drive>/sen_school_level_underlying_data.csv\"\nDfE_SEN_data <- read.csv(loc)\n\n\nIndividually:\n\nSelect a single local authority (LA) or region, and copy-paste the data to a new sheet.\nCalculate the total number of pupils in the LA, the total number listed as receiving SEN support, and the total number with an EHC plan.\nCalculate the percentages of pupils in the SEN support and EHC plan categories.\nFind the mean, median, maximum and minimum percentages of students with SEN support and EHC plans.\n\nAs a class: Compare results for the different areas, and also to England as a whole. How much variation is there?\n\nShow the code# Descriptive Statistics using the DfE SEN School Level Data\n\ninstall.packages(\"psych\")\nlibrary(psych)\nlibrary(tidyverse)\n\n# Counting in a selected region\n\nDfE_SEN_data %>% \n  filter(la_name==\"Camden\") %>% \n  summarise(SEN_total=sum(SEN.support), \n            EHCplan=sum(EHC.plan), \n            Total=sum(Total.pupils))\n\n# Counting total SEN supported students in regions\nDfE_SEN_data %>%\n  group_by(district_administrative_name) %>%\n  summarise(SEN_support=sum(SEN.support), \n            EHCplan=sum(EHC.plan), \n            Total=sum(Total.pupils))\n\n# Calculating Percentages of students and finding maximums and minimums\nPercenttable<-DfE_SEN_data  %>% \n  group_by(district_administrative_name) %>%\n  summarise(SEN_support=sum(SEN.support), \n            EHCplan=sum(EHC.plan), \n            Total=sum(Total.pupils)) %>%\n  mutate(percentageEHCplan = (EHCplan/Total)*100, \n         percentagesupport = (SEN_support/Total)*100) \n\ndescribe(Percenttable) # describe is a function from the psych package (remember to load tidyverse after it)\n                       #  which gives summary data include max, min, mean etc.\n\n# An alternative way to do this is to turn the table into the longer format\n# This converts each entry in the table into an individual row in a list\n# which can then be used to calculate descriptive statistics\n\nDfE_SEN_data %>%\n  group_by(district_administrative_name) %>%\n  summarise(SEN_support=sum(SEN.support), \n            EHCplan=sum(EHC.plan), \n            Total=sum(Total.pupils))\nnew_table %>% \n  pivot_longer(!district_administrative_name,\n               names_to = \"variable\",\n               values_to = \"value\") %>%\n  group_by(variable) %>%\n  summarise(mean_value = mean(value),\n            max_value = max(value),\n            median_value = median(value)\n  )"
  },
  {
    "objectID": "index.html#statistics-1",
    "href": "index.html#statistics-1",
    "title": "Questions and Answers",
    "section": "\n3.7 Statistics",
    "text": "3.7 Statistics\nUsing the same data set: DfE_SEN_School_Level\nPractice:\n\nFiltering and reorganizing data\nCalculating averages and ranges (and, optionally, quartiles, percentiles, standard deviations, etc.)\nDisplaying data in different types of chart\nComparing subsets of the data on variables that interest you (e.g. state-funded vs independent, religious denomination, girls’ vs boys’ vs mixed schools, etc.) Why might single sex schools have smaller numbers of EHC plans?\n\n\nShow the code# Presenting % on EHC by gender of school\ngenderplot <- DfE_SEN_data %>%\n  group_by(sex_of_school_description) %>%\n  summarise(SEN_support=sum(SEN.support), \n            EHCplan=sum(EHC.plan), \n            Total=sum(Total.pupils)) %>%\n  mutate(percentageEHCplan = (EHCplan/Total)*100, \n         percentagesupport = (SEN_support/Total)*100)\n\n\n# using the genderplot data create a graph\nggplot(data=genderplot,\n       aes(x=sex_of_school_description,\n           y=percentageEHCplan)) +\n  geom_col()\n\n# Calculate percentage on plan and support by type of school\n\nestabdata<-DfE_SEN_data %>%\n  group_by(type_of_establishment) %>%\n  summarise(SEN_support=sum(SEN.support), \n            EHCplan=sum(EHC.plan), \n            Total=sum(Total.pupils)) %>%\n  mutate(percentageEHCplan = (EHCplan/Total)*100, \n         percentagesupport = (SEN_support/Total)*100)\n\n# Plot the type of school data\nggplot(data=estabdata,\n       aes(x=type_of_establishment,\n           y=percentageEHCplan)) +\n  geom_col()+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "index.html#using-r-to-do-descriptive-statistics-and-plot-graphs",
    "href": "index.html#using-r-to-do-descriptive-statistics-and-plot-graphs",
    "title": "Questions and Answers",
    "section": "\n3.8 Using R to do descriptive statistics and plot graphs",
    "text": "3.8 Using R to do descriptive statistics and plot graphs\n\n\nYou can find the code used in the video below:\n\nShow the code# Introduction to plotting graphs\n#\n# Download data from /Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\n# You want the file: Students_2018_RBDP_none_levels.rds\n# and place in your own file system\n# change loc to load the data directly. Loading into R might take a few minutes\nlibrary(tidyverse)\nloc <- \"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\"\nPISA_2018 <- read_rds(loc)\n\n# Calculating means of groups\n# The PISA_2018 dataframe is piped to a new dataframe MeanPISA\n# The data are grouped by the country variable (CNT)\n# The countries of interest are chosen (UK, France, Germany and the US)\n# The summarise function is used to output the mean and standard deviation score for each country\n# on the Science Plausible Value (PV1SCIE) and NAs are ignored na.rm=TRUE\n\nMeanPISA <- PISA_2018 %>%\n  group_by(CNT)  %>%\n  filter(CNT==\"United Kingdom\" | CNT== \"France\" | CNT== \"Germany\" | CNT==\"United States\")  %>%\n  summarise(mean_sci = mean(PV1SCIE, na.rm=TRUE), sd_sci= sd(PV1SCIE, na.rm=TRUE)) \nprint(MeanPISA)\n\n\n# To plot data we can use the ggplot function. \n# We will start by plotting a column graph use geom_col\n# We specify the data set for ggplot to use (MeanPisa) and then \n# define the x and y variables:\n# ggplot(MeanPISA,\n#       aes(x=CNT, y=mean_sci))\n# geom_col() (Note the plus is on the line before) plots the graph and the fill colour is set to red\n# The next three lines set the formatting of the axis text and add x and y axis labels\n\nggplot(MeanPISA,\n       aes(x=CNT, y=mean_sci))+\ngeom_col(fill=\"red\") +\n  theme(axis.text.x = element_text(angle = 90, hjust=0.95, vjust=0.2, size=10)) +\n  xlab(\"Country\") +\n  ylab(\"Science Score\")\n\n# For plotting a scatter plot or PISA reading scores against science scores\n#, first we make a managable data set\n# I will filter the data set to include only the UK data\n# Select the country, reading and science score, and remove any NAs\n\nUKData <- PISA_2018 %>%\n  filter(CNT==\"United Kingdom\") %>%\n  select(CNT, PV1SCIE, PV1READ, ST004D01T) %>%\n  drop_na(PV1SCIE)\n\n# This time I will use ggplot to plot a scatter graph\n# I feed UKDATA to ggplot, specify the x (PISA Reading score)\n# And y (PISA science score). This time, I have linked the colour\n# to a variable (ST004D01T) which is the gender value, giving\n# plot points of different colours for boys and girls\n# To produce a scatter plot, I use geom_point to plot points,\n# Giving the size of point and the transparency (alpha=0.5) -\n# some transparency of points is helpful when plots become dense\n# The x and y lables are added\n# Finally, a line is plotted - geom_smooth(method='lm')\n# sets the line to a linear ('lm') line\n\n  ggplot(UKData,\n       aes(x=PV1READ, y=PV1SCIE, colour=ST004D01T)) +\n  geom_point(size=0.1, alpha=0.5) +\n  ylab(\"Science Score\") +\n  xlab(\"Reading Score\") +\n  geom_smooth(method='lm')\n  \n# Where R becomes very powerful is being able to produce multiple charts rapidly\n# In the code below, I plot reading against science scores as above, but this time\n# Use the entire data set - for the whole world!\n# All the steps are the same, except, I use the facet_wrap, a way to create multiple\n# graph panels - the instruction creates a set of graphs for each country  \n  \n  WorldData <- PISA_2018 %>%\n    select(CNT, PV1SCIE, PV1READ, ST004D01T) %>%\n    drop_na(PV1SCIE)\n  \n  ggplot(WorldData,\n         aes(x=PV1READ, y=PV1SCIE, colour=ST004D01T)) +\n    geom_point(size=0.1, alpha=0.5) +\n    ylab(\"Science Score\") +\n    xlab(\"Reading Score\") +\n    geom_smooth(method='lm') +\n    facet_wrap(CNT~.)"
  },
  {
    "objectID": "index.html#statistical-analysis",
    "href": "index.html#statistical-analysis",
    "title": "Questions and Answers",
    "section": "\n5.1 Statistical analysis",
    "text": "5.1 Statistical analysis\nThere are probably statistical libraries in R to do every sort of test you will ever need, from the typical ANOVA to cutting edge machine learning. The full list of R packages sits on the cran server and you can load packages as and when you need them at no cost. R comes pre-packaged with some common statistical tools, for example, the t.test() and linear model regression lm(). For other stats tools you’ll need to install the package and load it (see Section 2.6.1) before you can use the functions."
  },
  {
    "objectID": "index.html#task-1-1",
    "href": "index.html#task-1-1",
    "title": "Questions and Answers",
    "section": "\n6.1 Task 1",
    "text": "6.1 Task 1"
  },
  {
    "objectID": "index.html#task-2-1",
    "href": "index.html#task-2-1",
    "title": "Questions and Answers",
    "section": "\n6.2 Task 2",
    "text": "6.2 Task 2"
  },
  {
    "objectID": "index.html#task-3",
    "href": "index.html#task-3",
    "title": "Questions and Answers",
    "section": "\n6.3 Task 3",
    "text": "6.3 Task 3\n\n\n\n\n6.3.1 Doing t-tests in R\n\n\nYou can find the code from the video below:\n\nShow the code# Introduction to t-tests in R\n#\n# Download data from /Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\n# You want the file: Students_2018_RBDP_none_levels.rds\n# and place in your own file system\n# change loc to load the data directly. Loading into R might take a few minutes\ninstall.packages(\"nortest\")\n\nlibrary(tidyverse)\nlibrary(nortest)\nloc <- \"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\"\nPISA_2018 <- read_rds(loc)\n\n# Are there differences between the mean scores of UK boys and girls in PISA mathematics?\n#\n# Select the gender (ST004D01T) and math score columns (PV1MATH)\n# Filter the data to select UK responses\n\nMaleUK<-PISA_2018 %>%\n  select(CNT,ST004D01T, PV1MATH) %>%\n  filter(CNT=='United Kingdom') %>%\n  filter(ST004D01T=='Male')\n\nFemaleUK<-PISA_2018 %>%\n  select(CNT,ST004D01T, PV1MATH) %>%\n  filter(CNT=='United Kingdom') %>%\n  filter(ST004D01T=='Female')\n\n# The conditions to do a t-test include that the data are normally distributed\n# and there is homogeneity (similarity) of the variances (the squared standard deviations)\n# Let us check the conditions are met by calculating first if the data sets are normally\n# distributed using the Pearson test of normality from the nortest package\n\npearson.test(as.numeric(MaleUK$PV1MATH))\npearson.test(as.numeric(FemaleUK$PV1MATH))\n\n# The p-values are over 0.05 so both distriburtions are normal\n# Pearson chi-square normality test\n#\n# data:  as.numeric(MaleUK$PV1MATH)\n# P = 75.714, p-value = 0.1936\n# Pearson chi-square normality test\n#\n# data:  as.numeric(FemaleUK$PV1MATH)\n# P = 74.06, p-value = 0.2589\n#\n# We will then check the variances of the two data sets\n\nVarM<-var(MaleUK$PV1MATH)\nVarF<-var(FemaleUK$PV1MATH)\nVarM/VarF\n\n# The variance ratio is close to 1 (1.1)\n# So our two conditions are met and can we can perform the t-test\n\nt.test(MaleUK$PV1MATH, FemaleUK$PV1MATH)\n\n# The p-value is <0.05 (4.061e-08) suggesting there are statistically\n# differences between boys and girls"
  },
  {
    "objectID": "index.html#chi-square-tests",
    "href": "index.html#chi-square-tests",
    "title": "Questions and Answers",
    "section": "\n7.1 Chi-square tests",
    "text": "7.1 Chi-square tests\nChi squared (\\(\\chi^2\\)) tests are non-parametric tests, this means that the test isn’t expecting the underlying data to be distributed in a certain way. Chi-square determines how well the frequency distribution for a sample fits the population distribution and will let you know when things aren’t distributed as expected. For example you might expect girls and boys to have the same coloured dogs, chi square would tell you whether the null hypothesis, that there is no difference between the categories, is true or not. I.e. girls and boys are equally likely to have the same colours of dog at home.\nIn more mathematical terms, chi square examines differences between the categories of an independent variable with respect to a dependent variable measured on a nominal (or categorical) scale, that is a scale that has values that aren’t ordered, or continuous, for example Gender or favourite flavour of icecream.\nIn the example below you will be loading data about Ofsted inspections to see if the Ofsted grade of a state secondary school varies dependent on whether the school is all all boys, all girls or mixed."
  },
  {
    "objectID": "index.html#load-the-data",
    "href": "index.html#load-the-data",
    "title": "Questions and Answers",
    "section": "\n7.2 Load the data",
    "text": "7.2 Load the data\nThe data for this example comes from the DfE edubase system. This system is updated almost daily with information on all education providers in the country. The snapshot below was taken in 2018, you are welcome to download a later copy.\n\n# Download data on all educational providers in England\n# with details on FSM and Ofsted inspections\n\nlibrary(\"tidyverse\")\nlibrary(\"openxlsx\")\n\nDfE_schools_2018 <- read.xlsx(\"https://drive.google.com/uc?export=download&id=1tp9xe3dS__eg7RrXf0T_oMxcrz_TbMdM\",\n                      sheet=\"Schools\")"
  },
  {
    "objectID": "index.html#wrangling-the-data",
    "href": "index.html#wrangling-the-data",
    "title": "Questions and Answers",
    "section": "\n7.3 Wrangling the data",
    "text": "7.3 Wrangling the data\nThe dataset is absolutely massive, weighing in at about 60Mb and almost 50,000 providers, both historic and current. You need to whittle this down to the schools that you are interested in, that is the schools that are open, for secondary school students and are not independent (private) providers.\nWe’ll also need to\n\n# note that 2018 data doesn't have inadequate\n\nOfsted_ratings <- DfE_schools_2018 %>%\n  filter(Open == \"Open\",\n         EstablishmentGroup != \"Independent schools\",\n         Phase == \"Secondary\",\n         OfstedRating %in% c(\"Outstanding\", \"Good\",\n                             \"Requires improvement\",\"Inadequate\",\n                             \"Special Measures\")) %>%\n  mutate(FSM_group = ntile(FSM, n=3)) %>%\n  mutate(FSM_group = ifelse(FSM_group == 3,\n                            \"High\",\n                            ifelse(FSM_group == 2,\n                                   \"Medium\",\n                                   \"Low\")))"
  },
  {
    "objectID": "index.html#contingency-tables",
    "href": "index.html#contingency-tables",
    "title": "Questions and Answers",
    "section": "\n7.4 Contingency tables",
    "text": "7.4 Contingency tables\nTo get a feel for what the data looks like we can build a contingency table. This will show the number of providers that match each combination of of the two groupings we are looking at, in this case the OfstedRating and the FSM_group. To do this we will first count each group of OfstedRating and FSM_group. This makes a nice list of the number of instances of each group:\n\n# to get a frequency table of the above we can use group_by\n\nOfsted_ratings_freq <- Ofsted_ratings %>%\n  group_by(OfstedRating, FSM_group) %>%\n  count()\n\nprint(Ofsted_ratings_freq)\n\n# A tibble: 12 × 3\n# Groups:   OfstedRating, FSM_group [12]\n   OfstedRating         FSM_group     n\n   <chr>                <chr>     <int>\n 1 Good                 High        486\n 2 Good                 Low         506\n 3 Good                 Medium      577\n 4 Outstanding          High         90\n 5 Outstanding          Low         252\n 6 Outstanding          Medium      100\n 7 Requires improvement High        222\n 8 Requires improvement Low          69\n 9 Requires improvement Medium      145\n10 Special Measures     High         34\n11 Special Measures     Low           5\n12 Special Measures     Medium       10\n\n\nTo put this into a contingency table we can use pivot_wider, this will keep the FSM_group and by fetching names_from = OfstedRating, it will create a new column for each OfstedRating and will then show how many instances of each combined OfstedRating and FSM_group there are.\n\n# build a contingency table\ncontingency_table <- Ofsted_ratings_freq %>% \n  pivot_wider(names_from = OfstedRating,\n              values_from = n)\nprint(contingency_table)\n\n# A tibble: 3 × 5\n# Groups:   FSM_group [3]\n  FSM_group  Good Outstanding `Requires improvement` `Special Measures`\n  <chr>     <int>       <int>                  <int>              <int>\n1 High        486          90                    222                 34\n2 Low         506         252                     69                  5\n3 Medium      577         100                    145                 10"
  },
  {
    "objectID": "index.html#plotting-the-chi-square-relationships",
    "href": "index.html#plotting-the-chi-square-relationships",
    "title": "Questions and Answers",
    "section": "\n7.5 Plotting the chi-square relationships",
    "text": "7.5 Plotting the chi-square relationships\nThe numbers in the contingency table might look odd, but it might be hard to see how far out they are from each other. We can also visualise the data from the contingency table by building a mosaic plot. To do this you are going to need to install and load the ggmosaic package. See packages section for more details on how to do this.\nIf you were to go and create a mosaic plot you might find that the order of the x and y axis isn’t to your liking:\n\n # install.packages(\"ggmosaic\")\nlibrary(ggmosaic)\n# plot results\nggplot(data = Ofsted_ratings) +\n  geom_mosaic(aes(x = product(OfstedRating, \n                              FSM_group), \n                  fill = OfstedRating))\n\nWarning: `unite_()` was deprecated in tidyr 1.2.0.\nℹ Please use `unite()` instead.\nℹ The deprecated feature was likely used in the ggmosaic package.\n  Please report the issue at <]8;;https://github.com/haleyjeppson/ggmosaichttps://github.com/haleyjeppson/ggmosaic]8;;>.\n\n\n\n\n\nThe order of the x and y axis on the table are defined by the levels of the data. This is a specific R concept, where we have columns stored as factors, with levels. Factors define a column as only allowing a certain set of values, these values are defined by the levels, and the order of the levels.\n. You #TODO: get the ‘factors’ in order\n\n # install.packages(\"ggmosaic\")\nlibrary(ggmosaic)\n\n# add order to the factors involved in the mosaic\nrdr <- c(\"Outstanding\", \"Good\", \"Requires improvement\", \"Special Measures\") \n\nOfsted_ratings <- Ofsted_ratings %>% \n  mutate(OfstedRating = factor(OfstedRating, \n                               levels=rdr),\n        FSM_group = factor(FSM_group, \n                           levels=c(\"Low\", \"Medium\", \"High\")))"
  },
  {
    "objectID": "index.html#running-chi-square-tests",
    "href": "index.html#running-chi-square-tests",
    "title": "Questions and Answers",
    "section": "\n7.6 Running Chi square tests",
    "text": "7.6 Running Chi square tests\nNow we have the providers that we want, we can start to build a chi-square test. This is very easy in R and it follows the following structure:\n\nchi\n\n\nchisq.test(Ofsted_ratings$OfstedRating, Ofsted_ratings$FSM_group)\n\n\n    Pearson's Chi-squared test\n\ndata:  Ofsted_ratings$OfstedRating and Ofsted_ratings$FSM_group\nX-squared = 230.58, df = 6, p-value < 2.2e-16\n\n# summary(chisq.test(Ofsted_ratings$OfstedRating, Ofsted_ratings$FSM_group))"
  },
  {
    "objectID": "index.html#seminar-tasks-1",
    "href": "index.html#seminar-tasks-1",
    "title": "Questions and Answers",
    "section": "\n7.7 Seminar Tasks",
    "text": "7.7 Seminar Tasks\n\n7.7.1 Activity 1- Checking chi-square test in a research paper\n\n\n\nIn this activity you are going to look at the data presented in a paper by Mutodi and Ngirande (2014). They present the relationships between a number of demographic factors and maths anxiety. For example, table 3 in the paper looks at the relationship between gender and maths anxiety.\n\nanx3_table_out\n\n\n\n\n\n\nGender\n      High level of anxiety\n      Moderate level of anxiety\n      No math anxiety\n      Not sure\n      Total\n    \n\n\nFemale\n14\n10\n3\n9\n36\n\n\nMale\n26\n35\n6\n17\n84\n\n\nTotal\n40\n45\n9\n26\n120\n\n\n\nSource: Table 3, Mutodi, P. and Ngirande, H. (2014) The influence of studentsperceptions on Mathematics performance. A case of a selected high school in South Africa. Mediterranean Journal of Social Sciences\n    \n\n\n\n\nThe raw survey data is available in a two column csv format, with each row equal to one survey response. The first column being the demographic data; in the case below, Gender, and the second column listing the student’s answer to the questions about maths anxiety, listed here as name:\n\nanx3_data %>% head(3)\n\n# A tibble: 3 × 2\n  Gender name                 \n  <chr>  <chr>                \n1 Male   High level of anxiety\n2 Male   High level of anxiety\n3 Male   High level of anxiety\n\n\n\nUsing the gender and maths anxiety dataset, group the Gender and name fields, counting the number of responses in each group.\nComment on any issues you find with the data, the methodological or the calculations.\nrepeat this for Table 4 (HINT: you won’t be grouping by Gender this time!)\nrepeat this for Table 5\n\n\nNow you have had a brief explore of the data we need to conduct some chi-square tests to check whether the results between groups are\n\nShow the code# Load the csv files for the three tables\nloc<-\"<your HDD>/anx_table_3.csv\"\nanxiety_table_3 <- read_csv(loc)\n\nloc<-\"<your HDD>/anx_table_4.csv\"\nanxiety_table_4 <- read_csv(loc)\n\nloc<-\"<your HDD>/anx_table_5.csv\"\nanxiety_table_5 <- read_csv(loc)\n\n\n# This section gets the data into the correct format for the square test in R\n# The Count tables are turned back into a long list of entries like this:\n# A tibble: 120 × 2\n#Gender name                 \n#<chr>  <chr>                \n# 1 Male   High level of anxiety\n# 2 Male   High level of anxiety\n# 3 Male   High level of anxiety\n#\n# That is done by \n# 1) Select(-total) removes the total column which we don't need \n# 2) filter(Gender !=\"Total\") removes the row that stores totals\n#    leaving just the rows storing actual data\n# 3) pivot_longer turns the table into a long dataframe, -Gender\n#    ignores/keeps the Gender column and converts all the other\n#    columns into one column, with the heading and matching value \n#    making up new rows\n# 4) uncount turns the counts stored in value in the table into \n#    individual entries, e.g. Male, No anxiety, 45 would create \n#    45 rows with \"Male, No anxiety\"\n\nanx_3 <- Anxietytable3 %>% \n  select(-Total) %>% \n  filter(Gender != \"Total\") %>%\n  pivot_longer(-Gender) %>% \n  uncount(value)\n\nanx_4 <- Anxietytable4 %>% \n  select(-Total) %>% \n  filter(Age != \"Total\") %>%\n  pivot_longer(-Age) %>% \n  uncount(value)\n\nanx_5 <- Anxietytable5 %>% \n  select(-Total) %>% \n  filter(HomeLang != \"Total\") %>%\n  pivot_longer(-HomeLang) %>% \n  uncount(value)\n\n# save long dataframes\n# write.csv(anx_3, glue(\"{loc_amy}Amy/anx_table_3.csv\"), row.names = FALSE)\n# write.csv(anx_4, glue(\"{loc_amy}Amy/anx_table_4.csv\"), row.names = FALSE)\n# write.csv(anx_5, glue(\"{loc_amy}Amy/anx_table_5.csv\"), row.names = FALSE)\n\n# conduct chi-square tests\nchisq.test(anx_3$Gender, anx_3$name)\nchisq.test(anx_4$Age, anx_4$name)\nchisq.test(anx_5$HomeLang, anx_5$name)\n\n# conduct - Kruskal-Wallis tests\nkruskal.test(anx_3$Gender, anx_3$name)\nkruskal.test (anx_4$Age, anx_4$name)\nkruskal.test (anx_5$HomeLang, anx_5$name)\n\n\n\n7.7.2 Activity 2- Determine if admissions type in LAs are proportionate to national averages\nLooking at the DfE Data set, choose a Local Authority (I suggest Dorset) and determine if the proportion of selective and non-selective schools are statistically similar or different to the national average. Comment on any potential issues with the data or the approach.\n\nShow the code# Task 2\n# Load the file for the task\nloc<-\"https://drive.google.com/uc?export=download&id=1tp9xe3dS__eg7RrXf0T_oMxcrz_TbMdM\"\nDfE_schools_2018 <- read.xlsx(loc,sheet=\"Schools\")\n# Create a dataframe of the admission policies of Dorset schools\nDorsetschAd<-DfE_schools_2018 %>%\n  select(LA,AdmissionsPolicy)%>%\n  filter(LA==\"Dorset\")\n# Create a dataframe of the admission policies of all non-Dorset schools (note LA! means\n# not equal to)\nOtherUKSch<-DfE_schools_2018 %>%\n  select(LA,AdmissionsPolicy)%>%\n  filter(LA!=\"Dorset\")\n# OtherUKSchs are labelled by LA so reset all these names just to UK\nOtherUKSch$LA<-\"UK\"\n# Join the two frames to give one long list\nAllSch<-rbind(OtherUKSch, DorsetschAd)\n# To check what test to do print the frequency table\ntable(AllSch)\n# And a percentage version\n(100*prop.table(table(AllSch)))\n# Expected values are fine so use the Chi squared test\n# AdmissionsPolicy\n# LA       Non-selective Not applicable    Selective\n# Dorset   0.059974356    0.349505729  0.006204244\n# UK      16.075195434   81.718161889  1.790958349\n# Note \nchisq.test(AllSch$LA, AllSch$AdmissionsPolicy, simulate.p.value = TRUE)\n\n\n\n7.7.3 Activity 3- Determine if Ofsted rating and gender of school are independent\nLooking again at the DfE Data set, compare Ofsted rating of the school against gender to determine if these are independent or not. You may wish to focus on a particular phase (such as secondary) and only include certain Ofsted ratings. Comment on any issues with the data.\n\nShow the code# Is there a relationship between school gender and Ofsted Rating?\n\nchisq.test(DfE_schools_2018$Gender,DfE_schools_2018$OfstedRating, simulate.p.value = TRUE)\n# Yes!\n# Pearson's Chi-squared test with simulated p-value (based on 2000 replicates)\n#\n# data:  DfE_schools_2018$Gender and DfE_schools_2018$OfstedRating\n# X-squared = 675.4, df = NA, p-value = 0.0004998\n\n\n\n7.7.4 Activity 4- Create your own problem\nUsing the DfE Data set (or otherwise), create a research question which requires one of the chi-square tests to answer the question. State clearly what your null and alternative hypothesis are, what you are using as the significance level, what the chi-square calc and/or p-values for the test are, what conclusion you make, and any issues you think there are with the test.\n\n7.7.5 Doing Chi-Square tests in R\n\n\nYou can find the code used in the video below\n\n# Introduction to Chi-square\n#\n# Download data from /Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\n# You want the file: Students_2018_RBDP_none_levels.rds\n# and place in your own file system\n# change loc to load the data directly. Loading into R might take a few minutes\n\nloc <- \"https://drive.google.com/open?id=14pL2Bz677Kk5_nn9BTmEuuUGY9S09bDb&authuser=richardandrewbrock%40gmail.com&usp=drive_fs\"\nPISA_2018 <- read_rds(loc)\n\n# Are there differences between how often students change school?\n# ST004D01T is the gender variable (Male, Female)\n# SCCHANGE is a categorical variable (No change / One change / Two or more changes)\n\nchidata <- PISA_2018 %>%\n  select(CNT,ST004D01T,SCCHANGE) %>%\n  filter(CNT==\"United Kingdom\")\n\nchidata<-chidata[-c(1)]\nchidata<-drop_na(chidata)\n\n chidata <- PISA_2018 %>%\n   filter(CNT==\"United Kingdom\")\n   select(ST004D01T,SCCHANGE) %>% \n   drop_na()\n# Above is the approiach I took in the video\n# An alternative, Pete suggests, which is more elegant, is below\n# Note he drops the country varibale, within the piped section\n# using: elect(-CNT)\n#    \n# chidata <- PISA_2018 %>%\n#   select(CNT,ST004D01T,SCCHANGE) %>%\n#   filter(CNT==\"United Kingdom\") %>%\n#   select(-CNT) %>% \n#   drop_na()\n\n# run the test\nchisq.test(chidata$ST004D01T, chidata$SCCHANGE)\n\n```"
  },
  {
    "objectID": "index.html#running-the-test",
    "href": "index.html#running-the-test",
    "title": "Questions and Answers",
    "section": "\n8.1 Running the test",
    "text": "8.1 Running the test\n\nres_aov <- aov(PV1SCIE ~ inquiry_components,\n               data = inquiry_data)\n\nsummary(res_aov)\n\n                       Df    Sum Sq  Mean Sq F value Pr(>F)    \ninquiry_components      4 1.563e+08 39086096    4161 <2e-16 ***\nResiduals          250922 2.357e+09     9393                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTukeyHSD(res_aov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1SCIE ~ inquiry_components, data = inquiry_data)\n\n$inquiry_components\n         diff       lwr        upr p adj\nC-A  43.60278  39.91980  47.285765     0\nI-A -30.38961 -35.31026 -25.468963     0\nN-A  25.60709  22.48822  28.725951     0\nQ-A -42.80561 -46.19298 -39.418240     0\nI-C -73.99239 -78.35836 -69.626429     0\nN-C -17.99570 -20.13490 -15.856492     0\nQ-C -86.40840 -88.92299 -83.893803     0\nN-I  55.99670  52.09482  59.898570     0\nQ-I -12.41600 -16.53566  -8.296343     0\nQ-N -68.41270 -69.98945 -66.835952     0\n\n\n\n8.1.1 Reporting the test\nTo put the ANOVA and Tukey tests in a format for reporting we can use the easystats package. Easystats is a collection of tools to help you statistically analyse data and present your findings. One you have installed and loaded easystats you can then use the report(<stats_model>) command to format your results for a paper you are writing:\n\ninstall.packages(\"easystats\")\n\nWarning: package 'easystats' is in use and will not be installed\n\nlibrary(\"easystats\") # Load the package every time you want to use these tools\n\nreport(res_aov)\n\nWarning: Could not find Sum-of-Squares for the (Intercept) in the ANOVA table.\n\n\nThe ANOVA (formula: PV1SCIE ~ inquiry_components) suggests that:\n\n  - The main effect of inquiry_components is statistically significant and medium\n(F(4, 250922) = 4161.08, p < .001; Eta2 = 0.06, 95% CI [0.07, 1.00])\n\nEffect sizes were labelled following Field's (2013) recommendations.\n\n\n\n8.1.2 Plotting the results\n\nExplain how to understand this\nCould we have a ggplot version of this?\n\n\nplot(TukeyHSD(res_aov))\n\n\n\n\n\n8.1.3 Post tests function\nExplanation needed here\n\nlibrary(multcomp)\n# Tukey HSD test:\npost_test <- glht(res_aov,\n                  linfct = mcp(inquiry_components = \"Tukey\"))\nsummary(post_test)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: aov(formula = PV1SCIE ~ inquiry_components, data = inquiry_data)\n\nLinear Hypotheses:\n           Estimate Std. Error  t value Pr(>|t|)    \nC - A == 0  43.6028     1.3502   32.294   <1e-10 ***\nI - A == 0 -30.3896     1.8039  -16.847   <1e-10 ***\nN - A == 0  25.6071     1.1434   22.396   <1e-10 ***\nQ - A == 0 -42.8056     1.2418  -34.470   <1e-10 ***\nI - C == 0 -73.9924     1.6006  -46.229   <1e-10 ***\nN - C == 0 -17.9957     0.7842  -22.947   <1e-10 ***\nQ - C == 0 -86.4084     0.9218  -93.734   <1e-10 ***\nN - I == 0  55.9967     1.4304   39.147   <1e-10 ***\n [ reached getOption(\"max.print\") -- omitted 2 rows ]\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n8.1.4 Eta squared\nExplanation needed here\n\nlibrary(lsr)\netaSquared(res_aov)\n\n                       eta.sq eta.sq.part\ninquiry_components 0.06220631  0.06220631"
  },
  {
    "objectID": "index.html#seminar-tasks-2",
    "href": "index.html#seminar-tasks-2",
    "title": "Questions and Answers",
    "section": "\n8.2 Seminar tasks",
    "text": "8.2 Seminar tasks\n\n8.2.1 Activity 1: run ANOVA tests exploring…\nNeed to set something simple for them to do here\n\n# code solution to go here\n\n\n8.2.2 Activity 2: prepare for and run Tukey HSD post hoc test with summary and plot of which contrasts between levels are statistically significant\n\n# code solution to go here\n\n\n8.2.3 Activity 3\n\n# code solution to go here"
  },
  {
    "objectID": "index.html#writing-a-quantitative-report",
    "href": "index.html#writing-a-quantitative-report",
    "title": "Questions and Answers",
    "section": "\n9.1 Writing a Quantitative Report",
    "text": "9.1 Writing a Quantitative Report\nIn the lecture you looked at Du and Wong (2019) as an example of a quantitative report. This session will help you structure your writing for your own quantitative report in assignment 3.\n\n9.1.1 Activity 1: Proposing a question\n\nSpend 10 minutes researching a problem (this can’t be extensive but find something that is flagged as requiring more research). Alternatively, you make already have a problem, in which case move onto the next step\n\nState a rough research problem:\ne.g., There is an imbalance in the number of students studying a-level biology (i.e., too few boys)\n\n\nTurn the problem into a question:\ne.g., What school features correlate with higher and lower level of male uptake of a-level biology?\n\n\nIncrease the specificity of the question:\ne.g., In DfE school census data for the period 2017-2022 what school variables (including number of biology teachers, uptake of GCSE triple science, % of FSM students etc.) correlate with higher and lower level of male uptake of a-level biology?\n\n\n9.1.2 Activity 2: Find a data set and check its applicability\n\nUse the list of open data sets to choose an appropriate data set\nDoes it include all the data to answer your question? Which items will you use in your analysis? What form is the data you will use in?\nWhat form of cleaning will the data require?\nWill you need to draw on multiple data sets?\n\n9.1.3 Activity 3: Decide on approaches to analysis\n\nWhat types of data are relevant to your questions (continuous, discontinuous?)\nWhat types of test will you need to run?\nWhat kind of descriptive statistics will be useful?\n\n9.1.4 Activity 4: Sketch a research plan\n\nWhen will you finalize your question?\nWhen will you carry out your data analysis?\nWhen will you write up?\nWhat help will you need?\nHow can you collaborate with peers?\nWhat R/SPSS/Excel skills do you need to acquire?"
  },
  {
    "objectID": "index.html#choosing-appropriate-quantitative-tests",
    "href": "index.html#choosing-appropriate-quantitative-tests",
    "title": "Questions and Answers",
    "section": "\n12.1 Choosing appropriate quantitative tests",
    "text": "12.1 Choosing appropriate quantitative tests\nIn the lecture, this flow chart was introduced:\n\nThat chart will help you choose the test to use for the tasks below."
  },
  {
    "objectID": "index.html#seminar-tasks-3",
    "href": "index.html#seminar-tasks-3",
    "title": "Questions and Answers",
    "section": "\n12.2 Seminar Tasks",
    "text": "12.2 Seminar Tasks\nUse the reduced PISA 2018 dataset\nWe will store the location of the file in loc and then use read-rds to import the file. This is a cut down version of the PISA 2018 student dataset.\nLoad the data from there dataset:\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n# Download data from /Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\n# You want the file: Students_2018_RBDP_none_levels.rds\n# and place in your own file system\n# change loc to load the data directly. Loading into R might take a few minutes\n\nloc <- \"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2018_RBDP_none_levels.rds\"\n PISA_2018 <- read_rds(loc)\n\n\n12.2.1 Task 1 Plot a graph of mean science scores by country\nImagine we wish to compare the mean scores of students on the science element of PISA by plotting a bar graph. First you need to use the sumarise function to calculate means by countries. Then use ggplot with geom_col to create the graph.\n\nShow the code# Task 1: Plot a graph of mean science scores by country\n# Create a variable avgscience - for every country (Group_by(CNT)) calcuate the mean\n# science score (PV1SCIE) and ignore NA (na.rm=TRUE)\navgscience <- PISA_2018 %>% \n  group_by(CNT) %>%\n  summarise(mean_sci = mean(PV1SCIE, na.rm=TRUE)) %>%\n# Arrange in descending order  \n  arrange(desc(mean_sci))\n# Plot the data in avgscience, x=CNT (reorder to ascending order), mean science score on the y\n# Change the fill colour to red, rotate the text, locate the text and reduce the font size\n    ggplot(data = avgscience, \n           aes(x= reorder(CNT, -mean_sci), y=mean_sci)) +\n    geom_col(fill=\"red\") +\n    theme(axis.text.x = element_text(angle = 90, hjust=0.95, vjust=0.2, size=5))\n\n\n\n12.2.2 Task 2 Are there differences in Science scores by gender for the total data set?\nConsider the kinds of variables that represent the science score. What is an appropriate test to determine differences in the means between the two groups? Create two vectors, for boys and girls, that you can feed into the t.test function.\n\nShow the code# Task 2: Are there differences in Science scores by gender for the total data set? (No)\n\n# Choose the  gender (ST004D01T) and science score columns (PV1SCIE) from  2018 data, filter for males \n# Put that data into MaleSci\nMaleSci <- PISA_2018 %>% \n  select(ST004D01T, PV1SCIE) %>% \n  filter(ST004D01T == \"Male\")\n\n# Choose the  gender (ST004D01T) and science score columns (PV1SCIE) from  2018 data, filter for females \n# Put that data into FemaleSci\nFemaleSci <- PISA_2018 %>% \n  select(CNT, ST004D01T, PV1SCIE) %>% \n  filter(ST004D01T == \"Female\")\n\n#Do a t-test comparing MaleSci and FemaleSci\nt.test(MaleSci$PV1SCIE, FemaleSci$PV1SCIE)\n\n\n\n12.2.3 Task 3 Are there differences in Science scores by gender for UK students?\nAs above, but include a filter by country.\n\nShow the code# Task 3: Are there differences in Science scores by gender for UK students? (No)\n\n# Choose the country (CNT), gender (ST004D01T) and science score columns (PV1SCIE) from  2018 data, filter for males and the UK\n# Put that data into UKMaleSci\nUKMaleSci <- PISA_2018 %>% \n  select(CNT, ST004D01T, PV1SCIE) %>% \n  filter(ST004D01T == \"Male\")  %>% \n  filter(CNT==\"United Kingdom\")\n\n# Choose the country (CNT), gender (ST004D01T) and science score columns (PV1SCIE) from  2018 data, filter for females and the UK\n# Put that data into UKFemaleSci\nUKFemaleSci <- PISA_2018 %>% \n  select(CNT, ST004D01T, PV1SCIE) %>% \n  filter(ST004D01T == \"Female\") %>% \n  filter(CNT==\"United Kingdom\")\n\n# Do a t-test comparing UKMaleSci and UKFemaleSci\nt.test(UKMaleSci$PV1SCIE, UKFemaleSci$PV1SCIE)\n\n\n\n12.2.4 Task 4 For the whole data set, is there a correlation between students’ science score and reading scores?\nReflect on the appropriate test to show correlation between two scores. This test can be carried out quite simply using a couple of lines of code.\n\nShow the code# Task 4: For the whole data set, is there a correlation between students’ science score reading score? (Yes, significant 0.77)\n\n# Do the regression test between science score (PV1SCIE) and reading score (PV1READ) on the PISA_2018 data\nlmSciRead <- lm(PV1SCIE ~ PV1READ, data=PISA_2018)\nsummary(lmSciRead)\n\n# Add Gender to this as well? Not sure I have the correct lm type here, but it looks interesting!\n# lmSciRead <- lm(PV1SCIE ~ PV1READ + ST004D01T, data=PISA_2018)\n# summary(lmSciRead)\n\n\n\n12.2.5 Task 5 Plot a representation of UK students’ science score against reading score.\nIt can help here to create a data.frame that contains a filtered version of the whole dataset you can pass to ggplot.\n\nShow the code# Task 5: Plot a representation of UK students’ science score against reading score.\n \n# Choose the three variables of interest, science score (PV1SCIE), reading score (PV1READ) and country (CNT)\n# and filter for the UK. Put the values into regplotdata\nregplotdata<- PISA_2018 %>% \n  select(PV1SCIE, PV1READ, CNT) %>% \n  filter(CNT==\"United Kingdom\")\n\n# Plot the data in regplotdata, set the science score on the x-xis and reading on y-axis, set the size, colour and alpha (transparency)\n# of points and add a linear ('lm') black line\n  ggplot(data = regplotdata, \n         aes(x=PV1SCIE, y=PV1READ)) +\n    geom_point(size=0.5, colour=\"red\", alpha=0.3) + \n    geom_smooth(method = \"lm\", colour=\"black\")\n\n\n\n12.2.6 Task 6 Is there a relationship between UK students’ gender and the number of years students spend in early childhood care (e.g. kindergarten)?\nNote here that the time spent learning science (SMIS) is categorical as only certain values of time are allowed (0, 45, 90, 130 etc). Consider an appropriate test in that case.\n\nShow the code# Task 6: Is there a relationship between UK students’ gender and the number of years students spend in early childhood care (e.g. kindergarten)? (No significant difference by gender exists)\n  \nchi_data <- PISA_2018 %>%\n  select(CNT, ST004D01T, DURECEC) %>% \n  filter(CNT==\"United Kingdom\")  %>% \n  na.omit()\n\n# Create a frequency table\nYrsECFred <- chi_data %>%\n    group_by(ST004D01T, DURECEC)%>%\n    count()\n  \n# Perform the Kruskal Wallis test (note the no of years is\n# ordinal rather than categorical)  test on the data\n\nkruskal.test(YrsECFred$ST004D01T,YrsECFred$n)"
  },
  {
    "objectID": "index.html#pisa",
    "href": "index.html#pisa",
    "title": "Questions and Answers",
    "section": "\n13.1 PISA",
    "text": "13.1 PISA"
  },
  {
    "objectID": "index.html#what-is-pisa",
    "href": "index.html#what-is-pisa",
    "title": "Questions and Answers",
    "section": "\n13.2 What is PISA",
    "text": "13.2 What is PISA\nThe Programme for International Student Assessment (PISA) is an OECD initiative that looks at the reading, mathematics and science abilities of students aged 15 years old. Data is collected from ~38 OECD countries and other partner countries every three years.\n\n\nDataset\nDescription\n03\n06\n09\n12\n15\n18\n\n\n\nStudent\ndemographic data on student participants\nx\nx\nx\nx\nx\nx\n\n\nSchool\ndescriptive data about schools\nx\nx\nx\nx\nx\nx\n\n\nParent\na survey for student’s parents including information about home environments and parental education\nx\nx\n\n\n\n\n\n\nTeacher\ndemographic, teaching, qualification and training data\n\n\n\nx\nx\nx\n\n\nCognitive\n\nx\nx\nx\nx\nx\nx\n\n\n\nPISA datasets above can be found on the OECD website. The links in the table above will allow you to download .rds versions of these files which we have created, though they might need additional editing, e.g. reducing the number of columns or changing the types of each column. If you want to find out more about what each field stores, take a look at the corresponding codebook, for example from 2018."
  },
  {
    "objectID": "index.html#how-to-use-it",
    "href": "index.html#how-to-use-it",
    "title": "Questions and Answers",
    "section": "\n13.3 How to use it",
    "text": "13.3 How to use it\nThe PISA datasets come in SPSS or SAS formats. The data used in this course comes directly from downloading the SPSS .sav files and using the haven package to clean it into a native R format suitable for analysis. There are a few quirks that you need to be aware of:\n\nR uses levels (factors) instead of labelled data\nAll SPSS fields are labelled, and auto conversion into the native R dataframe format would make numeric fields factors(!?). To avoid this confusion we have stripped out the no-response data and replaced it with NA values. This means that you won’t be able to tell the reason that a field is missing, and the following labels have all been set to NA:\n\n\nLabels set to NA in .rds file\n\nvalue\nlabel\n\n\n\n95\nValid Skip\n\n\n97\nNot Applicable\n\n\n98\nInvalid\n\n\n99\nNo Response\n\n\n\n\nAs the fields are now using R’s native factor format you might find that the data doesn’t quite match the format of the table labels. For example, CNT is labelled “Country code 3-character”, but the data is now instead the full country name.\nthe examples shown above use cut down PISA datasets, where only a limited number of columns are included."
  },
  {
    "objectID": "index.html#common-issues",
    "href": "index.html#common-issues",
    "title": "Questions and Answers",
    "section": "\n13.4 Common issues",
    "text": "13.4 Common issues\nThe PISA datasets can be absolutely huge and might bring your computer to its knees; if you are using a computer with less than 16Gb of RAM you might not be able to load some tables at all. Tables such as the Cognitive dataset have hundreds of thousands of rows and thousands of columns, loading them directly might lead to an error similar to this: Error: cannot allocate vector of size 2.1 Gb. This means that R can’t find enough RAM to load the dataset and has given up. You can see a rough estimate of how much RAM R is currently using the top Environment panel:\n\nTo get around this issues you can try to clean your current R environment using the brush tool:\n\nThis will drop all the current dataframes, objects, functions and packages that you have loaded meaning you will have to reload packages such as library(tidyverse) and library(haven) before you can attempt to reload the PISA tables.\nA lack of RAM might also be the result of lots of other programs running concurrently on your computer. Try to close anything that you don’t need, web browsers can be particularly RAM hungry, so close them or as many tabs as you can.\nIf none of the above works, then please get in touch with the team, letting them know which table you need from which year, with which fields and for which countries. We will be able to provide you with a cutdown dataset."
  },
  {
    "objectID": "index.html#questions-7",
    "href": "index.html#questions-7",
    "title": "Questions and Answers",
    "section": "\n13.5 Questions",
    "text": "13.5 Questions\n\n13.5.1 What are Plausible Values?\nIn the PISA dataset, the outcomes of student tests are reported as plausible values, for example, in the variables of the science test (PV1SCIE, PV2SCIE, PV3SCIE, PV3SCIE, and PV5SCIE). It might seem counter intuitive that there are five values for a score on a test.\nPlausible values (PVs) are a way of expressing the error in a measurement. The number of questions in the full PISA survey is very large, so students are randomly allocated to take a subset of questions (and even then, the test still takes two hours!). As no student completes the full set of questions, estimating how a student would have performed on the full question set involves some error. Plausible values are a way of expressing the uncertainty in the estimation of student scores.\nOne way of thinking of the PV scores is that they represent five different estimates of students’ abilities based on the questions they have answered. To decrease measurement error, five different approaches are applied to create five different estimates, the PV scores.\nThe PISA Data Analysis Manual suggests:\n\nPopulation statistics should be estimated using each plausible value separately. The reported population statistic is then the average of each plausible value statistic. For instance, if one is interested in the correlation coefficient between the social index and the reading performance in PISA, then five correlation coefficients should be computed and then averaged\nPlausible values should never be averaged at the student level, i.e. by computing in the dataset the mean of the five plausible values at the student level and then computing the statistic of interest once using that average PV value. Doing so would be equivalent to an EAP estimate, with a bias as described in the previous section.\n(p. 100) Monseur et al. (2009)\n\n\nWhat are PV Values - exclude non-OECD? as mean too low\ndifference between TA and NA for field names\n\n13.5.2 Why are some countries OECD countries and others aren’t?\nThe Organisation for Economic Co-operation and Development (OECD) has 38 member states. PISA is run by the OECD and its member states normally take part in each PISA cycle, but other countries are allowed to take part as Partners. You can find more details on participation here.\nResults for OECD members are generally higher than for Partner countries:\n\nPISA_2018 %>% \n  group_by(OECD) %>% \n  summarise(country_n = length(unique(CNT)),\n            math_mean = mean(PV1MATH, na.rm=TRUE),\n            math_sd = sd(PV1MATH, na.rm=TRUE),\n            students_n = n())\n\n# A tibble: 2 × 5\n  OECD  country_n math_mean math_sd students_n\n  <fct>     <int>     <dbl>   <dbl>      <int>\n1 No           43      434.   106.      317477\n2 Yes          37      490.    93.8     294527\n\n\n\n13.5.3 Why are the PV grades pivoting around the ~500 mark?\n\n13.5.4 Why are the letters TA and NA used in some field names?"
  },
  {
    "objectID": "index.html#interesting-papers-and-reading-on-pisa",
    "href": "index.html#interesting-papers-and-reading-on-pisa",
    "title": "Questions and Answers",
    "section": "\n13.6 Interesting papers and reading on PISA",
    "text": "13.6 Interesting papers and reading on PISA\nJerrim Jiang and McComas (2015) Monseur et al. (2009)"
  },
  {
    "objectID": "index.html#copyright",
    "href": "index.html#copyright",
    "title": "Questions and Answers",
    "section": "\n13.7 Copyright",
    "text": "13.7 Copyright\n\nAll PISA products are published under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)\n\nThis includes the rds formatted datasets linked above."
  },
  {
    "objectID": "index.html#english-department-for-education",
    "href": "index.html#english-department-for-education",
    "title": "Questions and Answers",
    "section": "\n13.8 English Department for Education",
    "text": "13.8 English Department for Education\nEducation provider details https://www.get-information-schools.service.gov.uk/Downloads\nResults"
  },
  {
    "objectID": "index.html#timss",
    "href": "index.html#timss",
    "title": "Questions and Answers",
    "section": "\n13.9 TIMSS",
    "text": "13.9 TIMSS"
  },
  {
    "objectID": "index.html#other-datasets",
    "href": "index.html#other-datasets",
    "title": "Questions and Answers",
    "section": "\n13.10 Other datasets",
    "text": "13.10 Other datasets\nGender development index:\nhttps://hdr.undp.org/gender-development-index#/indicies/GDI\n\n\n\nONS\nhttps://www.ons.gov.uk/census/2011census/2011censusdata\nhttps://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationandhouseholdestimatesenglandandwalescensus2021"
  },
  {
    "objectID": "index.html#sec-QANDA",
    "href": "index.html#sec-QANDA",
    "title": "Questions and Answers",
    "section": "\n14.1 Questions about R",
    "text": "14.1 Questions about R\nWhy doesn’t my select/filter statement work?\nWhen you are loading packages, sometimes different packages have the same function names in them, and the functions themselves will do very different things. For example, there is a select function in the tidyverse, but also another select function in the package MASS that does something very different. If we load the tidyverse before loading MASS, then the MASS version of select is the one that will be used?!\n\n\n\n\nlibrary(tidyverse)\nlibrary(MASS)\n\ndiamonds %>% select(carat, cut, color)\n\nTo get around this make sure that you load the tidyverse after MASS, in fact you should always load the tidyverse last.\n\nlibrary(MASS) \nlibrary(tidyverse)\n\ndiamonds %>% select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   <dbl> <ord>     <ord>\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# … with 53,930 more rows\n\n\nyou can also specify the package that select comes from (in this case from a package within the tidyverse called dplyr):\n\ndiamonds %>% dplyr::select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   <dbl> <ord>     <ord>\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# … with 53,930 more rows\n\n\nHow can I unload packages\nIf you are finding yourself with a conflict as mentioned above and want to unload packages, then you need to run the following code:\n\n# adapted from: @mmfrgmpds https://stackoverflow.com/questions/7505547/detach-all-packages-while-working-in-r\nwhile(!is.null(sessionInfo()$loadedOnly)){\n  lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)\n  invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))    \n}"
  },
  {
    "objectID": "index.html#about-the-coursework",
    "href": "index.html#about-the-coursework",
    "title": "Questions and Answers",
    "section": "\n14.2 About the coursework",
    "text": "14.2 About the coursework\n?filter"
  }
]